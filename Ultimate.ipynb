{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/250\n",
      "50000/50000 [==============================] - 61s 1ms/step - loss: 2.0074 - acc: 0.2504 - val_loss: 1.7253 - val_acc: 0.3786\n",
      "Epoch 2/250\n",
      "50000/50000 [==============================] - 50s 997us/step - loss: 1.6732 - acc: 0.3802 - val_loss: 1.5442 - val_acc: 0.4375\n",
      "Epoch 3/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 1.5274 - acc: 0.4384 - val_loss: 1.4163 - val_acc: 0.4868\n",
      "Epoch 4/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 1.4312 - acc: 0.4760 - val_loss: 1.3284 - val_acc: 0.5256\n",
      "Epoch 5/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 1.3538 - acc: 0.5111 - val_loss: 1.2654 - val_acc: 0.5420\n",
      "Epoch 6/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 1.2885 - acc: 0.5384 - val_loss: 1.1919 - val_acc: 0.5839\n",
      "Epoch 7/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 1.2394 - acc: 0.5568 - val_loss: 1.1426 - val_acc: 0.5959\n",
      "Epoch 8/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 1.1920 - acc: 0.5762 - val_loss: 1.1068 - val_acc: 0.6091\n",
      "Epoch 9/250\n",
      "50000/50000 [==============================] - 50s 1000us/step - loss: 1.1463 - acc: 0.5928 - val_loss: 1.0775 - val_acc: 0.6209\n",
      "Epoch 10/250\n",
      "50000/50000 [==============================] - 50s 1000us/step - loss: 1.1168 - acc: 0.6046 - val_loss: 1.0451 - val_acc: 0.6335\n",
      "Epoch 11/250\n",
      "50000/50000 [==============================] - 50s 998us/step - loss: 1.0808 - acc: 0.6183 - val_loss: 1.0078 - val_acc: 0.6488\n",
      "Epoch 12/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 1.0513 - acc: 0.6262 - val_loss: 0.9881 - val_acc: 0.6548\n",
      "Epoch 13/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 1.0269 - acc: 0.6374 - val_loss: 0.9707 - val_acc: 0.6613\n",
      "Epoch 14/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.9994 - acc: 0.6478 - val_loss: 0.9493 - val_acc: 0.6715\n",
      "Epoch 15/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.9799 - acc: 0.6564 - val_loss: 0.9512 - val_acc: 0.6679\n",
      "Epoch 16/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.9552 - acc: 0.6623 - val_loss: 0.9040 - val_acc: 0.6848\n",
      "Epoch 17/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.9363 - acc: 0.6714 - val_loss: 0.8965 - val_acc: 0.6899\n",
      "Epoch 18/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.9149 - acc: 0.6795 - val_loss: 0.8778 - val_acc: 0.6977\n",
      "Epoch 19/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.8976 - acc: 0.6856 - val_loss: 0.8638 - val_acc: 0.7028\n",
      "Epoch 20/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.8829 - acc: 0.6909 - val_loss: 0.8438 - val_acc: 0.7082\n",
      "Epoch 21/250\n",
      "50000/50000 [==============================] - 50s 1000us/step - loss: 0.8628 - acc: 0.6962 - val_loss: 0.8400 - val_acc: 0.7070\n",
      "Epoch 22/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.8451 - acc: 0.7045 - val_loss: 0.8229 - val_acc: 0.7159\n",
      "Epoch 23/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.8270 - acc: 0.7098 - val_loss: 0.8207 - val_acc: 0.7120\n",
      "Epoch 24/250\n",
      "50000/50000 [==============================] - 50s 998us/step - loss: 0.8142 - acc: 0.7152 - val_loss: 0.7954 - val_acc: 0.7281\n",
      "Epoch 25/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.7992 - acc: 0.7198 - val_loss: 0.8000 - val_acc: 0.7210\n",
      "Epoch 26/250\n",
      "50000/50000 [==============================] - 50s 998us/step - loss: 0.7884 - acc: 0.7231 - val_loss: 0.7910 - val_acc: 0.7255\n",
      "Epoch 27/250\n",
      "50000/50000 [==============================] - 50s 998us/step - loss: 0.7753 - acc: 0.7279 - val_loss: 0.7690 - val_acc: 0.7313\n",
      "Epoch 28/250\n",
      "50000/50000 [==============================] - 50s 999us/step - loss: 0.7630 - acc: 0.7337 - val_loss: 0.7525 - val_acc: 0.7400\n",
      "Epoch 29/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.7430 - acc: 0.7407 - val_loss: 0.7626 - val_acc: 0.7311\n",
      "Epoch 30/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.7330 - acc: 0.7441 - val_loss: 0.7348 - val_acc: 0.7466\n",
      "Epoch 31/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.7258 - acc: 0.7451 - val_loss: 0.7449 - val_acc: 0.7414\n",
      "Epoch 32/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.7095 - acc: 0.7509 - val_loss: 0.7358 - val_acc: 0.7416\n",
      "Epoch 33/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.7048 - acc: 0.7531 - val_loss: 0.7223 - val_acc: 0.7495\n",
      "Epoch 34/250\n",
      "50000/50000 [==============================] - 50s 998us/step - loss: 0.6877 - acc: 0.7595 - val_loss: 0.7175 - val_acc: 0.7497\n",
      "Epoch 35/250\n",
      "50000/50000 [==============================] - 50s 999us/step - loss: 0.6813 - acc: 0.7601 - val_loss: 0.7102 - val_acc: 0.7535\n",
      "Epoch 36/250\n",
      "50000/50000 [==============================] - 50s 997us/step - loss: 0.6704 - acc: 0.7653 - val_loss: 0.7134 - val_acc: 0.7558\n",
      "Epoch 37/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.6584 - acc: 0.7690 - val_loss: 0.6903 - val_acc: 0.7600\n",
      "Epoch 38/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.6472 - acc: 0.7722 - val_loss: 0.6860 - val_acc: 0.7632\n",
      "Epoch 39/250\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 0.6399 - acc: 0.7770 - val_loss: 0.6877 - val_acc: 0.7638\n",
      "Epoch 40/250\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 0.6298 - acc: 0.7773 - val_loss: 0.6854 - val_acc: 0.7641\n",
      "Epoch 41/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.6196 - acc: 0.7852 - val_loss: 0.6747 - val_acc: 0.7705\n",
      "Epoch 42/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.6133 - acc: 0.7855 - val_loss: 0.6704 - val_acc: 0.7669\n",
      "Epoch 43/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.6028 - acc: 0.7873 - val_loss: 0.6674 - val_acc: 0.7714\n",
      "Epoch 44/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.5943 - acc: 0.7920 - val_loss: 0.6555 - val_acc: 0.7716\n",
      "Epoch 45/250\n",
      "50000/50000 [==============================] - 50s 998us/step - loss: 0.5869 - acc: 0.7945 - val_loss: 0.6562 - val_acc: 0.7781\n",
      "Epoch 46/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.5757 - acc: 0.7989 - val_loss: 0.6486 - val_acc: 0.7778\n",
      "Epoch 47/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.5727 - acc: 0.7983 - val_loss: 0.6431 - val_acc: 0.7810\n",
      "Epoch 48/250\n",
      "50000/50000 [==============================] - 50s 999us/step - loss: 0.5630 - acc: 0.8012 - val_loss: 0.6450 - val_acc: 0.7787\n",
      "Epoch 49/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.5566 - acc: 0.8049 - val_loss: 0.6445 - val_acc: 0.7762\n",
      "Epoch 50/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.5511 - acc: 0.8069 - val_loss: 0.6504 - val_acc: 0.7746\n",
      "10000/10000 [==============================] - 4s 426us/step\n",
      "Loss: 0.650\n",
      "Accuracy: 0.775\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(1000)\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.0001, decay=1e-6),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train / 255.0, to_categorical(Y_train),\n",
    "          batch_size=128,\n",
    "          shuffle=True,\n",
    "          epochs=250,\n",
    "          validation_data=(X_test / 255.0, to_categorical(Y_test)),\n",
    "          callbacks=[EarlyStopping(min_delta=0.001, patience=3)])\n",
    "\n",
    "# Evaluate the model\n",
    "scores = model.evaluate(X_test / 255.0, to_categorical(Y_test))\n",
    "\n",
    "print('Loss: %.3f' % scores[0])\n",
    "print('Accuracy: %.3f' % scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.convolutional.Conv2D object at 0x000002857F37D128>\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000285700587F0>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x000002850E5F34E0>\n",
      "<keras.layers.core.Dropout object at 0x000002850E5F3860>\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000028505321E10>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x000002850E623400>\n",
      "<keras.layers.convolutional.Conv2D object at 0x000002850E5F3908>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x000002850E667898>\n",
      "<keras.layers.core.Dropout object at 0x000002856E1770B8>\n",
      "<keras.layers.core.Flatten object at 0x000002850E67CCF8>\n",
      "<keras.layers.core.Dense object at 0x000002850E667908>\n",
      "<keras.layers.core.Dropout object at 0x000002850E690E48>\n",
      "<keras.layers.core.Dense object at 0x000002850E6D06D8>\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = Sequential()\n",
    "\n",
    "for layer in model.layers[:-3]:\n",
    "    layer.trainable = False\n",
    "    new_model.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.convolutional.Conv2D at 0x2857f37d128>,\n",
       " <keras.layers.convolutional.Conv2D at 0x285700587f0>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x2850e5f34e0>,\n",
       " <keras.layers.core.Dropout at 0x2850e5f3860>,\n",
       " <keras.layers.convolutional.Conv2D at 0x28505321e10>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x2850e623400>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2850e5f3908>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x2850e667898>,\n",
       " <keras.layers.core.Dropout at 0x2856e1770b8>,\n",
       " <keras.layers.core.Flatten at 0x2850e67ccf8>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.add(Dense(1024, activation='relu'))\n",
    "\n",
    "new_model.add(Dense(200, activation='relu'))\n",
    "\n",
    "new_model.add(Dense(100, activation='softmax'))\n",
    "\n",
    "new_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.01, decay=1e-6),\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar100\n",
    "\n",
    "(X_train_100, Y_train_100), (X_test_100, Y_test_100) = cifar100.load_data()\n",
    "\n",
    "X_train_100 = X_train_100 / 255.0\n",
    "X_test_100 = X_test_100 / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "391/391 [==============================] - 40s 102ms/step - loss: 3.3271 - acc: 0.2038 - val_loss: 2.9447 - val_acc: 0.2723\n",
      "Epoch 2/250\n",
      "391/391 [==============================] - 22s 57ms/step - loss: 2.9649 - acc: 0.2689 - val_loss: 2.8296 - val_acc: 0.3013\n",
      "Epoch 3/250\n",
      "391/391 [==============================] - 22s 57ms/step - loss: 2.8571 - acc: 0.2931 - val_loss: 2.8027 - val_acc: 0.3112\n",
      "Epoch 4/250\n",
      "391/391 [==============================] - 22s 57ms/step - loss: 2.7849 - acc: 0.3092 - val_loss: 2.7801 - val_acc: 0.3171\n",
      "Epoch 5/250\n",
      "391/391 [==============================] - 22s 57ms/step - loss: 2.7250 - acc: 0.3217 - val_loss: 2.7818 - val_acc: 0.3219\n",
      "Epoch 6/250\n",
      "391/391 [==============================] - 22s 57ms/step - loss: 2.6845 - acc: 0.3310 - val_loss: 2.7748 - val_acc: 0.3251\n",
      "Epoch 7/250\n",
      "391/391 [==============================] - 22s 57ms/step - loss: 2.6492 - acc: 0.3394 - val_loss: 2.7530 - val_acc: 0.3287\n",
      "Epoch 8/250\n",
      "391/391 [==============================] - 22s 57ms/step - loss: 2.6134 - acc: 0.3480 - val_loss: 2.7978 - val_acc: 0.3256\n",
      "Epoch 9/250\n",
      "391/391 [==============================] - 22s 57ms/step - loss: 2.5903 - acc: 0.3538 - val_loss: 2.7498 - val_acc: 0.3332\n",
      "Epoch 10/250\n",
      "391/391 [==============================] - 22s 56ms/step - loss: 2.5651 - acc: 0.3592 - val_loss: 2.7449 - val_acc: 0.3345\n",
      "Epoch 11/250\n",
      "391/391 [==============================] - 22s 57ms/step - loss: 2.5355 - acc: 0.3654 - val_loss: 2.7662 - val_acc: 0.3326\n",
      "Epoch 12/250\n",
      "391/391 [==============================] - 22s 57ms/step - loss: 2.5197 - acc: 0.3696 - val_loss: 2.7807 - val_acc: 0.3354\n",
      "Epoch 13/250\n",
      "391/391 [==============================] - 22s 56ms/step - loss: 2.5057 - acc: 0.3741 - val_loss: 2.7853 - val_acc: 0.3363\n",
      "Epoch 14/250\n",
      "391/391 [==============================] - 22s 56ms/step - loss: 2.4873 - acc: 0.3778 - val_loss: 2.7635 - val_acc: 0.3398\n",
      "Epoch 15/250\n",
      "391/391 [==============================] - 22s 57ms/step - loss: 2.4695 - acc: 0.3842 - val_loss: 2.7576 - val_acc: 0.3435\n",
      "Epoch 16/250\n",
      "391/391 [==============================] - 22s 57ms/step - loss: 2.4591 - acc: 0.3870 - val_loss: 2.7667 - val_acc: 0.3386\n",
      "Epoch 17/250\n",
      "391/391 [==============================] - 22s 57ms/step - loss: 2.4486 - acc: 0.3905 - val_loss: 2.7929 - val_acc: 0.3416\n",
      "Epoch 18/250\n",
      "391/391 [==============================] - 22s 57ms/step - loss: 2.4369 - acc: 0.3900 - val_loss: 2.7676 - val_acc: 0.3482\n",
      "Epoch 19/250\n",
      "391/391 [==============================] - 22s 56ms/step - loss: 2.4170 - acc: 0.3933 - val_loss: 2.7879 - val_acc: 0.3353\n",
      "Epoch 20/250\n",
      "391/391 [==============================] - 22s 57ms/step - loss: 2.4024 - acc: 0.4013 - val_loss: 2.7676 - val_acc: 0.3481\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x285085f3fd0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_gen_100 = ImageDataGenerator()#rotation_range=90; vertical_flip = True\n",
    "train_gen_100.fit(X_train_100)\n",
    "\n",
    "# Train the model\n",
    "new_model.fit_generator(train_gen_100.flow(X_train_100, to_categorical(Y_train_100), batch_size=128, shuffle = True),\n",
    "          epochs=250,\n",
    "          validation_data=(X_test_100, to_categorical(Y_test_100)),\n",
    "          callbacks=[EarlyStopping(min_delta=0.001, patience=10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NON-Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/250\n",
      "50000/50000 [==============================] - 53s 1ms/step - loss: 4.4423 - acc: 0.0272 - val_loss: 4.2010 - val_acc: 0.0638\n",
      "Epoch 2/250\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 4.1047 - acc: 0.0705 - val_loss: 3.9122 - val_acc: 0.1176\n",
      "Epoch 3/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 3.8967 - acc: 0.1025 - val_loss: 3.6956 - val_acc: 0.1489\n",
      "Epoch 4/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 3.7311 - acc: 0.1323 - val_loss: 3.5388 - val_acc: 0.1796\n",
      "Epoch 5/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 3.6146 - acc: 0.1492 - val_loss: 3.4394 - val_acc: 0.1886\n",
      "Epoch 6/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 3.5141 - acc: 0.1671 - val_loss: 3.3514 - val_acc: 0.2065\n",
      "Epoch 7/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 3.4328 - acc: 0.1811 - val_loss: 3.2699 - val_acc: 0.2251\n",
      "Epoch 8/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 3.3584 - acc: 0.1938 - val_loss: 3.1897 - val_acc: 0.2370\n",
      "Epoch 9/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 3.2956 - acc: 0.2041 - val_loss: 3.1343 - val_acc: 0.2486\n",
      "Epoch 10/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 3.2315 - acc: 0.2183 - val_loss: 3.1003 - val_acc: 0.2522\n",
      "Epoch 11/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 3.1783 - acc: 0.2267 - val_loss: 3.0105 - val_acc: 0.2719\n",
      "Epoch 12/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 3.1213 - acc: 0.2357 - val_loss: 2.9676 - val_acc: 0.2770\n",
      "Epoch 13/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 3.0718 - acc: 0.2470 - val_loss: 2.9325 - val_acc: 0.2901\n",
      "Epoch 14/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 3.0323 - acc: 0.2542 - val_loss: 2.8970 - val_acc: 0.2914\n",
      "Epoch 15/250\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 2.9905 - acc: 0.2626 - val_loss: 2.8560 - val_acc: 0.2977\n",
      "Epoch 16/250\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 2.9500 - acc: 0.2699 - val_loss: 2.8112 - val_acc: 0.3081\n",
      "Epoch 17/250\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 2.9119 - acc: 0.2746 - val_loss: 2.7877 - val_acc: 0.3122\n",
      "Epoch 18/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 2.8820 - acc: 0.2824 - val_loss: 2.7602 - val_acc: 0.3179\n",
      "Epoch 19/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 2.8397 - acc: 0.2924 - val_loss: 2.7272 - val_acc: 0.3226\n",
      "Epoch 20/250\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 2.8106 - acc: 0.3005 - val_loss: 2.7141 - val_acc: 0.3232\n",
      "Epoch 21/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 2.7804 - acc: 0.3027 - val_loss: 2.6701 - val_acc: 0.3330\n",
      "Epoch 22/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 2.7489 - acc: 0.3100 - val_loss: 2.6611 - val_acc: 0.3318\n",
      "Epoch 23/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 2.7192 - acc: 0.3184 - val_loss: 2.6161 - val_acc: 0.3448\n",
      "Epoch 24/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 2.6918 - acc: 0.3208 - val_loss: 2.5918 - val_acc: 0.3481\n",
      "Epoch 25/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 2.6667 - acc: 0.3282 - val_loss: 2.5696 - val_acc: 0.3548\n",
      "Epoch 26/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 2.6371 - acc: 0.3306 - val_loss: 2.5666 - val_acc: 0.3496\n",
      "Epoch 27/250\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 2.6173 - acc: 0.3340 - val_loss: 2.5514 - val_acc: 0.3570\n",
      "Epoch 28/250\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 2.5819 - acc: 0.3433 - val_loss: 2.5201 - val_acc: 0.3646\n",
      "Epoch 29/250\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 2.5580 - acc: 0.3474 - val_loss: 2.4943 - val_acc: 0.3706\n",
      "Epoch 30/250\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 2.5392 - acc: 0.3526 - val_loss: 2.4590 - val_acc: 0.3763\n",
      "Epoch 31/250\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 2.5103 - acc: 0.3588 - val_loss: 2.4478 - val_acc: 0.3791\n",
      "Epoch 32/250\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 2.4801 - acc: 0.3642 - val_loss: 2.4374 - val_acc: 0.3808\n",
      "Epoch 33/250\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 2.4583 - acc: 0.3685 - val_loss: 2.4072 - val_acc: 0.3892\n",
      "Epoch 34/250\n",
      "50000/50000 [==============================] - 57s 1ms/step - loss: 2.4341 - acc: 0.3722 - val_loss: 2.3942 - val_acc: 0.3847\n",
      "Epoch 35/250\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 2.4094 - acc: 0.3790 - val_loss: 2.3813 - val_acc: 0.3929\n",
      "Epoch 36/250\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 2.3876 - acc: 0.3833 - val_loss: 2.3534 - val_acc: 0.3981\n",
      "Epoch 37/250\n",
      "50000/50000 [==============================] - 70s 1ms/step - loss: 2.3652 - acc: 0.3866 - val_loss: 2.3663 - val_acc: 0.3962\n",
      "Epoch 38/250\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 2.3504 - acc: 0.3923 - val_loss: 2.3352 - val_acc: 0.4000\n",
      "Epoch 39/250\n",
      "50000/50000 [==============================] - 69s 1ms/step - loss: 2.3263 - acc: 0.3942 - val_loss: 2.3184 - val_acc: 0.4032\n",
      "Epoch 40/250\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 2.3038 - acc: 0.3996 - val_loss: 2.2943 - val_acc: 0.4066\n",
      "Epoch 41/250\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 2.2885 - acc: 0.4022 - val_loss: 2.3036 - val_acc: 0.4097\n",
      "Epoch 42/250\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 2.2665 - acc: 0.4086 - val_loss: 2.2781 - val_acc: 0.4131\n",
      "Epoch 43/250\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 2.2447 - acc: 0.4114 - val_loss: 2.2646 - val_acc: 0.4192\n",
      "Epoch 44/250\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 2.2309 - acc: 0.4138 - val_loss: 2.2490 - val_acc: 0.4196\n",
      "Epoch 45/250\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 2.2140 - acc: 0.4216 - val_loss: 2.2513 - val_acc: 0.4229\n",
      "Epoch 46/250\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 2.1968 - acc: 0.4227 - val_loss: 2.2118 - val_acc: 0.4294\n",
      "Epoch 47/250\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 2.1806 - acc: 0.4248 - val_loss: 2.2215 - val_acc: 0.4309\n",
      "Epoch 48/250\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 2.1645 - acc: 0.4273 - val_loss: 2.1991 - val_acc: 0.4324\n",
      "Epoch 49/250\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 2.1432 - acc: 0.4345 - val_loss: 2.1859 - val_acc: 0.4376\n",
      "Epoch 50/250\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 2.1359 - acc: 0.4351 - val_loss: 2.1862 - val_acc: 0.4340\n",
      "Epoch 51/250\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 2.1122 - acc: 0.4405 - val_loss: 2.1902 - val_acc: 0.4293\n",
      "Epoch 52/250\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 2.0978 - acc: 0.4448 - val_loss: 2.1743 - val_acc: 0.4357\n",
      "Epoch 53/250\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 2.0847 - acc: 0.4443 - val_loss: 2.1572 - val_acc: 0.4407\n",
      "Epoch 54/250\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 2.0722 - acc: 0.4485 - val_loss: 2.1423 - val_acc: 0.4415\n",
      "Epoch 55/250\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 2.0531 - acc: 0.4524 - val_loss: 2.1262 - val_acc: 0.4490\n",
      "Epoch 56/250\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 2.0416 - acc: 0.4560 - val_loss: 2.1304 - val_acc: 0.4464\n",
      "Epoch 57/250\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 2.0317 - acc: 0.4561 - val_loss: 2.1156 - val_acc: 0.4508\n",
      "Epoch 58/250\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 2.0114 - acc: 0.4616 - val_loss: 2.1100 - val_acc: 0.4517\n",
      "Epoch 59/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 51s 1ms/step - loss: 2.0004 - acc: 0.4655 - val_loss: 2.0976 - val_acc: 0.4534\n",
      "Epoch 60/250\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 1.9841 - acc: 0.4676 - val_loss: 2.0931 - val_acc: 0.4537\n",
      "Epoch 61/250\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 1.9730 - acc: 0.4692 - val_loss: 2.0910 - val_acc: 0.4557\n",
      "Epoch 62/250\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 1.9677 - acc: 0.4729 - val_loss: 2.0908 - val_acc: 0.4567\n",
      "Epoch 63/250\n",
      " 6400/50000 [==>...........................] - ETA: 41s - loss: 1.9271 - acc: 0.4817"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-134fb311751a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     49\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m250\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m           callbacks=[EarlyStopping(min_delta=0.001, patience=3)])\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;31m# Evaluate the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\condathree\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\condathree\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\condathree\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\condathree\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[1;32m-> 1451\u001b[1;33m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[0;32m   1452\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(1000)\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "(X_train, Y_train), (X_test, Y_test) = cifar100.load_data()\n",
    "\n",
    "# Create the model\n",
    "model1 = Sequential()\n",
    "\n",
    "model1.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model1.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model1.add(Dropout(0.25))\n",
    "\n",
    "model1.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model1.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model1.add(Dropout(0.25))\n",
    "\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(1024, activation='relu'))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(100, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model1.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.0001, decay=1e-6),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model1.fit(X_train / 255.0, to_categorical(Y_train),\n",
    "          batch_size=128,\n",
    "          shuffle=True,\n",
    "          epochs=250,\n",
    "          validation_data=(X_test / 255.0, to_categorical(Y_test)),\n",
    "          callbacks=[EarlyStopping(min_delta=0.001, patience=3)])\n",
    "\n",
    "# Evaluate the model\n",
    "scores = model1.evaluate(X_test / 255.0, to_categorical(Y_test))\n",
    "\n",
    "print('Loss: %.3f' % scores[0])\n",
    "print('Accuracy: %.3f' % scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:condathree]",
   "language": "python",
   "name": "conda-env-condathree-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
