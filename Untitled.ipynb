{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "train_gen = ImageDataGenerator(rotation_range=90,\n",
    "                               vertical_flip = True,horizontal_flip = True)\n",
    "\n",
    "train_gen.fit(X_train)\n",
    "print('hello')\n",
    "new_instances_X = []\n",
    "new_instances_y = []\n",
    "i = 0\n",
    "for X_batch, y_batch in train_gen.flow(X_train, Y_train, batch_size=1):\n",
    "    i+=1\n",
    "    if i == 100000:\n",
    "        break\n",
    "    new_instances_X.append(X_batch[0])\n",
    "    new_instances_y.append(y_batch[0])            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_aug = np.concatenate([X_train, np.array(new_instances_X)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_aug = np.concatenate([Y_train, np.array(new_instances_y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_instances_X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "391/391 [==============================] - 17s 44ms/step - loss: 2.0931 - acc: 0.2336 - val_loss: 1.9033 - val_acc: 0.3260\n",
      "Epoch 2/250\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 1.7657 - acc: 0.3691 - val_loss: 1.6617 - val_acc: 0.4030\n",
      "Epoch 3/250\n",
      "391/391 [==============================] - 16s 41ms/step - loss: 1.5925 - acc: 0.4278 - val_loss: 1.5662 - val_acc: 0.4406\n",
      "Epoch 4/250\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 1.4737 - acc: 0.4700 - val_loss: 1.4352 - val_acc: 0.4849\n",
      "Epoch 5/250\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.3829 - acc: 0.5065 - val_loss: 1.3549 - val_acc: 0.5179\n",
      "Epoch 6/250\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.3144 - acc: 0.5335 - val_loss: 1.3338 - val_acc: 0.5296\n",
      "Epoch 7/250\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.2545 - acc: 0.5540 - val_loss: 1.2502 - val_acc: 0.5580\n",
      "Epoch 8/250\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.1990 - acc: 0.5764 - val_loss: 1.2101 - val_acc: 0.5772\n",
      "Epoch 9/250\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.1535 - acc: 0.5949 - val_loss: 1.1648 - val_acc: 0.5921\n",
      "Epoch 10/250\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.0978 - acc: 0.6152 - val_loss: 1.1357 - val_acc: 0.6015\n",
      "Epoch 11/250\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.0545 - acc: 0.6290 - val_loss: 1.1135 - val_acc: 0.6105\n",
      "Epoch 12/250\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 1.0200 - acc: 0.6429 - val_loss: 1.1251 - val_acc: 0.6013\n",
      "Epoch 13/250\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 0.9753 - acc: 0.6588 - val_loss: 1.1013 - val_acc: 0.6145\n",
      "Epoch 14/250\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 0.9312 - acc: 0.6752 - val_loss: 1.0877 - val_acc: 0.6205\n",
      "Epoch 15/250\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 0.8890 - acc: 0.6899 - val_loss: 1.0609 - val_acc: 0.6323\n",
      "Epoch 16/250\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 0.8570 - acc: 0.7016 - val_loss: 1.0600 - val_acc: 0.6344\n",
      "Epoch 17/250\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 0.8184 - acc: 0.7161 - val_loss: 1.0961 - val_acc: 0.6210\n",
      "Epoch 18/250\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 0.7759 - acc: 0.7297 - val_loss: 1.0617 - val_acc: 0.6410\n",
      "10000/10000 [==============================] - 3s 284us/step\n",
      "Loss: 1.062\n",
      "Accuracy: 0.641\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "#validation_data=(X_test / 255.0, to_categorical(Y_test)),\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(1000)\n",
    "\n",
    "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
    "\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "\n",
    "train_gen = ImageDataGenerator()#rotation_range=90; vertical_flip = True\n",
    "train_gen.fit(X_train)\n",
    "\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, kernel_size=(5, 5), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3)))\n",
    "model.add(Conv2D(48, kernel_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(84, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr = 0.001, momentum = 0.9),#Adam(lr=0.001, decay=1e-6),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit_generator(train_gen.flow(X_train, to_categorical(Y_train), batch_size=128, shuffle = True),\n",
    "          epochs=250,\n",
    "          validation_data=(X_test, to_categorical(Y_test)),\n",
    "          callbacks=[EarlyStopping(min_delta=0.001, patience=3)])\n",
    "\n",
    "# Evaluate the model\n",
    "scores = model.evaluate(X_test, to_categorical(Y_test))\n",
    "\n",
    "print('Loss: %.3f' % scores[0])\n",
    "print('Accuracy: %.3f' % scores[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 28, 28, 16)        1216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 12, 12, 32)        4640      \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 11, 11, 48)        6192      \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 5808)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 512)               2974208   \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 84)                10836     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 3,063,606\n",
      "Trainable params: 3,063,606\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.convolutional.Conv2D object at 0x000002A88EBB1898>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x000002A88EBB1D68>\n",
      "<keras.layers.convolutional.Conv2D object at 0x000002A88EBB1C18>\n",
      "<keras.layers.convolutional.Conv2D object at 0x000002A88EBB6FD0>\n",
      "<keras.layers.core.Flatten object at 0x000002A88EBC7BE0>\n",
      "<keras.layers.core.Dense object at 0x000002A88EBC7EB8>\n",
      "<keras.layers.core.Dense object at 0x000002A88EBDA908>\n",
      "<keras.layers.core.Dense object at 0x000002A9DD4A8320>\n",
      "<keras.layers.core.Dense object at 0x000002A9DD4A7198>\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.convolutional.Conv2D at 0x2a88ebb1898>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x2a88ebb1d68>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2a88ebb1c18>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2a88ebb6fd0>,\n",
       " <keras.layers.core.Flatten at 0x2a88ebc7be0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[:-4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = Sequential()\n",
    "\n",
    "\n",
    "\n",
    "for layer in model.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "    new_model.add(layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.add(Dense(1000, activation='relu'))\n",
    "\n",
    "new_model.add(Dense(250, activation='relu'))\n",
    "\n",
    "new_model.add(Dense(100, activation='softmax'))\n",
    "\n",
    "new_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer = SGD(lr = 0.001, momentum = 0.9),\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "391/391 [==============================] - 27s 70ms/step - loss: 3.6300 - acc: 0.1586 - val_loss: 3.4740 - val_acc: 0.1881\n",
      "Epoch 2/250\n",
      "391/391 [==============================] - 22s 56ms/step - loss: 3.2997 - acc: 0.2101 - val_loss: 3.4497 - val_acc: 0.2047\n",
      "Epoch 3/250\n",
      "391/391 [==============================] - 22s 57ms/step - loss: 3.1124 - acc: 0.2463 - val_loss: 3.4028 - val_acc: 0.2115\n",
      "Epoch 4/250\n",
      "391/391 [==============================] - 22s 57ms/step - loss: 2.9717 - acc: 0.2694 - val_loss: 3.4448 - val_acc: 0.2185\n",
      "Epoch 5/250\n",
      "391/391 [==============================] - 22s 57ms/step - loss: 2.8494 - acc: 0.2910 - val_loss: 3.4981 - val_acc: 0.2159\n",
      "Epoch 6/250\n",
      "391/391 [==============================] - 22s 57ms/step - loss: 2.7724 - acc: 0.3054 - val_loss: 3.5186 - val_acc: 0.2190\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a88f0d8a90>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_gen_100 = ImageDataGenerator()#rotation_range=90; vertical_flip = True\n",
    "train_gen_100.fit(X_train_100)\n",
    "\n",
    "# Train the model\n",
    "new_model.fit_generator(train_gen_100.flow(X_train_100, to_categorical(Y_train_100), batch_size=128, shuffle = True),\n",
    "          epochs=250,\n",
    "          validation_data=(X_test_100, to_categorical(Y_test_100)),\n",
    "          callbacks=[EarlyStopping(min_delta=0.001, patience=3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar100\n",
    "\n",
    "(X_train_100, Y_train_100), (X_test_100, Y_test_100) = cifar100.load_data()\n",
    "\n",
    "X_train_100 = X_train_100 / 255.0\n",
    "X_test_100 = X_test_100 / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 100)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_categorical(Y_test_100).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "391/391 [==============================] - 32s 82ms/step - loss: 3.6287 - acc: 0.1590 - val_loss: 3.1182 - val_acc: 0.2503\n",
      "Epoch 2/250\n",
      "391/391 [==============================] - 29s 74ms/step - loss: 2.8276 - acc: 0.3003 - val_loss: 2.8585 - val_acc: 0.3031\n",
      "Epoch 3/250\n",
      "391/391 [==============================] - 29s 74ms/step - loss: 2.3985 - acc: 0.3874 - val_loss: 2.7266 - val_acc: 0.3326\n",
      "Epoch 4/250\n",
      "391/391 [==============================] - 29s 74ms/step - loss: 1.9673 - acc: 0.4799 - val_loss: 2.7227 - val_acc: 0.3446\n",
      "Epoch 5/250\n",
      "391/391 [==============================] - 29s 74ms/step - loss: 1.4882 - acc: 0.5903 - val_loss: 2.9757 - val_acc: 0.3295\n",
      "Epoch 6/250\n",
      "391/391 [==============================] - 29s 74ms/step - loss: 1.0054 - acc: 0.7128 - val_loss: 3.2224 - val_acc: 0.3326\n",
      "Epoch 7/250\n",
      "391/391 [==============================] - 29s 74ms/step - loss: 0.6110 - acc: 0.8194 - val_loss: 3.8898 - val_acc: 0.3283\n",
      "10000/10000 [==============================] - 4s 398us/step\n",
      "Loss: 3.890\n",
      "Accuracy: 0.328\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "#validation_data=(X_test / 255.0, to_categorical(Y_test)),\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.datasets import cifar100\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(1000)\n",
    "\n",
    "(X_train, Y_train), (X_test, Y_test) = cifar100.load_data()\n",
    "\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "\n",
    "train_gen = ImageDataGenerator()#rotation_range=90; vertical_flip = True\n",
    "train_gen.fit(X_train)\n",
    "\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, kernel_size=(5, 5), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3)))\n",
    "model.add(Conv2D(48, kernel_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(100, activation='softmax'))\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer = SGD(lr = 0.001, momentum = 0.9),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit_generator(train_gen.flow(X_train, to_categorical(Y_train), batch_size=128, shuffle = True),\n",
    "          epochs=250,\n",
    "          validation_data=(X_test, to_categorical(Y_test)),\n",
    "          callbacks=[EarlyStopping(min_delta=0.001, patience=3)])\n",
    "\n",
    "# Evaluate the model\n",
    "scores = model.evaluate(X_test, to_categorical(Y_test))\n",
    "\n",
    "print('Loss: %.3f' % scores[0])\n",
    "print('Accuracy: %.3f' % scores[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:condathree]",
   "language": "python",
   "name": "conda-env-condathree-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
