{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = pd.DataFrame(columns=['experience','train','epoch','itrs','loss','accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepLearning on Cifar10 and TransferLearning to Cifar100\n",
    "\n",
    "- Construire et Evaluer un Réseau de neuron\n",
    "- Evaluer l'impact des différents choix\n",
    "    - Pretraitement\n",
    "    - Auguementation de données\n",
    "    - Initialisation\n",
    "    - Architecture\n",
    "    - Nombre de couches\n",
    "    - Régularisation\n",
    "    - Opimisation\n",
    "    - fonction de coût\n",
    "- Le passage de Cifar10 à Cifar100\n",
    "\n",
    "Le but de ce projet m'a l'air de comprendre le fonctionnement de cnn et de tester plusiers procedures qui pourraient influencer le résultat et les quantifier. Donc J'ai cré le propre cnn et l'entrainer nous-même, surtout, avec cela nous pourrons tester l'impact de l'architecture et nombre de couches par exemple. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform PILImage of range [0,1] to Tensors of normalized range[-1,1]\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
    "\n",
    "valtransform = transforms.Compose(\n",
    "    [transforms.RandomCrop(32,padding=4),\n",
    "     transforms.RandomHorizontalFlip(),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "    ])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=False, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "validationset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=False, transform=valtransform)\n",
    "validationloader = torch.utils.data.DataLoader(validationset,batch_size=1000,\n",
    "                                              shuffle=False, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=False,transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB6CAYAAACvHqiXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhR4RERGxTRBf6BERERHbBP8f/XT85gkOMWgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x204a37fdb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " bird   dog truck  bird\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5 # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg,(1,2,0)))\n",
    "    plt.show()\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "#show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "#print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define our CNN\n",
    "Notice that images are in 3-channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BaseCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaseCNN,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,6,5)#in_channels,Out_channels,kernel_size\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(6,16,5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)#reshape\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Loss function and optimizer\n",
    "Use Cross_Entropy loss and SGD with Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sergey\\AppData\\Local\\conda\\conda\\envs\\condathree\\lib\\site-packages\\torch\\cuda\\__init__.py:117: UserWarning: \n",
      "    Found GPU0 GeForce GT 755M which is of cuda capability 3.0.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    \n",
      "  warnings.warn(old_gpu_warn % (d, name, major, capability[1]))\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "base_cnn = BaseCNN()\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    base_cnn = base_cnn.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(base_cnn.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the network\n",
    "This model will be the benchmark to be compared with during all experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(experiment,model=base_cnn,loss_function=criterion,optimizer=optimizer,trainloader=trainloader,validationloader=validationloader,validation=True,epochs=2):\n",
    "    recording = pd.DataFrame(columns=['experience','train','epoch','itrs','loss','accuracy'])\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs\n",
    "\n",
    "            inputs, labels = data\n",
    "            if use_gpu:\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999: # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss %.3f' % \n",
    "                      (epoch + 1, i + 1, running_loss / 2000))\n",
    "                recording.loc[recording.index.size]=[experiment, 0, epoch+1 , i+1, running_loss/2000, 0]\n",
    "                if validation:\n",
    "                    validation_loss = 0.0\n",
    "                    val_size = 0\n",
    "                    for val_data in validationloader:\n",
    "                        val_size += 1\n",
    "                        val_inputs, val_labels = val_data\n",
    "                        val_loss = loss_function(model(val_inputs),val_labels)\n",
    "                        validation_loss += val_loss.item()\n",
    "                    print('[%d, %5d] val_loss: %.3f' % \n",
    "                          (epoch + 1, i + 1, validation_loss/val_size))\n",
    "                    recording.loc[recording.index.size]=[experiment, 1, epoch+1, i+1, validation_loss/val_size, 0]\n",
    "                    running_loss = 0.0\n",
    "    print(\"Finish Training\")\n",
    "    return recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: no kernel image is available for execution on the device",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-800f19157ae9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrecording\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'base_cnn'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbase_cnn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-f29d13db6604>\u001b[0m in \u001b[0;36mtraining\u001b[1;34m(experiment, model, loss_function, optimizer, trainloader, validationloader, validation, epochs)\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[1;31m# forward + backward + optimize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\condathree\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-7236894a1d9f>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m16\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#reshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\condathree\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mrelu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m    860\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    863\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: no kernel image is available for execution on the device"
     ]
    }
   ],
   "source": [
    "recording = training('base_cnn',model=base_cnn,loss_function=criterion,optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = record.append(recording)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Data image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1118a1550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundTruth:    cat  ship  ship plane\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:    cat  ship  ship  ship\n"
     ]
    }
   ],
   "source": [
    "outputs = (base_cnn(images))\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                             for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result the whole testset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(experiment, model,testloader,recording):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        recording.loc[recording.index.size] = [experiment,0,0,0,0,100*correct/total]\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
    "    return recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 56 %\n"
     ]
    }
   ],
   "source": [
    "recording = testing('base_cnn_test',base_cnn,testloader=testloader,recording=recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = record.append(recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss 2.162\n",
      "[1,  2000] val_loss: 1.946\n",
      "[1,  4000] loss 1.789\n",
      "[1,  4000] val_loss: 1.843\n",
      "[1,  6000] loss 1.660\n",
      "[1,  6000] val_loss: 1.806\n",
      "[1,  8000] loss 1.559\n",
      "[1,  8000] val_loss: 1.988\n",
      "[1, 10000] loss 1.525\n",
      "[1, 10000] val_loss: 1.844\n",
      "[1, 12000] loss 1.452\n",
      "[1, 12000] val_loss: 1.899\n",
      "[2,  2000] loss 1.395\n",
      "[2,  2000] val_loss: 1.795\n",
      "[2,  4000] loss 1.376\n",
      "[2,  4000] val_loss: 1.790\n",
      "[2,  6000] loss 1.349\n",
      "[2,  6000] val_loss: 1.736\n",
      "[2,  8000] loss 1.328\n",
      "[2,  8000] val_loss: 1.844\n",
      "[2, 10000] loss 1.303\n",
      "[2, 10000] val_loss: 1.719\n",
      "[2, 12000] loss 1.277\n",
      "[2, 12000] val_loss: 1.765\n",
      "[3,  2000] loss 1.214\n",
      "[3,  2000] val_loss: 1.901\n",
      "[3,  4000] loss 1.206\n",
      "[3,  4000] val_loss: 1.724\n",
      "[3,  6000] loss 1.216\n",
      "[3,  6000] val_loss: 1.624\n",
      "[3,  8000] loss 1.203\n",
      "[3,  8000] val_loss: 1.715\n",
      "[3, 10000] loss 1.197\n",
      "[3, 10000] val_loss: 1.629\n",
      "[3, 12000] loss 1.160\n",
      "[3, 12000] val_loss: 1.633\n",
      "[4,  2000] loss 1.105\n",
      "[4,  2000] val_loss: 1.783\n",
      "[4,  4000] loss 1.100\n",
      "[4,  4000] val_loss: 1.712\n",
      "[4,  6000] loss 1.117\n",
      "[4,  6000] val_loss: 1.675\n",
      "[4,  8000] loss 1.111\n",
      "[4,  8000] val_loss: 1.605\n",
      "[4, 10000] loss 1.091\n",
      "[4, 10000] val_loss: 1.668\n",
      "[4, 12000] loss 1.094\n",
      "[4, 12000] val_loss: 1.686\n",
      "Finish Training\n",
      "Accuracy of the network on the 10000 test images: 59 %\n"
     ]
    }
   ],
   "source": [
    "# justification of 2 epochs\n",
    "base_cnn = BaseCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(base_cnn.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "recording = training('base_cnn_4epochs',model=base_cnn,loss_function=criterion,optimizer=optimizer,trainloader=trainloader,validationloader=validationloader,validation=True,epochs=4)\n",
    "recording = testing('base_cnn_4epochs',model=base_cnn,testloader=testloader,recording=recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = record.append(recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 69 %\n",
      "Accuracy of   car : 66 %\n",
      "Accuracy of  bird : 37 %\n",
      "Accuracy of   cat : 42 %\n",
      "Accuracy of  deer : 50 %\n",
      "Accuracy of   dog : 49 %\n",
      "Accuracy of  frog : 61 %\n",
      "Accuracy of horse : 61 %\n",
      "Accuracy of  ship : 60 %\n",
      "Accuracy of truck : 60 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = base_cnn(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation:\n",
    "Random horizontal flip and rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# horizontal flip\n",
    "horizontal_flip = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "])\n",
    "train_horizontal_flip = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=False, transform=horizontal_flip)\n",
    "\n",
    "# rotation\n",
    "rotation = transforms.Compose([\n",
    "    transforms.RandomRotation((-180,180)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "])\n",
    "train_rotation = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=False, transform=rotation)\n",
    "\n",
    "# Concatenate\n",
    "train_augumented = torch.utils.data.ConcatDataset([trainset,train_horizontal_flip,train_rotation])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train BaseCNN on Augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(train_augumented, batch_size=4,\n",
    "                                         shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss 2.188\n",
      "[1,  2000] val_loss: 2.077\n",
      "[1,  4000] loss 1.993\n",
      "[1,  4000] val_loss: 1.935\n",
      "[1,  6000] loss 1.855\n",
      "[1,  6000] val_loss: 1.812\n",
      "[1,  8000] loss 1.805\n",
      "[1,  8000] val_loss: 1.778\n",
      "[1, 10000] loss 1.738\n",
      "[1, 10000] val_loss: 1.839\n",
      "[1, 12000] loss 1.700\n",
      "[1, 12000] val_loss: 1.739\n",
      "[1, 14000] loss 1.668\n",
      "[1, 14000] val_loss: 1.818\n",
      "[1, 16000] loss 1.621\n",
      "[1, 16000] val_loss: 1.743\n",
      "[1, 18000] loss 1.603\n",
      "[1, 18000] val_loss: 1.719\n",
      "[1, 20000] loss 1.569\n",
      "[1, 20000] val_loss: 1.693\n",
      "[1, 22000] loss 1.547\n",
      "[1, 22000] val_loss: 1.706\n",
      "[1, 24000] loss 1.542\n",
      "[1, 24000] val_loss: 1.685\n",
      "[1, 26000] loss 1.527\n",
      "[1, 26000] val_loss: 1.625\n",
      "[1, 28000] loss 1.485\n",
      "[1, 28000] val_loss: 1.603\n",
      "[1, 30000] loss 1.488\n",
      "[1, 30000] val_loss: 1.586\n",
      "[1, 32000] loss 1.455\n",
      "[1, 32000] val_loss: 1.594\n",
      "[1, 34000] loss 1.449\n",
      "[1, 34000] val_loss: 1.597\n",
      "[1, 36000] loss 1.462\n",
      "[1, 36000] val_loss: 1.562\n",
      "[2,  2000] loss 1.422\n",
      "[2,  2000] val_loss: 1.584\n",
      "[2,  4000] loss 1.410\n",
      "[2,  4000] val_loss: 1.668\n",
      "[2,  6000] loss 1.411\n",
      "[2,  6000] val_loss: 1.585\n",
      "[2,  8000] loss 1.389\n",
      "[2,  8000] val_loss: 1.547\n",
      "[2, 10000] loss 1.370\n",
      "[2, 10000] val_loss: 1.614\n",
      "[2, 12000] loss 1.377\n",
      "[2, 12000] val_loss: 1.521\n",
      "[2, 14000] loss 1.367\n",
      "[2, 14000] val_loss: 1.647\n",
      "[2, 16000] loss 1.387\n",
      "[2, 16000] val_loss: 1.515\n",
      "[2, 18000] loss 1.358\n",
      "[2, 18000] val_loss: 1.574\n",
      "[2, 20000] loss 1.331\n",
      "[2, 20000] val_loss: 1.557\n",
      "[2, 22000] loss 1.349\n",
      "[2, 22000] val_loss: 1.491\n",
      "[2, 24000] loss 1.334\n",
      "[2, 24000] val_loss: 1.571\n",
      "[2, 26000] loss 1.314\n",
      "[2, 26000] val_loss: 1.506\n",
      "[2, 28000] loss 1.332\n",
      "[2, 28000] val_loss: 1.501\n",
      "[2, 30000] loss 1.332\n",
      "[2, 30000] val_loss: 1.518\n",
      "[2, 32000] loss 1.299\n",
      "[2, 32000] val_loss: 1.558\n",
      "[2, 34000] loss 1.329\n",
      "[2, 34000] val_loss: 1.597\n",
      "[2, 36000] loss 1.318\n",
      "[2, 36000] val_loss: 1.540\n",
      "Finish Training\n",
      "Accuracy of the network on the 10000 test images: 59 %\n"
     ]
    }
   ],
   "source": [
    "# Augmented data\n",
    "base_cnn = BaseCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(base_cnn.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "recording = training('base_cnn_augmented_data_2epoch',model=base_cnn,loss_function=criterion,optimizer=optimizer,trainloader=trainloader,validationloader=validationloader,validation=True,epochs=2)\n",
    "recording = testing('base_cnn_augmented_data_2epoch',model=base_cnn,testloader=testloader,recording=recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = record.append(recording)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion Augmentation de données:\n",
    "Sur le basecnn que nous avons construit, avec une simple augmentation de donnée, nous avons augumenté le Accuracy par 4% (de 55% à 59%). Donc l'augumentation de données est une manière simple d'améliorer la performence du modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intialisation\n",
    "Xavier_initialization_normal vs Xavier_initialization_uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseCNN_with_Xavier_normal(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaseCNN_with_Xavier_normal,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,6,5)#in_channels,Out_channels,kernel_size\n",
    "        torch.nn.init.xavier_normal_(self.conv1.weight)\n",
    "        torch.nn.init.zeros_(self.conv1.bias)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(6,16,5)\n",
    "        torch.nn.init.xavier_normal_(self.conv2.weight)\n",
    "        torch.nn.init.zeros_(self.conv2.bias)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        torch.nn.init.xavier_normal_(self.fc1.weight)\n",
    "        torch.nn.init.zeros_(self.fc1.bias)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        torch.nn.init.xavier_normal_(self.fc2.weight)\n",
    "        torch.nn.init.zeros_(self.fc2.bias)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        torch.nn.init.xavier_normal_(self.fc3.weight)\n",
    "        torch.nn.init.zeros_(self.fc3.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)#reshape\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss 2.056\n",
      "[1,  2000] val_loss: 1.905\n",
      "[1,  4000] loss 1.819\n",
      "[1,  4000] val_loss: 1.782\n",
      "[1,  6000] loss 1.750\n",
      "[1,  6000] val_loss: 1.778\n",
      "[1,  8000] loss 1.688\n",
      "[1,  8000] val_loss: 1.745\n",
      "[1, 10000] loss 1.673\n",
      "[1, 10000] val_loss: 1.720\n",
      "[1, 12000] loss 1.618\n",
      "[1, 12000] val_loss: 1.672\n",
      "[1, 14000] loss 1.601\n",
      "[1, 14000] val_loss: 1.718\n",
      "[1, 16000] loss 1.581\n",
      "[1, 16000] val_loss: 1.678\n",
      "[1, 18000] loss 1.560\n",
      "[1, 18000] val_loss: 1.761\n",
      "[1, 20000] loss 1.546\n",
      "[1, 20000] val_loss: 1.718\n",
      "[1, 22000] loss 1.526\n",
      "[1, 22000] val_loss: 1.652\n",
      "[1, 24000] loss 1.526\n",
      "[1, 24000] val_loss: 1.619\n",
      "[1, 26000] loss 1.508\n",
      "[1, 26000] val_loss: 1.745\n",
      "[1, 28000] loss 1.510\n",
      "[1, 28000] val_loss: 1.698\n",
      "[1, 30000] loss 1.475\n",
      "[1, 30000] val_loss: 1.613\n",
      "[1, 32000] loss 1.465\n",
      "[1, 32000] val_loss: 1.623\n",
      "[1, 34000] loss 1.467\n",
      "[1, 34000] val_loss: 1.686\n",
      "[1, 36000] loss 1.491\n",
      "[1, 36000] val_loss: 1.713\n",
      "[2,  2000] loss 1.440\n",
      "[2,  2000] val_loss: 1.661\n",
      "[2,  4000] loss 1.433\n",
      "[2,  4000] val_loss: 1.615\n",
      "[2,  6000] loss 1.420\n",
      "[2,  6000] val_loss: 1.639\n",
      "[2,  8000] loss 1.421\n",
      "[2,  8000] val_loss: 1.682\n",
      "[2, 10000] loss 1.411\n",
      "[2, 10000] val_loss: 1.624\n",
      "[2, 12000] loss 1.410\n",
      "[2, 12000] val_loss: 1.640\n",
      "[2, 14000] loss 1.399\n",
      "[2, 14000] val_loss: 1.702\n",
      "[2, 16000] loss 1.380\n",
      "[2, 16000] val_loss: 1.727\n",
      "[2, 18000] loss 1.398\n",
      "[2, 18000] val_loss: 1.621\n",
      "[2, 20000] loss 1.379\n",
      "[2, 20000] val_loss: 1.659\n",
      "[2, 22000] loss 1.390\n",
      "[2, 22000] val_loss: 1.604\n",
      "[2, 24000] loss 1.379\n",
      "[2, 24000] val_loss: 1.603\n",
      "[2, 26000] loss 1.385\n",
      "[2, 26000] val_loss: 1.675\n",
      "[2, 28000] loss 1.369\n",
      "[2, 28000] val_loss: 1.615\n",
      "[2, 30000] loss 1.382\n",
      "[2, 30000] val_loss: 1.617\n",
      "[2, 32000] loss 1.374\n",
      "[2, 32000] val_loss: 1.604\n",
      "[2, 34000] loss 1.374\n",
      "[2, 34000] val_loss: 1.538\n",
      "[2, 36000] loss 1.360\n",
      "[2, 36000] val_loss: 1.586\n",
      "[3,  2000] loss 1.330\n",
      "[3,  2000] val_loss: 1.602\n",
      "[3,  4000] loss 1.330\n",
      "[3,  4000] val_loss: 1.550\n",
      "[3,  6000] loss 1.340\n",
      "[3,  6000] val_loss: 1.548\n",
      "[3,  8000] loss 1.336\n",
      "[3,  8000] val_loss: 1.561\n",
      "[3, 10000] loss 1.340\n",
      "[3, 10000] val_loss: 1.589\n",
      "[3, 12000] loss 1.319\n",
      "[3, 12000] val_loss: 1.615\n",
      "[3, 14000] loss 1.321\n",
      "[3, 14000] val_loss: 1.604\n",
      "[3, 16000] loss 1.325\n",
      "[3, 16000] val_loss: 1.634\n",
      "[3, 18000] loss 1.321\n",
      "[3, 18000] val_loss: 1.657\n",
      "[3, 20000] loss 1.319\n",
      "[3, 20000] val_loss: 1.703\n",
      "[3, 22000] loss 1.321\n",
      "[3, 22000] val_loss: 1.626\n",
      "[3, 24000] loss 1.311\n",
      "[3, 24000] val_loss: 1.582\n",
      "[3, 26000] loss 1.308\n",
      "[3, 26000] val_loss: 1.741\n",
      "[3, 28000] loss 1.330\n",
      "[3, 28000] val_loss: 1.644\n",
      "[3, 30000] loss 1.337\n",
      "[3, 30000] val_loss: 1.548\n",
      "[3, 32000] loss 1.315\n",
      "[3, 32000] val_loss: 1.518\n",
      "[3, 34000] loss 1.308\n",
      "[3, 34000] val_loss: 1.468\n",
      "[3, 36000] loss 1.304\n",
      "[3, 36000] val_loss: 1.558\n",
      "[4,  2000] loss 1.269\n",
      "[4,  2000] val_loss: 1.523\n",
      "[4,  4000] loss 1.296\n",
      "[4,  4000] val_loss: 1.562\n",
      "[4,  6000] loss 1.296\n",
      "[4,  6000] val_loss: 1.578\n",
      "[4,  8000] loss 1.280\n",
      "[4,  8000] val_loss: 1.576\n",
      "[4, 10000] loss 1.290\n",
      "[4, 10000] val_loss: 1.561\n",
      "[4, 12000] loss 1.279\n",
      "[4, 12000] val_loss: 1.573\n",
      "[4, 14000] loss 1.279\n",
      "[4, 14000] val_loss: 1.681\n",
      "[4, 16000] loss 1.276\n",
      "[4, 16000] val_loss: 1.624\n",
      "[4, 18000] loss 1.275\n",
      "[4, 18000] val_loss: 1.611\n",
      "[4, 20000] loss 1.265\n",
      "[4, 20000] val_loss: 1.534\n",
      "[4, 22000] loss 1.290\n",
      "[4, 22000] val_loss: 1.480\n",
      "[4, 24000] loss 1.274\n",
      "[4, 24000] val_loss: 1.534\n",
      "[4, 26000] loss 1.299\n",
      "[4, 26000] val_loss: 1.527\n",
      "[4, 28000] loss 1.269\n",
      "[4, 28000] val_loss: 1.540\n",
      "[4, 30000] loss 1.280\n",
      "[4, 30000] val_loss: 1.539\n",
      "[4, 32000] loss 1.275\n",
      "[4, 32000] val_loss: 1.548\n",
      "[4, 34000] loss 1.279\n",
      "[4, 34000] val_loss: 1.548\n",
      "[4, 36000] loss 1.244\n",
      "[4, 36000] val_loss: 1.644\n",
      "Finish Training\n",
      "Accuracy of the network on the 10000 test images: 60 %\n"
     ]
    }
   ],
   "source": [
    "base_cnn_xavier_normal = BaseCNN_with_Xavier_normal()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(base_cnn_xavier_normal.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "recording = training('base_cnn_xavier_normal',model=base_cnn_xavier_normal,loss_function=criterion,optimizer=optimizer,trainloader=trainloader,validationloader=validationloader,validation=True,epochs=4)\n",
    "recording = testing('base_cnn_xavier_normal',model=base_cnn_xavier_normal,testloader=testloader,recording=recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = record.append(recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseCNN_with_Xavier_uniform(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaseCNN_with_Xavier_uniform,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,6,5)#in_channels,Out_channels,kernel_size\n",
    "        torch.nn.init.xavier_uniform_(self.conv1.weight)\n",
    "        torch.nn.init.zeros_(self.conv1.bias)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(6,16,5)\n",
    "        torch.nn.init.xavier_uniform_(self.conv2.weight)\n",
    "        torch.nn.init.zeros_(self.conv2.bias)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        torch.nn.init.zeros_(self.fc1.bias)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
    "        torch.nn.init.zeros_(self.fc2.bias)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        torch.nn.init.xavier_uniform_(self.fc3.weight)\n",
    "        torch.nn.init.zeros_(self.fc3.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)#reshape\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "base_cnn_xavier_uniform = BaseCNN_with_Xavier_uniform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(base_cnn_xavier_uniform.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss 2.040\n",
      "[1,  2000] val_loss: 1.876\n",
      "[1,  4000] loss 1.836\n",
      "[1,  4000] val_loss: 1.809\n",
      "[1,  6000] loss 1.770\n",
      "[1,  6000] val_loss: 1.783\n",
      "[1,  8000] loss 1.696\n",
      "[1,  8000] val_loss: 1.723\n",
      "[1, 10000] loss 1.674\n",
      "[1, 10000] val_loss: 1.789\n",
      "[1, 12000] loss 1.650\n",
      "[1, 12000] val_loss: 1.698\n",
      "[1, 14000] loss 1.609\n",
      "[1, 14000] val_loss: 1.704\n",
      "[1, 16000] loss 1.597\n",
      "[1, 16000] val_loss: 1.669\n",
      "[1, 18000] loss 1.591\n",
      "[1, 18000] val_loss: 1.677\n",
      "[1, 20000] loss 1.568\n",
      "[1, 20000] val_loss: 1.639\n",
      "[1, 22000] loss 1.531\n",
      "[1, 22000] val_loss: 1.679\n",
      "[1, 24000] loss 1.530\n",
      "[1, 24000] val_loss: 1.732\n",
      "[1, 26000] loss 1.517\n",
      "[1, 26000] val_loss: 1.629\n",
      "[1, 28000] loss 1.514\n",
      "[1, 28000] val_loss: 1.660\n",
      "[1, 30000] loss 1.480\n",
      "[1, 30000] val_loss: 1.672\n",
      "[1, 32000] loss 1.485\n",
      "[1, 32000] val_loss: 1.648\n",
      "[1, 34000] loss 1.469\n",
      "[1, 34000] val_loss: 1.791\n",
      "[1, 36000] loss 1.454\n",
      "[1, 36000] val_loss: 1.793\n",
      "[2,  2000] loss 1.438\n",
      "[2,  2000] val_loss: 1.712\n",
      "[2,  4000] loss 1.417\n",
      "[2,  4000] val_loss: 1.660\n",
      "[2,  6000] loss 1.409\n",
      "[2,  6000] val_loss: 1.597\n",
      "[2,  8000] loss 1.425\n",
      "[2,  8000] val_loss: 1.684\n",
      "[2, 10000] loss 1.423\n",
      "[2, 10000] val_loss: 1.612\n",
      "[2, 12000] loss 1.384\n",
      "[2, 12000] val_loss: 1.615\n",
      "[2, 14000] loss 1.406\n",
      "[2, 14000] val_loss: 1.645\n",
      "[2, 16000] loss 1.381\n",
      "[2, 16000] val_loss: 1.580\n",
      "[2, 18000] loss 1.394\n",
      "[2, 18000] val_loss: 1.562\n",
      "[2, 20000] loss 1.382\n",
      "[2, 20000] val_loss: 1.613\n",
      "[2, 22000] loss 1.402\n",
      "[2, 22000] val_loss: 1.613\n",
      "[2, 24000] loss 1.366\n",
      "[2, 24000] val_loss: 1.629\n",
      "[2, 26000] loss 1.359\n",
      "[2, 26000] val_loss: 1.611\n",
      "[2, 28000] loss 1.379\n",
      "[2, 28000] val_loss: 1.543\n",
      "[2, 30000] loss 1.372\n",
      "[2, 30000] val_loss: 1.645\n",
      "[2, 32000] loss 1.371\n",
      "[2, 32000] val_loss: 1.608\n",
      "[2, 34000] loss 1.357\n",
      "[2, 34000] val_loss: 1.571\n",
      "[2, 36000] loss 1.351\n",
      "[2, 36000] val_loss: 1.638\n",
      "[3,  2000] loss 1.322\n",
      "[3,  2000] val_loss: 1.599\n",
      "[3,  4000] loss 1.333\n",
      "[3,  4000] val_loss: 1.620\n",
      "[3,  6000] loss 1.328\n",
      "[3,  6000] val_loss: 1.557\n",
      "[3,  8000] loss 1.356\n",
      "[3,  8000] val_loss: 1.596\n",
      "[3, 10000] loss 1.327\n",
      "[3, 10000] val_loss: 1.644\n",
      "[3, 12000] loss 1.326\n",
      "[3, 12000] val_loss: 1.665\n",
      "[3, 14000] loss 1.321\n",
      "[3, 14000] val_loss: 1.628\n",
      "[3, 16000] loss 1.337\n",
      "[3, 16000] val_loss: 1.530\n",
      "[3, 18000] loss 1.312\n",
      "[3, 18000] val_loss: 1.584\n",
      "[3, 20000] loss 1.314\n",
      "[3, 20000] val_loss: 1.563\n",
      "[3, 22000] loss 1.278\n",
      "[3, 22000] val_loss: 1.642\n",
      "[3, 24000] loss 1.315\n",
      "[3, 24000] val_loss: 1.567\n",
      "[3, 26000] loss 1.311\n",
      "[3, 26000] val_loss: 1.565\n",
      "[3, 28000] loss 1.273\n",
      "[3, 28000] val_loss: 1.569\n",
      "[3, 30000] loss 1.288\n",
      "[3, 30000] val_loss: 1.540\n",
      "[3, 32000] loss 1.281\n",
      "[3, 32000] val_loss: 1.634\n",
      "[3, 34000] loss 1.302\n",
      "[3, 34000] val_loss: 1.579\n",
      "[3, 36000] loss 1.278\n",
      "[3, 36000] val_loss: 1.606\n",
      "[4,  2000] loss 1.246\n",
      "[4,  2000] val_loss: 1.720\n",
      "[4,  4000] loss 1.281\n",
      "[4,  4000] val_loss: 1.565\n",
      "[4,  6000] loss 1.255\n",
      "[4,  6000] val_loss: 1.536\n",
      "[4,  8000] loss 1.262\n",
      "[4,  8000] val_loss: 1.582\n",
      "[4, 10000] loss 1.285\n",
      "[4, 10000] val_loss: 1.566\n",
      "[4, 12000] loss 1.279\n",
      "[4, 12000] val_loss: 1.577\n",
      "[4, 14000] loss 1.267\n",
      "[4, 14000] val_loss: 1.528\n",
      "[4, 16000] loss 1.266\n",
      "[4, 16000] val_loss: 1.579\n",
      "[4, 18000] loss 1.277\n",
      "[4, 18000] val_loss: 1.527\n",
      "[4, 20000] loss 1.254\n",
      "[4, 20000] val_loss: 1.591\n",
      "[4, 22000] loss 1.255\n",
      "[4, 22000] val_loss: 1.574\n",
      "[4, 24000] loss 1.257\n",
      "[4, 24000] val_loss: 1.596\n",
      "[4, 26000] loss 1.266\n",
      "[4, 26000] val_loss: 1.630\n",
      "[4, 28000] loss 1.248\n",
      "[4, 28000] val_loss: 1.658\n",
      "[4, 30000] loss 1.261\n",
      "[4, 30000] val_loss: 1.516\n",
      "[4, 32000] loss 1.258\n",
      "[4, 32000] val_loss: 1.565\n",
      "[4, 34000] loss 1.267\n",
      "[4, 34000] val_loss: 1.610\n",
      "[4, 36000] loss 1.277\n",
      "[4, 36000] val_loss: 1.579\n",
      "Finish Training\n",
      "Accuracy of the network on the 10000 test images: 62 %\n"
     ]
    }
   ],
   "source": [
    "recording = training('base_cnn_xavier_uniform',model=base_cnn_xavier_uniform,loss_function=criterion,optimizer=optimizer,trainloader=trainloader,validationloader=validationloader,validation=True,epochs=4)\n",
    "recording = testing('base_cnn_xavier_uniform',model=base_cnn_xavier_uniform,testloader=testloader,recording=recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = record.append(recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "record.to_csv('record.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion Initialisation:\n",
    "Même si l'initialisation nous donne des loss plus petit au début d'entraînement, l'initialisation par default est encore le plus performent qui nous donne 59% d'accuracy, soit 3% de plus que les initialisations personalisées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimisation\n",
    "\n",
    "SGD-Nesterov Adadelta, Adam, RMSprop\n",
    "\n",
    "- Adadelta > Adagrad reason"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SDG_Nesterov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(train_augumented, batch_size=4,\n",
    "                                         shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_cnn = BaseCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(base_cnn.parameters(),lr=0.001,momentum=0.9,nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss 2.277\n",
      "[1,  2000] val_loss: 2.119\n",
      "[1,  4000] loss 2.018\n",
      "[1,  4000] val_loss: 1.876\n",
      "[1,  6000] loss 1.868\n",
      "[1,  6000] val_loss: 1.844\n",
      "[1,  8000] loss 1.754\n",
      "[1,  8000] val_loss: 1.765\n",
      "[1, 10000] loss 1.705\n",
      "[1, 10000] val_loss: 1.785\n",
      "[1, 12000] loss 1.674\n",
      "[1, 12000] val_loss: 1.760\n",
      "[1, 14000] loss 1.655\n",
      "[1, 14000] val_loss: 1.754\n",
      "[1, 16000] loss 1.626\n",
      "[1, 16000] val_loss: 1.682\n",
      "[1, 18000] loss 1.590\n",
      "[1, 18000] val_loss: 1.672\n",
      "[1, 20000] loss 1.553\n",
      "[1, 20000] val_loss: 1.702\n",
      "[1, 22000] loss 1.552\n",
      "[1, 22000] val_loss: 1.633\n",
      "[1, 24000] loss 1.554\n",
      "[1, 24000] val_loss: 1.642\n",
      "[1, 26000] loss 1.506\n",
      "[1, 26000] val_loss: 1.645\n",
      "[1, 28000] loss 1.493\n",
      "[1, 28000] val_loss: 1.647\n",
      "[1, 30000] loss 1.494\n",
      "[1, 30000] val_loss: 1.753\n",
      "[1, 32000] loss 1.509\n",
      "[1, 32000] val_loss: 1.676\n",
      "[1, 34000] loss 1.469\n",
      "[1, 34000] val_loss: 1.682\n",
      "[1, 36000] loss 1.453\n",
      "[1, 36000] val_loss: 1.596\n",
      "[2,  2000] loss 1.427\n",
      "[2,  2000] val_loss: 1.607\n",
      "[2,  4000] loss 1.446\n",
      "[2,  4000] val_loss: 1.618\n",
      "[2,  6000] loss 1.412\n",
      "[2,  6000] val_loss: 1.642\n",
      "[2,  8000] loss 1.412\n",
      "[2,  8000] val_loss: 1.600\n",
      "[2, 10000] loss 1.410\n",
      "[2, 10000] val_loss: 1.596\n",
      "[2, 12000] loss 1.407\n",
      "[2, 12000] val_loss: 1.630\n",
      "[2, 14000] loss 1.377\n",
      "[2, 14000] val_loss: 1.672\n",
      "[2, 16000] loss 1.399\n",
      "[2, 16000] val_loss: 1.599\n",
      "[2, 18000] loss 1.390\n",
      "[2, 18000] val_loss: 1.590\n",
      "[2, 20000] loss 1.372\n",
      "[2, 20000] val_loss: 1.568\n",
      "[2, 22000] loss 1.373\n",
      "[2, 22000] val_loss: 1.574\n",
      "[2, 24000] loss 1.376\n",
      "[2, 24000] val_loss: 1.617\n",
      "[2, 26000] loss 1.364\n",
      "[2, 26000] val_loss: 1.578\n",
      "[2, 28000] loss 1.379\n",
      "[2, 28000] val_loss: 1.531\n",
      "[2, 30000] loss 1.361\n",
      "[2, 30000] val_loss: 1.672\n",
      "[2, 32000] loss 1.347\n",
      "[2, 32000] val_loss: 1.541\n",
      "[2, 34000] loss 1.360\n",
      "[2, 34000] val_loss: 1.568\n",
      "[2, 36000] loss 1.333\n",
      "[2, 36000] val_loss: 1.594\n",
      "Finish Training\n",
      "Accuracy of the network on the 10000 test images: 57 %\n"
     ]
    }
   ],
   "source": [
    "recording = training('base_cnn_SGD_nesterov_2epoch',model=base_cnn,loss_function=criterion,optimizer=optimizer,trainloader=trainloader,validationloader=validationloader,validation=True,epochs=2)\n",
    "recording = testing('base_cnn_SGD_nesterov_2epoch',model=base_cnn,testloader=testloader,recording=recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = record.append(recording)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adadelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_cnn = BaseCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adadelta(base_cnn.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss 2.026\n",
      "[1,  2000] val_loss: 1.992\n",
      "[1,  4000] loss 1.829\n",
      "[1,  4000] val_loss: 2.094\n",
      "[1,  6000] loss 1.811\n",
      "[1,  6000] val_loss: 1.816\n",
      "[1,  8000] loss 1.793\n",
      "[1,  8000] val_loss: 1.850\n",
      "[1, 10000] loss 1.794\n",
      "[1, 10000] val_loss: 1.933\n",
      "[1, 12000] loss 1.794\n",
      "[1, 12000] val_loss: 2.323\n",
      "[1, 14000] loss 1.803\n",
      "[1, 14000] val_loss: 1.873\n",
      "[1, 16000] loss 1.774\n",
      "[1, 16000] val_loss: 2.043\n",
      "[1, 18000] loss 1.762\n",
      "[1, 18000] val_loss: 1.910\n",
      "[1, 20000] loss 1.786\n",
      "[1, 20000] val_loss: 1.829\n",
      "[1, 22000] loss 1.805\n",
      "[1, 22000] val_loss: 1.908\n",
      "[1, 24000] loss 1.839\n",
      "[1, 24000] val_loss: 2.170\n",
      "[1, 26000] loss 1.831\n",
      "[1, 26000] val_loss: 2.191\n",
      "[1, 28000] loss 1.821\n",
      "[1, 28000] val_loss: 2.072\n",
      "[1, 30000] loss 1.815\n",
      "[1, 30000] val_loss: 1.910\n",
      "[1, 32000] loss 1.840\n",
      "[1, 32000] val_loss: 1.933\n",
      "[1, 34000] loss 1.867\n",
      "[1, 34000] val_loss: 2.931\n",
      "[1, 36000] loss 1.847\n",
      "[1, 36000] val_loss: 1.876\n",
      "[2,  2000] loss 1.804\n",
      "[2,  2000] val_loss: 1.827\n",
      "[2,  4000] loss 1.823\n",
      "[2,  4000] val_loss: 1.834\n",
      "[2,  6000] loss 1.835\n",
      "[2,  6000] val_loss: 1.964\n",
      "[2,  8000] loss 1.836\n",
      "[2,  8000] val_loss: 2.091\n",
      "[2, 10000] loss 1.860\n",
      "[2, 10000] val_loss: 2.087\n",
      "[2, 12000] loss 1.866\n",
      "[2, 12000] val_loss: 2.081\n",
      "[2, 14000] loss 1.844\n",
      "[2, 14000] val_loss: 2.035\n",
      "[2, 16000] loss 1.823\n",
      "[2, 16000] val_loss: 2.175\n",
      "[2, 18000] loss 1.806\n",
      "[2, 18000] val_loss: 2.128\n",
      "[2, 20000] loss 1.838\n",
      "[2, 20000] val_loss: 2.688\n",
      "[2, 22000] loss 1.841\n",
      "[2, 22000] val_loss: 2.663\n",
      "[2, 24000] loss 1.831\n",
      "[2, 24000] val_loss: 2.065\n",
      "[2, 26000] loss 1.870\n",
      "[2, 26000] val_loss: 1.934\n",
      "[2, 28000] loss 1.880\n",
      "[2, 28000] val_loss: 3.379\n",
      "[2, 30000] loss 1.850\n",
      "[2, 30000] val_loss: 2.533\n",
      "[2, 32000] loss 1.863\n",
      "[2, 32000] val_loss: 2.195\n",
      "[2, 34000] loss 1.878\n",
      "[2, 34000] val_loss: 2.222\n",
      "[2, 36000] loss 1.896\n",
      "[2, 36000] val_loss: 2.358\n",
      "Finish Training\n",
      "Accuracy of the network on the 10000 test images: 35 %\n"
     ]
    }
   ],
   "source": [
    "recording = training('base_cnn_adadelta_2epoch',model=base_cnn,loss_function=criterion,optimizer=optimizer,trainloader=trainloader,validationloader=validationloader,validation=True,epochs=2)\n",
    "recording = testing('base_cnn_adadelta_2epoch',model=base_cnn,testloader=testloader,recording=recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = record.append(recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set lr = 0.1\n",
    "base_cnn = BaseCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adadelta(base_cnn.parameters(),lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss 2.297\n",
      "[1,  2000] val_loss: 2.277\n",
      "[1,  4000] loss 2.221\n",
      "[1,  4000] val_loss: 2.167\n",
      "[1,  6000] loss 2.129\n",
      "[1,  6000] val_loss: 2.090\n",
      "[1,  8000] loss 2.061\n",
      "[1,  8000] val_loss: 2.041\n",
      "[1, 10000] loss 2.030\n",
      "[1, 10000] val_loss: 2.012\n",
      "[1, 12000] loss 1.995\n",
      "[1, 12000] val_loss: 1.993\n",
      "[1, 14000] loss 1.996\n",
      "[1, 14000] val_loss: 1.983\n",
      "[1, 16000] loss 1.979\n",
      "[1, 16000] val_loss: 1.970\n",
      "[1, 18000] loss 1.963\n",
      "[1, 18000] val_loss: 1.957\n",
      "[1, 20000] loss 1.965\n",
      "[1, 20000] val_loss: 1.944\n",
      "[1, 22000] loss 1.950\n",
      "[1, 22000] val_loss: 1.936\n",
      "[1, 24000] loss 1.922\n",
      "[1, 24000] val_loss: 1.918\n",
      "[1, 26000] loss 1.908\n",
      "[1, 26000] val_loss: 1.911\n",
      "[1, 28000] loss 1.899\n",
      "[1, 28000] val_loss: 1.903\n",
      "[1, 30000] loss 1.880\n",
      "[1, 30000] val_loss: 1.894\n",
      "[1, 32000] loss 1.880\n",
      "[1, 32000] val_loss: 1.890\n",
      "[1, 34000] loss 1.866\n",
      "[1, 34000] val_loss: 1.877\n",
      "[1, 36000] loss 1.862\n",
      "[1, 36000] val_loss: 1.870\n",
      "[2,  2000] loss 1.831\n",
      "[2,  2000] val_loss: 1.870\n",
      "[2,  4000] loss 1.837\n",
      "[2,  4000] val_loss: 1.856\n",
      "[2,  6000] loss 1.821\n",
      "[2,  6000] val_loss: 1.845\n",
      "[2,  8000] loss 1.838\n",
      "[2,  8000] val_loss: 1.839\n",
      "[2, 10000] loss 1.807\n",
      "[2, 10000] val_loss: 1.845\n",
      "[2, 12000] loss 1.811\n",
      "[2, 12000] val_loss: 1.833\n",
      "[2, 14000] loss 1.804\n",
      "[2, 14000] val_loss: 1.821\n",
      "[2, 16000] loss 1.779\n",
      "[2, 16000] val_loss: 1.820\n",
      "[2, 18000] loss 1.782\n",
      "[2, 18000] val_loss: 1.810\n",
      "[2, 20000] loss 1.786\n",
      "[2, 20000] val_loss: 1.809\n",
      "[2, 22000] loss 1.758\n",
      "[2, 22000] val_loss: 1.806\n",
      "[2, 24000] loss 1.765\n",
      "[2, 24000] val_loss: 1.802\n",
      "[2, 26000] loss 1.768\n",
      "[2, 26000] val_loss: 1.810\n",
      "[2, 28000] loss 1.770\n",
      "[2, 28000] val_loss: 1.800\n",
      "[2, 30000] loss 1.728\n",
      "[2, 30000] val_loss: 1.792\n",
      "[2, 32000] loss 1.735\n",
      "[2, 32000] val_loss: 1.799\n",
      "[2, 34000] loss 1.756\n",
      "[2, 34000] val_loss: 1.800\n",
      "[2, 36000] loss 1.734\n",
      "[2, 36000] val_loss: 1.781\n",
      "Finish Training\n",
      "Accuracy of the network on the 10000 test images: 42 %\n"
     ]
    }
   ],
   "source": [
    "recording = training('base_cnn_adadelta_2epoch_lr001',model=base_cnn,loss_function=criterion,optimizer=optimizer,trainloader=trainloader,validationloader=validationloader,validation=True,epochs=2)\n",
    "recording = testing('base_cnn_adadelta_2epoch_lr001',model=base_cnn,testloader=testloader,recording=recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = record.append(recording)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_cnn = BaseCNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(base_cnn.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss 1.991\n",
      "[1,  2000] val_loss: 1.825\n",
      "[1,  4000] loss 1.761\n",
      "[1,  4000] val_loss: 1.733\n",
      "[1,  6000] loss 1.685\n",
      "[1,  6000] val_loss: 1.756\n",
      "[1,  8000] loss 1.618\n",
      "[1,  8000] val_loss: 1.698\n",
      "[1, 10000] loss 1.596\n",
      "[1, 10000] val_loss: 1.686\n",
      "[1, 12000] loss 1.574\n",
      "[1, 12000] val_loss: 1.654\n",
      "[1, 14000] loss 1.547\n",
      "[1, 14000] val_loss: 1.709\n",
      "[1, 16000] loss 1.548\n",
      "[1, 16000] val_loss: 1.661\n",
      "[1, 18000] loss 1.528\n",
      "[1, 18000] val_loss: 1.721\n",
      "[1, 20000] loss 1.512\n",
      "[1, 20000] val_loss: 1.668\n",
      "[1, 22000] loss 1.496\n",
      "[1, 22000] val_loss: 1.657\n",
      "[1, 24000] loss 1.502\n",
      "[1, 24000] val_loss: 1.634\n",
      "[1, 26000] loss 1.479\n",
      "[1, 26000] val_loss: 1.594\n",
      "[1, 28000] loss 1.477\n",
      "[1, 28000] val_loss: 1.643\n",
      "[1, 30000] loss 1.468\n",
      "[1, 30000] val_loss: 1.673\n",
      "[1, 32000] loss 1.485\n",
      "[1, 32000] val_loss: 1.596\n",
      "[1, 34000] loss 1.468\n",
      "[1, 34000] val_loss: 1.564\n",
      "[1, 36000] loss 1.434\n",
      "[1, 36000] val_loss: 1.579\n",
      "[2,  2000] loss 1.442\n",
      "[2,  2000] val_loss: 1.594\n",
      "[2,  4000] loss 1.446\n",
      "[2,  4000] val_loss: 1.632\n",
      "[2,  6000] loss 1.398\n",
      "[2,  6000] val_loss: 1.635\n",
      "[2,  8000] loss 1.439\n",
      "[2,  8000] val_loss: 1.612\n",
      "[2, 10000] loss 1.423\n",
      "[2, 10000] val_loss: 1.670\n",
      "[2, 12000] loss 1.411\n",
      "[2, 12000] val_loss: 1.630\n",
      "[2, 14000] loss 1.391\n",
      "[2, 14000] val_loss: 1.578\n",
      "[2, 16000] loss 1.395\n",
      "[2, 16000] val_loss: 1.616\n",
      "[2, 18000] loss 1.399\n",
      "[2, 18000] val_loss: 1.591\n",
      "[2, 20000] loss 1.395\n",
      "[2, 20000] val_loss: 1.617\n",
      "[2, 22000] loss 1.401\n",
      "[2, 22000] val_loss: 1.630\n",
      "[2, 24000] loss 1.373\n",
      "[2, 24000] val_loss: 1.599\n",
      "[2, 26000] loss 1.392\n",
      "[2, 26000] val_loss: 1.543\n",
      "[2, 28000] loss 1.402\n",
      "[2, 28000] val_loss: 1.625\n",
      "[2, 30000] loss 1.397\n",
      "[2, 30000] val_loss: 1.573\n",
      "[2, 32000] loss 1.370\n",
      "[2, 32000] val_loss: 1.565\n",
      "[2, 34000] loss 1.380\n",
      "[2, 34000] val_loss: 1.632\n",
      "[2, 36000] loss 1.388\n",
      "[2, 36000] val_loss: 1.561\n",
      "Finish Training\n",
      "Accuracy of the network on the 10000 test images: 55 %\n"
     ]
    }
   ],
   "source": [
    "recording = training('base_cnn_adam_2epoch_lr001',model=base_cnn,loss_function=criterion,optimizer=optimizer,trainloader=trainloader,validationloader=validationloader,validation=True,epochs=2)\n",
    "recording = testing('base_cnn_adam_2epoch_lr001',model=base_cnn,testloader=testloader,recording=recording)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_cnn = BaseCNN()\n",
    "criterion = nn.MultiMarginLoss()\n",
    "optimizer = optim.SGD(base_cnn.parameters(),lr=0.001,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss 0.826\n",
      "[1,  2000] val_loss: 0.651\n",
      "[1,  4000] loss 0.616\n",
      "[1,  4000] val_loss: 0.540\n",
      "[1,  6000] loss 0.525\n",
      "[1,  6000] val_loss: 0.491\n",
      "[1,  8000] loss 0.481\n",
      "[1,  8000] val_loss: 0.470\n",
      "[1, 10000] loss 0.448\n",
      "[1, 10000] val_loss: 0.462\n",
      "[1, 12000] loss 0.423\n",
      "[1, 12000] val_loss: 0.419\n",
      "[1, 14000] loss 0.413\n",
      "[1, 14000] val_loss: 0.439\n",
      "[1, 16000] loss 0.409\n",
      "[1, 16000] val_loss: 0.456\n",
      "[1, 18000] loss 0.395\n",
      "[1, 18000] val_loss: 0.413\n",
      "[1, 20000] loss 0.396\n",
      "[1, 20000] val_loss: 0.430\n",
      "[1, 22000] loss 0.382\n",
      "[1, 22000] val_loss: 0.439\n",
      "[1, 24000] loss 0.377\n",
      "[1, 24000] val_loss: 0.438\n",
      "[1, 26000] loss 0.367\n",
      "[1, 26000] val_loss: 0.432\n",
      "[1, 28000] loss 0.367\n",
      "[1, 28000] val_loss: 0.424\n",
      "[1, 30000] loss 0.363\n",
      "[1, 30000] val_loss: 0.406\n",
      "[1, 32000] loss 0.355\n",
      "[1, 32000] val_loss: 0.413\n",
      "[1, 34000] loss 0.348\n",
      "[1, 34000] val_loss: 0.433\n",
      "[1, 36000] loss 0.356\n",
      "[1, 36000] val_loss: 0.419\n",
      "[2,  2000] loss 0.331\n",
      "[2,  2000] val_loss: 0.416\n",
      "[2,  4000] loss 0.332\n",
      "[2,  4000] val_loss: 0.398\n",
      "[2,  6000] loss 0.335\n",
      "[2,  6000] val_loss: 0.447\n",
      "[2,  8000] loss 0.336\n",
      "[2,  8000] val_loss: 0.377\n",
      "[2, 10000] loss 0.329\n",
      "[2, 10000] val_loss: 0.421\n",
      "[2, 12000] loss 0.321\n",
      "[2, 12000] val_loss: 0.401\n",
      "[2, 14000] loss 0.320\n",
      "[2, 14000] val_loss: 0.420\n",
      "[2, 16000] loss 0.317\n",
      "[2, 16000] val_loss: 0.409\n",
      "[2, 18000] loss 0.307\n",
      "[2, 18000] val_loss: 0.418\n",
      "[2, 20000] loss 0.315\n",
      "[2, 20000] val_loss: 0.398\n",
      "[2, 22000] loss 0.309\n",
      "[2, 22000] val_loss: 0.396\n",
      "[2, 24000] loss 0.311\n",
      "[2, 24000] val_loss: 0.386\n",
      "[2, 26000] loss 0.310\n",
      "[2, 26000] val_loss: 0.401\n",
      "[2, 28000] loss 0.308\n",
      "[2, 28000] val_loss: 0.386\n",
      "[2, 30000] loss 0.303\n",
      "[2, 30000] val_loss: 0.411\n",
      "[2, 32000] loss 0.304\n",
      "[2, 32000] val_loss: 0.401\n",
      "[2, 34000] loss 0.303\n",
      "[2, 34000] val_loss: 0.405\n",
      "[2, 36000] loss 0.304\n",
      "[2, 36000] val_loss: 0.409\n",
      "Finish Training\n",
      "Accuracy of the network on the 10000 test images: 55 %\n"
     ]
    }
   ],
   "source": [
    "recording = training('base_cnn_multimargin_lr001',model=base_cnn,loss_function=criterion,optimizer=optimizer,trainloader=trainloader,validationloader=validationloader,validation=True,epochs=2)\n",
    "recording = testing('base_cnn_multimargin_lr001',model=base_cnn,testloader=testloader,recording=recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = record.append(recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Focal loss implementation\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=0, alpha=None, size_average=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        if isinstance(alpha,(float,int,int)): self.alpha = torch.Tensor([alpha,1-alpha])\n",
    "        if isinstance(alpha,list): self.alpha = torch.Tensor(alpha)\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        if input.dim()>2:\n",
    "            input = input.view(input.size(0),input.size(1),-1)  # N,C,H,W => N,C,H*W\n",
    "            input = input.transpose(1,2)    # N,C,H*W => N,H*W,C\n",
    "            input = input.contiguous().view(-1,input.size(2))   # N,H*W,C => N*H*W,C\n",
    "        target = target.view(-1,1)\n",
    "\n",
    "        logpt = F.log_softmax(input)\n",
    "        logpt = logpt.gather(1,target)\n",
    "        logpt = logpt.view(-1)\n",
    "        pt = Variable(logpt.data.exp())\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            if self.alpha.type()!=input.data.type():\n",
    "                self.alpha = self.alpha.type_as(input.data)\n",
    "            at = self.alpha.gather(0,target.data.view(-1))\n",
    "            logpt = logpt * Variable(at)\n",
    "\n",
    "        loss = -1 * (1-pt)**self.gamma * logpt\n",
    "        if self.size_average: return loss.mean()\n",
    "        else: return loss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_cnn = BaseCNN()\n",
    "criterion = FocalLoss(gamma=2)\n",
    "optimizer = optim.SGD(base_cnn.parameters(),lr=0.001,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/LuyiSHENX/lib/python3.6/site-packages/ipykernel_launcher.py:23: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss 1.855\n",
      "[1,  2000] val_loss: 1.798\n",
      "[1,  4000] loss 1.638\n",
      "[1,  4000] val_loss: 1.494\n",
      "[1,  6000] loss 1.431\n",
      "[1,  6000] val_loss: 1.376\n",
      "[1,  8000] loss 1.333\n",
      "[1,  8000] val_loss: 1.279\n",
      "[1, 10000] loss 1.262\n",
      "[1, 10000] val_loss: 1.238\n",
      "[1, 12000] loss 1.223\n",
      "[1, 12000] val_loss: 1.260\n",
      "[1, 14000] loss 1.175\n",
      "[1, 14000] val_loss: 1.244\n",
      "[1, 16000] loss 1.177\n",
      "[1, 16000] val_loss: 1.238\n",
      "[1, 18000] loss 1.146\n",
      "[1, 18000] val_loss: 1.202\n",
      "[1, 20000] loss 1.126\n",
      "[1, 20000] val_loss: 1.177\n",
      "[1, 22000] loss 1.118\n",
      "[1, 22000] val_loss: 1.198\n",
      "[1, 24000] loss 1.081\n",
      "[1, 24000] val_loss: 1.240\n",
      "[1, 26000] loss 1.080\n",
      "[1, 26000] val_loss: 1.161\n",
      "[1, 28000] loss 1.052\n",
      "[1, 28000] val_loss: 1.164\n",
      "[1, 30000] loss 1.043\n",
      "[1, 30000] val_loss: 1.113\n",
      "[1, 32000] loss 1.044\n",
      "[1, 32000] val_loss: 1.115\n",
      "[1, 34000] loss 1.024\n",
      "[1, 34000] val_loss: 1.148\n",
      "[1, 36000] loss 1.008\n",
      "[1, 36000] val_loss: 1.148\n",
      "[2,  2000] loss 0.994\n",
      "[2,  2000] val_loss: 1.118\n",
      "[2,  4000] loss 0.992\n",
      "[2,  4000] val_loss: 1.084\n",
      "[2,  6000] loss 0.968\n",
      "[2,  6000] val_loss: 1.055\n",
      "[2,  8000] loss 0.976\n",
      "[2,  8000] val_loss: 1.112\n",
      "[2, 10000] loss 0.956\n",
      "[2, 10000] val_loss: 1.150\n",
      "[2, 12000] loss 0.952\n",
      "[2, 12000] val_loss: 1.093\n",
      "[2, 14000] loss 0.958\n",
      "[2, 14000] val_loss: 1.027\n",
      "[2, 16000] loss 0.943\n",
      "[2, 16000] val_loss: 1.115\n",
      "[2, 18000] loss 0.908\n",
      "[2, 18000] val_loss: 1.075\n",
      "[2, 20000] loss 0.929\n",
      "[2, 20000] val_loss: 1.108\n",
      "[2, 22000] loss 0.908\n",
      "[2, 22000] val_loss: 1.059\n",
      "[2, 24000] loss 0.914\n",
      "[2, 24000] val_loss: 1.026\n",
      "[2, 26000] loss 0.898\n",
      "[2, 26000] val_loss: 1.037\n",
      "[2, 28000] loss 0.900\n",
      "[2, 28000] val_loss: 1.064\n",
      "[2, 30000] loss 0.899\n",
      "[2, 30000] val_loss: 1.096\n",
      "[2, 32000] loss 0.921\n",
      "[2, 32000] val_loss: 1.055\n",
      "[2, 34000] loss 0.889\n",
      "[2, 34000] val_loss: 1.067\n",
      "[2, 36000] loss 0.878\n",
      "[2, 36000] val_loss: 1.032\n",
      "Finish Training\n",
      "Accuracy of the network on the 10000 test images: 55 %\n"
     ]
    }
   ],
   "source": [
    "recording = training('base_cnn_focalloss2_lr001',model=base_cnn,loss_function=criterion,optimizer=optimizer,trainloader=trainloader,validationloader=validationloader,validation=True,epochs=2)\n",
    "recording = testing('base_cnn_focalloss2_lr001',model=base_cnn,testloader=testloader,recording=recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = record.append(recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "record.to_csv('record.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_cnn = BaseCNN()\n",
    "criterion = FocalLoss(gamma=5)\n",
    "optimizer = optim.SGD(base_cnn.parameters(),lr=0.001,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/LuyiSHENX/lib/python3.6/site-packages/ipykernel_launcher.py:23: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss 0.588\n",
      "[1,  2000] val_loss: 0.737\n",
      "[1,  4000] loss 0.574\n",
      "[1,  4000] val_loss: 0.717\n",
      "[1,  6000] loss 0.579\n",
      "[1,  6000] val_loss: 0.832\n",
      "[1,  8000] loss 0.581\n",
      "[1,  8000] val_loss: 0.716\n",
      "[1, 10000] loss 0.588\n",
      "[1, 10000] val_loss: 0.734\n",
      "[1, 12000] loss 0.566\n",
      "[1, 12000] val_loss: 0.729\n",
      "[1, 14000] loss 0.563\n",
      "[1, 14000] val_loss: 0.797\n",
      "[1, 16000] loss 0.565\n",
      "[1, 16000] val_loss: 0.700\n",
      "[1, 18000] loss 0.566\n",
      "[1, 18000] val_loss: 0.722\n",
      "[1, 20000] loss 0.561\n",
      "[1, 20000] val_loss: 0.757\n",
      "[1, 22000] loss 0.562\n",
      "[1, 22000] val_loss: 0.694\n",
      "[1, 24000] loss 0.542\n",
      "[1, 24000] val_loss: 0.705\n",
      "[1, 26000] loss 0.563\n",
      "[1, 26000] val_loss: 0.730\n",
      "[1, 28000] loss 0.552\n",
      "[1, 28000] val_loss: 0.691\n",
      "[1, 30000] loss 0.545\n",
      "[1, 30000] val_loss: 0.721\n",
      "[1, 32000] loss 0.558\n",
      "[1, 32000] val_loss: 0.712\n",
      "[1, 34000] loss 0.562\n",
      "[1, 34000] val_loss: 0.660\n",
      "[1, 36000] loss 0.540\n",
      "[1, 36000] val_loss: 0.675\n",
      "[2,  2000] loss 0.529\n",
      "[2,  2000] val_loss: 0.662\n",
      "[2,  4000] loss 0.527\n",
      "[2,  4000] val_loss: 0.731\n",
      "[2,  6000] loss 0.535\n",
      "[2,  6000] val_loss: 0.690\n",
      "[2,  8000] loss 0.514\n",
      "[2,  8000] val_loss: 0.686\n",
      "[2, 10000] loss 0.516\n",
      "[2, 10000] val_loss: 0.676\n",
      "[2, 12000] loss 0.520\n",
      "[2, 12000] val_loss: 0.673\n",
      "[2, 14000] loss 0.536\n",
      "[2, 14000] val_loss: 0.713\n",
      "[2, 16000] loss 0.530\n",
      "[2, 16000] val_loss: 0.690\n",
      "[2, 18000] loss 0.538\n",
      "[2, 18000] val_loss: 0.687\n",
      "[2, 20000] loss 0.533\n",
      "[2, 20000] val_loss: 0.688\n",
      "[2, 22000] loss 0.531\n",
      "[2, 22000] val_loss: 0.709\n",
      "[2, 24000] loss 0.526\n",
      "[2, 24000] val_loss: 0.675\n",
      "[2, 26000] loss 0.528\n",
      "[2, 26000] val_loss: 0.720\n",
      "[2, 28000] loss 0.514\n",
      "[2, 28000] val_loss: 0.670\n",
      "[2, 30000] loss 0.526\n",
      "[2, 30000] val_loss: 0.701\n",
      "[2, 32000] loss 0.516\n",
      "[2, 32000] val_loss: 0.663\n",
      "[2, 34000] loss 0.511\n",
      "[2, 34000] val_loss: 0.698\n",
      "[2, 36000] loss 0.510\n",
      "[2, 36000] val_loss: 0.674\n",
      "Finish Training\n",
      "Accuracy of the network on the 10000 test images: 55 %\n"
     ]
    }
   ],
   "source": [
    "recording = training('base_cnn_focalloss5_lr001',model=base_cnn,loss_function=criterion,optimizer=optimizer,trainloader=trainloader,validationloader=validationloader,validation=True,epochs=2)\n",
    "recording = testing('base_cnn_focalloss5_lr001',model=base_cnn,testloader=testloader,recording=recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "hideOutput": true
   },
   "outputs": [],
   "source": [
    "record=record.append(recording)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN1,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,6,3)#in_channels,Out_channels,kernel_size\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(6,16,3)\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 6 *6)#reshape\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernal 3*3 instead of 5*5\n",
    "cnn = CNN1()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(cnn.parameters(),lr=0.001,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss 2.197\n",
      "[1,  2000] val_loss: 2.028\n",
      "[1,  4000] loss 1.965\n",
      "[1,  4000] val_loss: 2.083\n",
      "[1,  6000] loss 1.849\n",
      "[1,  6000] val_loss: 1.818\n",
      "[1,  8000] loss 1.787\n",
      "[1,  8000] val_loss: 1.741\n",
      "[1, 10000] loss 1.706\n",
      "[1, 10000] val_loss: 1.670\n",
      "[1, 12000] loss 1.645\n",
      "[1, 12000] val_loss: 1.651\n",
      "[1, 14000] loss 1.620\n",
      "[1, 14000] val_loss: 1.687\n",
      "[1, 16000] loss 1.582\n",
      "[1, 16000] val_loss: 1.581\n",
      "[1, 18000] loss 1.559\n",
      "[1, 18000] val_loss: 1.649\n",
      "[1, 20000] loss 1.554\n",
      "[1, 20000] val_loss: 1.579\n",
      "[1, 22000] loss 1.510\n",
      "[1, 22000] val_loss: 1.590\n",
      "[1, 24000] loss 1.499\n",
      "[1, 24000] val_loss: 1.579\n",
      "[1, 26000] loss 1.480\n",
      "[1, 26000] val_loss: 1.676\n",
      "[1, 28000] loss 1.470\n",
      "[1, 28000] val_loss: 1.612\n",
      "[1, 30000] loss 1.456\n",
      "[1, 30000] val_loss: 1.555\n",
      "[1, 32000] loss 1.448\n",
      "[1, 32000] val_loss: 1.550\n",
      "[1, 34000] loss 1.425\n",
      "[1, 34000] val_loss: 1.588\n",
      "[1, 36000] loss 1.429\n",
      "[1, 36000] val_loss: 1.510\n",
      "[2,  2000] loss 1.407\n",
      "[2,  2000] val_loss: 1.526\n",
      "[2,  4000] loss 1.361\n",
      "[2,  4000] val_loss: 1.609\n",
      "[2,  6000] loss 1.390\n",
      "[2,  6000] val_loss: 1.562\n",
      "[2,  8000] loss 1.353\n",
      "[2,  8000] val_loss: 1.527\n",
      "[2, 10000] loss 1.346\n",
      "[2, 10000] val_loss: 1.478\n",
      "[2, 12000] loss 1.349\n",
      "[2, 12000] val_loss: 1.456\n",
      "[2, 14000] loss 1.338\n",
      "[2, 14000] val_loss: 1.492\n",
      "[2, 16000] loss 1.345\n",
      "[2, 16000] val_loss: 1.494\n",
      "[2, 18000] loss 1.331\n",
      "[2, 18000] val_loss: 1.512\n",
      "[2, 20000] loss 1.315\n",
      "[2, 20000] val_loss: 1.512\n",
      "[2, 22000] loss 1.321\n",
      "[2, 22000] val_loss: 1.498\n",
      "[2, 24000] loss 1.295\n",
      "[2, 24000] val_loss: 1.445\n",
      "[2, 26000] loss 1.308\n",
      "[2, 26000] val_loss: 1.495\n",
      "[2, 28000] loss 1.312\n",
      "[2, 28000] val_loss: 1.541\n",
      "[2, 30000] loss 1.262\n",
      "[2, 30000] val_loss: 1.447\n",
      "[2, 32000] loss 1.298\n",
      "[2, 32000] val_loss: 1.465\n",
      "[2, 34000] loss 1.275\n",
      "[2, 34000] val_loss: 1.419\n",
      "[2, 36000] loss 1.297\n",
      "[2, 36000] val_loss: 1.435\n",
      "Finish Training\n",
      "Accuracy of the network on the 10000 test images: 60 %\n"
     ]
    }
   ],
   "source": [
    "recording = training('cnn_kernal_3_3',model=cnn,loss_function=criterion,optimizer=optimizer,trainloader=trainloader,validationloader=validationloader,validation=True,epochs=2)\n",
    "recording = testing('cnn_kernal_3_3',model=cnn,testloader=testloader,recording=recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = record.append(recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN1()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(cnn.parameters(),lr=0.001,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss 2.231\n",
      "[1,  2000] val_loss: 2.110\n",
      "[1,  4000] loss 1.975\n",
      "[1,  4000] val_loss: 1.908\n",
      "[1,  6000] loss 1.850\n",
      "[1,  6000] val_loss: 1.816\n",
      "[1,  8000] loss 1.773\n",
      "[1,  8000] val_loss: 1.764\n",
      "[1, 10000] loss 1.693\n",
      "[1, 10000] val_loss: 1.727\n",
      "[1, 12000] loss 1.653\n",
      "[1, 12000] val_loss: 1.694\n",
      "[1, 14000] loss 1.617\n",
      "[1, 14000] val_loss: 1.716\n",
      "[1, 16000] loss 1.579\n",
      "[1, 16000] val_loss: 1.783\n",
      "[1, 18000] loss 1.564\n",
      "[1, 18000] val_loss: 1.705\n",
      "[1, 20000] loss 1.532\n",
      "[1, 20000] val_loss: 1.700\n",
      "[1, 22000] loss 1.513\n",
      "[1, 22000] val_loss: 1.652\n",
      "[1, 24000] loss 1.490\n",
      "[1, 24000] val_loss: 1.653\n",
      "[1, 26000] loss 1.437\n",
      "[1, 26000] val_loss: 1.603\n",
      "[1, 28000] loss 1.445\n",
      "[1, 28000] val_loss: 1.640\n",
      "[1, 30000] loss 1.433\n",
      "[1, 30000] val_loss: 1.779\n",
      "[1, 32000] loss 1.407\n",
      "[1, 32000] val_loss: 1.638\n",
      "[1, 34000] loss 1.394\n",
      "[1, 34000] val_loss: 1.609\n",
      "[1, 36000] loss 1.376\n",
      "[1, 36000] val_loss: 1.578\n",
      "[2,  2000] loss 1.361\n",
      "[2,  2000] val_loss: 1.543\n",
      "[2,  4000] loss 1.357\n",
      "[2,  4000] val_loss: 1.560\n",
      "[2,  6000] loss 1.349\n",
      "[2,  6000] val_loss: 1.495\n",
      "[2,  8000] loss 1.318\n",
      "[2,  8000] val_loss: 1.575\n",
      "[2, 10000] loss 1.341\n",
      "[2, 10000] val_loss: 1.525\n",
      "[2, 12000] loss 1.322\n",
      "[2, 12000] val_loss: 1.484\n",
      "[2, 14000] loss 1.300\n",
      "[2, 14000] val_loss: 1.430\n",
      "[2, 16000] loss 1.292\n",
      "[2, 16000] val_loss: 1.453\n",
      "[2, 18000] loss 1.302\n",
      "[2, 18000] val_loss: 1.469\n",
      "[2, 20000] loss 1.311\n",
      "[2, 20000] val_loss: 1.517\n",
      "[2, 22000] loss 1.287\n",
      "[2, 22000] val_loss: 1.428\n",
      "[2, 24000] loss 1.290\n",
      "[2, 24000] val_loss: 1.500\n",
      "[2, 26000] loss 1.255\n",
      "[2, 26000] val_loss: 1.496\n",
      "[2, 28000] loss 1.283\n",
      "[2, 28000] val_loss: 1.448\n",
      "[2, 30000] loss 1.265\n",
      "[2, 30000] val_loss: 1.512\n",
      "[2, 32000] loss 1.263\n",
      "[2, 32000] val_loss: 1.482\n",
      "[2, 34000] loss 1.250\n",
      "[2, 34000] val_loss: 1.461\n",
      "[2, 36000] loss 1.257\n",
      "[2, 36000] val_loss: 1.470\n",
      "[3,  2000] loss 1.210\n",
      "[3,  2000] val_loss: 1.488\n",
      "[3,  4000] loss 1.204\n",
      "[3,  4000] val_loss: 1.435\n",
      "[3,  6000] loss 1.227\n",
      "[3,  6000] val_loss: 1.437\n",
      "[3,  8000] loss 1.222\n",
      "[3,  8000] val_loss: 1.437\n",
      "[3, 10000] loss 1.194\n",
      "[3, 10000] val_loss: 1.403\n",
      "[3, 12000] loss 1.217\n",
      "[3, 12000] val_loss: 1.395\n",
      "[3, 14000] loss 1.216\n",
      "[3, 14000] val_loss: 1.404\n",
      "[3, 16000] loss 1.212\n",
      "[3, 16000] val_loss: 1.401\n",
      "[3, 18000] loss 1.190\n",
      "[3, 18000] val_loss: 1.515\n",
      "[3, 20000] loss 1.192\n",
      "[3, 20000] val_loss: 1.420\n",
      "[3, 22000] loss 1.173\n",
      "[3, 22000] val_loss: 1.413\n",
      "[3, 24000] loss 1.180\n",
      "[3, 24000] val_loss: 1.484\n",
      "[3, 26000] loss 1.198\n",
      "[3, 26000] val_loss: 1.422\n",
      "[3, 28000] loss 1.193\n",
      "[3, 28000] val_loss: 1.372\n",
      "[3, 30000] loss 1.190\n",
      "[3, 30000] val_loss: 1.424\n",
      "[3, 32000] loss 1.178\n",
      "[3, 32000] val_loss: 1.387\n",
      "[3, 34000] loss 1.177\n",
      "[3, 34000] val_loss: 1.427\n",
      "[3, 36000] loss 1.192\n",
      "[3, 36000] val_loss: 1.419\n",
      "[4,  2000] loss 1.143\n",
      "[4,  2000] val_loss: 1.396\n",
      "[4,  4000] loss 1.152\n",
      "[4,  4000] val_loss: 1.372\n",
      "[4,  6000] loss 1.130\n",
      "[4,  6000] val_loss: 1.506\n",
      "[4,  8000] loss 1.158\n",
      "[4,  8000] val_loss: 1.421\n",
      "[4, 10000] loss 1.147\n",
      "[4, 10000] val_loss: 1.422\n",
      "[4, 12000] loss 1.146\n",
      "[4, 12000] val_loss: 1.390\n",
      "[4, 14000] loss 1.141\n",
      "[4, 14000] val_loss: 1.399\n",
      "[4, 16000] loss 1.152\n",
      "[4, 16000] val_loss: 1.434\n",
      "[4, 18000] loss 1.172\n",
      "[4, 18000] val_loss: 1.383\n",
      "[4, 20000] loss 1.145\n",
      "[4, 20000] val_loss: 1.397\n",
      "[4, 22000] loss 1.145\n",
      "[4, 22000] val_loss: 1.415\n",
      "[4, 24000] loss 1.135\n",
      "[4, 24000] val_loss: 1.446\n",
      "[4, 26000] loss 1.143\n",
      "[4, 26000] val_loss: 1.383\n",
      "[4, 28000] loss 1.138\n",
      "[4, 28000] val_loss: 1.403\n",
      "[4, 30000] loss 1.133\n",
      "[4, 30000] val_loss: 1.357\n",
      "[4, 32000] loss 1.160\n",
      "[4, 32000] val_loss: 1.396\n",
      "[4, 34000] loss 1.132\n",
      "[4, 34000] val_loss: 1.476\n",
      "[4, 36000] loss 1.127\n",
      "[4, 36000] val_loss: 1.369\n",
      "Finish Training\n",
      "Accuracy of the network on the 10000 test images: 63 %\n"
     ]
    }
   ],
   "source": [
    "recording = training('cnn_kernal_3_3_4epoch',model=cnn,loss_function=criterion,optimizer=optimizer,trainloader=trainloader,validationloader=validationloader,validation=True,epochs=4)\n",
    "recording = testing('cnn_kernal_3_3_4epoch',model=cnn,testloader=testloader,recording=recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = record.append(recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN2,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,16,3)#in_channels,Out_channels,kernel_size\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(16,32,3)\n",
    "        self.fc1 = nn.Linear(32 * 6 * 6, 256)\n",
    "        self.fc2 = nn.Linear(256, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 32 * 6 *6)#reshape\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN2()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(cnn.parameters(),lr=0.001,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss 2.237\n",
      "[1,  2000] val_loss: 2.056\n",
      "[1,  4000] loss 2.004\n",
      "[1,  4000] val_loss: 1.967\n",
      "[1,  6000] loss 1.811\n",
      "[1,  6000] val_loss: 1.793\n",
      "[1,  8000] loss 1.728\n",
      "[1,  8000] val_loss: 1.720\n",
      "[1, 10000] loss 1.668\n",
      "[1, 10000] val_loss: 1.696\n",
      "[1, 12000] loss 1.601\n",
      "[1, 12000] val_loss: 1.622\n",
      "[1, 14000] loss 1.551\n",
      "[1, 14000] val_loss: 1.678\n",
      "[1, 16000] loss 1.489\n",
      "[1, 16000] val_loss: 1.676\n",
      "[1, 18000] loss 1.450\n",
      "[1, 18000] val_loss: 1.575\n",
      "[1, 20000] loss 1.440\n",
      "[1, 20000] val_loss: 1.639\n",
      "[1, 22000] loss 1.402\n",
      "[1, 22000] val_loss: 1.661\n",
      "[1, 24000] loss 1.373\n",
      "[1, 24000] val_loss: 1.570\n",
      "[1, 26000] loss 1.342\n",
      "[1, 26000] val_loss: 1.677\n",
      "[1, 28000] loss 1.341\n",
      "[1, 28000] val_loss: 1.544\n",
      "[1, 30000] loss 1.278\n",
      "[1, 30000] val_loss: 1.533\n",
      "[1, 32000] loss 1.288\n",
      "[1, 32000] val_loss: 1.559\n",
      "[1, 34000] loss 1.252\n",
      "[1, 34000] val_loss: 1.600\n",
      "[1, 36000] loss 1.255\n",
      "[1, 36000] val_loss: 1.443\n",
      "[2,  2000] loss 1.200\n",
      "[2,  2000] val_loss: 1.491\n",
      "[2,  4000] loss 1.205\n",
      "[2,  4000] val_loss: 1.486\n",
      "[2,  6000] loss 1.181\n",
      "[2,  6000] val_loss: 1.540\n",
      "[2,  8000] loss 1.165\n",
      "[2,  8000] val_loss: 1.600\n",
      "[2, 10000] loss 1.160\n",
      "[2, 10000] val_loss: 1.475\n",
      "[2, 12000] loss 1.137\n",
      "[2, 12000] val_loss: 1.573\n",
      "[2, 14000] loss 1.142\n",
      "[2, 14000] val_loss: 1.602\n",
      "[2, 16000] loss 1.136\n",
      "[2, 16000] val_loss: 1.599\n",
      "[2, 18000] loss 1.126\n",
      "[2, 18000] val_loss: 1.565\n",
      "[2, 20000] loss 1.107\n",
      "[2, 20000] val_loss: 1.426\n",
      "[2, 22000] loss 1.105\n",
      "[2, 22000] val_loss: 1.526\n",
      "[2, 24000] loss 1.102\n",
      "[2, 24000] val_loss: 1.593\n",
      "[2, 26000] loss 1.093\n",
      "[2, 26000] val_loss: 1.375\n",
      "[2, 28000] loss 1.096\n",
      "[2, 28000] val_loss: 1.404\n",
      "[2, 30000] loss 1.084\n",
      "[2, 30000] val_loss: 1.490\n",
      "[2, 32000] loss 1.067\n",
      "[2, 32000] val_loss: 1.670\n",
      "[2, 34000] loss 1.040\n",
      "[2, 34000] val_loss: 1.717\n",
      "[2, 36000] loss 1.060\n",
      "[2, 36000] val_loss: 1.495\n",
      "Finish Training\n",
      "Accuracy of the network on the 10000 test images: 67 %\n"
     ]
    }
   ],
   "source": [
    "recording = training('cnn_kernal_3_3_channel_16_2epoch',model=cnn,loss_function=criterion,optimizer=optimizer,trainloader=trainloader,validationloader=validationloader,validation=True,epochs=2)\n",
    "recording = testing('cnn_kernal_3_3_channel_16_2epoch',model=cnn,testloader=testloader,recording=recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = record.append(recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN3,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,6,5)#in_channels,Out_channels,kernel_size\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(6,16,5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128,84)\n",
    "        self.fc4 = nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)#reshape\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN3()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(cnn.parameters(),lr=0.001,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss 2.299\n",
      "[1,  2000] val_loss: 2.279\n",
      "[1,  4000] loss 2.109\n",
      "[1,  4000] val_loss: 1.987\n",
      "[1,  6000] loss 1.943\n",
      "[1,  6000] val_loss: 1.867\n",
      "[1,  8000] loss 1.848\n",
      "[1,  8000] val_loss: 1.819\n",
      "[1, 10000] loss 1.784\n",
      "[1, 10000] val_loss: 1.794\n",
      "[1, 12000] loss 1.727\n",
      "[1, 12000] val_loss: 1.728\n",
      "[1, 14000] loss 1.685\n",
      "[1, 14000] val_loss: 1.729\n",
      "[1, 16000] loss 1.654\n",
      "[1, 16000] val_loss: 1.791\n",
      "[1, 18000] loss 1.612\n",
      "[1, 18000] val_loss: 1.720\n",
      "[1, 20000] loss 1.597\n",
      "[1, 20000] val_loss: 1.708\n",
      "[1, 22000] loss 1.586\n",
      "[1, 22000] val_loss: 1.774\n",
      "[1, 24000] loss 1.548\n",
      "[1, 24000] val_loss: 1.649\n",
      "[1, 26000] loss 1.526\n",
      "[1, 26000] val_loss: 1.716\n",
      "[1, 28000] loss 1.550\n",
      "[1, 28000] val_loss: 1.655\n",
      "[1, 30000] loss 1.500\n",
      "[1, 30000] val_loss: 1.656\n",
      "[1, 32000] loss 1.490\n",
      "[1, 32000] val_loss: 1.774\n",
      "[1, 34000] loss 1.489\n",
      "[1, 34000] val_loss: 1.706\n",
      "[1, 36000] loss 1.476\n",
      "[1, 36000] val_loss: 1.646\n",
      "[2,  2000] loss 1.431\n",
      "[2,  2000] val_loss: 1.679\n",
      "[2,  4000] loss 1.441\n",
      "[2,  4000] val_loss: 1.603\n",
      "[2,  6000] loss 1.395\n",
      "[2,  6000] val_loss: 1.612\n",
      "[2,  8000] loss 1.432\n",
      "[2,  8000] val_loss: 1.636\n",
      "[2, 10000] loss 1.385\n",
      "[2, 10000] val_loss: 1.578\n",
      "[2, 12000] loss 1.386\n",
      "[2, 12000] val_loss: 1.634\n",
      "[2, 14000] loss 1.411\n",
      "[2, 14000] val_loss: 1.650\n",
      "[2, 16000] loss 1.376\n",
      "[2, 16000] val_loss: 1.655\n",
      "[2, 18000] loss 1.372\n",
      "[2, 18000] val_loss: 1.691\n",
      "[2, 20000] loss 1.359\n",
      "[2, 20000] val_loss: 1.634\n",
      "[2, 22000] loss 1.366\n",
      "[2, 22000] val_loss: 1.634\n",
      "[2, 24000] loss 1.339\n",
      "[2, 24000] val_loss: 1.565\n",
      "[2, 26000] loss 1.337\n",
      "[2, 26000] val_loss: 1.577\n",
      "[2, 28000] loss 1.321\n",
      "[2, 28000] val_loss: 1.652\n",
      "[2, 30000] loss 1.324\n",
      "[2, 30000] val_loss: 1.587\n",
      "[2, 32000] loss 1.299\n",
      "[2, 32000] val_loss: 1.591\n",
      "[2, 34000] loss 1.328\n",
      "[2, 34000] val_loss: 1.640\n",
      "[2, 36000] loss 1.283\n",
      "[2, 36000] val_loss: 1.617\n",
      "Finish Training\n",
      "Accuracy of the network on the 10000 test images: 60 %\n"
     ]
    }
   ],
   "source": [
    "recording = training('cnn_kernal_5_5_4dense_2epoch',model=cnn,loss_function=criterion,optimizer=optimizer,trainloader=trainloader,validationloader=validationloader,validation=True,epochs=2)\n",
    "recording = testing('cnn_kernal_5_5_4dense_2epoch',model=cnn,testloader=testloader,recording=recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = record.append(recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN2()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(cnn.parameters(),lr=0.001,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss 2.217\n",
      "[1,  2000] val_loss: 2.061\n",
      "[1,  4000] loss 1.949\n",
      "[1,  4000] val_loss: 1.860\n",
      "[1,  6000] loss 1.793\n",
      "[1,  6000] val_loss: 1.799\n",
      "[1,  8000] loss 1.728\n",
      "[1,  8000] val_loss: 1.701\n",
      "[1, 10000] loss 1.658\n",
      "[1, 10000] val_loss: 1.673\n",
      "[1, 12000] loss 1.601\n",
      "[1, 12000] val_loss: 1.635\n",
      "[1, 14000] loss 1.566\n",
      "[1, 14000] val_loss: 1.628\n",
      "[1, 16000] loss 1.510\n",
      "[1, 16000] val_loss: 1.668\n",
      "[1, 18000] loss 1.490\n",
      "[1, 18000] val_loss: 1.610\n",
      "[1, 20000] loss 1.448\n",
      "[1, 20000] val_loss: 1.593\n",
      "[1, 22000] loss 1.439\n",
      "[1, 22000] val_loss: 1.521\n",
      "[1, 24000] loss 1.382\n",
      "[1, 24000] val_loss: 1.524\n",
      "[1, 26000] loss 1.341\n",
      "[1, 26000] val_loss: 1.554\n",
      "[1, 28000] loss 1.349\n",
      "[1, 28000] val_loss: 1.482\n",
      "[1, 30000] loss 1.305\n",
      "[1, 30000] val_loss: 1.493\n",
      "[1, 32000] loss 1.276\n",
      "[1, 32000] val_loss: 1.426\n",
      "[1, 34000] loss 1.267\n",
      "[1, 34000] val_loss: 1.491\n",
      "[1, 36000] loss 1.245\n",
      "[1, 36000] val_loss: 1.438\n",
      "[2,  2000] loss 1.211\n",
      "[2,  2000] val_loss: 1.479\n",
      "[2,  4000] loss 1.222\n",
      "[2,  4000] val_loss: 1.518\n",
      "[2,  6000] loss 1.200\n",
      "[2,  6000] val_loss: 1.553\n",
      "[2,  8000] loss 1.195\n",
      "[2,  8000] val_loss: 1.369\n",
      "[2, 10000] loss 1.173\n",
      "[2, 10000] val_loss: 1.430\n",
      "[2, 12000] loss 1.141\n",
      "[2, 12000] val_loss: 1.408\n",
      "[2, 14000] loss 1.159\n",
      "[2, 14000] val_loss: 1.387\n",
      "[2, 16000] loss 1.144\n",
      "[2, 16000] val_loss: 1.458\n",
      "[2, 18000] loss 1.142\n",
      "[2, 18000] val_loss: 1.439\n",
      "[2, 20000] loss 1.119\n",
      "[2, 20000] val_loss: 1.332\n",
      "[2, 22000] loss 1.116\n",
      "[2, 22000] val_loss: 1.377\n",
      "[2, 24000] loss 1.108\n",
      "[2, 24000] val_loss: 1.398\n",
      "[2, 26000] loss 1.100\n",
      "[2, 26000] val_loss: 1.426\n",
      "[2, 28000] loss 1.102\n",
      "[2, 28000] val_loss: 1.459\n",
      "[2, 30000] loss 1.085\n",
      "[2, 30000] val_loss: 1.305\n",
      "[2, 32000] loss 1.108\n",
      "[2, 32000] val_loss: 1.360\n",
      "[2, 34000] loss 1.082\n",
      "[2, 34000] val_loss: 1.345\n",
      "[2, 36000] loss 1.063\n",
      "[2, 36000] val_loss: 1.332\n",
      "[3,  2000] loss 1.004\n",
      "[3,  2000] val_loss: 1.382\n",
      "[3,  4000] loss 1.027\n",
      "[3,  4000] val_loss: 1.403\n",
      "[3,  6000] loss 1.031\n",
      "[3,  6000] val_loss: 1.355\n",
      "[3,  8000] loss 1.000\n",
      "[3,  8000] val_loss: 1.453\n",
      "[3, 10000] loss 1.009\n",
      "[3, 10000] val_loss: 1.339\n",
      "[3, 12000] loss 1.011\n",
      "[3, 12000] val_loss: 1.322\n",
      "[3, 14000] loss 1.000\n",
      "[3, 14000] val_loss: 1.340\n",
      "[3, 16000] loss 1.017\n",
      "[3, 16000] val_loss: 1.333\n",
      "[3, 18000] loss 0.980\n",
      "[3, 18000] val_loss: 1.365\n",
      "[3, 20000] loss 1.022\n",
      "[3, 20000] val_loss: 1.272\n",
      "[3, 22000] loss 0.984\n",
      "[3, 22000] val_loss: 1.362\n",
      "[3, 24000] loss 1.002\n",
      "[3, 24000] val_loss: 1.414\n",
      "[3, 26000] loss 0.979\n",
      "[3, 26000] val_loss: 1.332\n",
      "[3, 28000] loss 0.968\n",
      "[3, 28000] val_loss: 1.357\n",
      "[3, 30000] loss 0.978\n",
      "[3, 30000] val_loss: 1.349\n",
      "[3, 32000] loss 0.957\n",
      "[3, 32000] val_loss: 1.294\n",
      "[3, 34000] loss 0.950\n",
      "[3, 34000] val_loss: 1.344\n",
      "[3, 36000] loss 0.965\n",
      "[3, 36000] val_loss: 1.464\n",
      "[4,  2000] loss 0.916\n",
      "[4,  2000] val_loss: 1.392\n",
      "[4,  4000] loss 0.910\n",
      "[4,  4000] val_loss: 1.297\n",
      "[4,  6000] loss 0.904\n",
      "[4,  6000] val_loss: 1.294\n",
      "[4,  8000] loss 0.922\n",
      "[4,  8000] val_loss: 1.296\n",
      "[4, 10000] loss 0.936\n",
      "[4, 10000] val_loss: 1.303\n",
      "[4, 12000] loss 0.922\n",
      "[4, 12000] val_loss: 1.318\n",
      "[4, 14000] loss 0.916\n",
      "[4, 14000] val_loss: 1.419\n",
      "[4, 16000] loss 0.902\n",
      "[4, 16000] val_loss: 1.271\n",
      "[4, 18000] loss 0.911\n",
      "[4, 18000] val_loss: 1.276\n",
      "[4, 20000] loss 0.908\n",
      "[4, 20000] val_loss: 1.287\n",
      "[4, 22000] loss 0.898\n",
      "[4, 22000] val_loss: 1.329\n",
      "[4, 24000] loss 0.907\n",
      "[4, 24000] val_loss: 1.279\n",
      "[4, 26000] loss 0.892\n",
      "[4, 26000] val_loss: 1.381\n",
      "[4, 28000] loss 0.903\n",
      "[4, 28000] val_loss: 1.342\n",
      "[4, 30000] loss 0.898\n",
      "[4, 30000] val_loss: 1.293\n",
      "[4, 32000] loss 0.922\n",
      "[4, 32000] val_loss: 1.288\n",
      "[4, 34000] loss 0.891\n",
      "[4, 34000] val_loss: 1.342\n",
      "[4, 36000] loss 0.872\n",
      "[4, 36000] val_loss: 1.312\n",
      "Finish Training\n",
      "Accuracy of the network on the 10000 test images: 70 %\n"
     ]
    }
   ],
   "source": [
    "#3*3kernal\n",
    "recording = training('cnn_kernal_5_5_4dense_4epoch',model=cnn,loss_function=criterion,optimizer=optimizer,trainloader=trainloader,validationloader=validationloader,validation=True,epochs=4)\n",
    "recording = testing('cnn_kernal_5_5_4dense_4epoch',model=cnn,testloader=testloader,recording=recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = record.append(recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experience</th>\n",
       "      <th>train</th>\n",
       "      <th>epoch</th>\n",
       "      <th>itrs</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>2.216621</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>2.060538</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4000</td>\n",
       "      <td>1.948544</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4000</td>\n",
       "      <td>1.859651</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6000</td>\n",
       "      <td>1.792599</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6000</td>\n",
       "      <td>1.799055</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8000</td>\n",
       "      <td>1.727922</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8000</td>\n",
       "      <td>1.700664</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.658381</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.672770</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12000</td>\n",
       "      <td>1.600563</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12000</td>\n",
       "      <td>1.635130</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14000</td>\n",
       "      <td>1.565857</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14000</td>\n",
       "      <td>1.627682</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16000</td>\n",
       "      <td>1.510127</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16000</td>\n",
       "      <td>1.667776</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18000</td>\n",
       "      <td>1.490284</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18000</td>\n",
       "      <td>1.609906</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20000</td>\n",
       "      <td>1.447582</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20000</td>\n",
       "      <td>1.593307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22000</td>\n",
       "      <td>1.439247</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22000</td>\n",
       "      <td>1.520754</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24000</td>\n",
       "      <td>1.381702</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24000</td>\n",
       "      <td>1.523847</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26000</td>\n",
       "      <td>1.340960</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26000</td>\n",
       "      <td>1.554098</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28000</td>\n",
       "      <td>1.349334</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28000</td>\n",
       "      <td>1.481779</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30000</td>\n",
       "      <td>1.304694</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30000</td>\n",
       "      <td>1.492743</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8000</td>\n",
       "      <td>1.296214</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.936403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.303041</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12000</td>\n",
       "      <td>0.921876</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>12000</td>\n",
       "      <td>1.317650</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>14000</td>\n",
       "      <td>0.916088</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>14000</td>\n",
       "      <td>1.419268</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>16000</td>\n",
       "      <td>0.902080</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>16000</td>\n",
       "      <td>1.271064</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>18000</td>\n",
       "      <td>0.911378</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>18000</td>\n",
       "      <td>1.275888</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.907806</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>20000</td>\n",
       "      <td>1.287139</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>22000</td>\n",
       "      <td>0.898090</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>22000</td>\n",
       "      <td>1.329379</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>24000</td>\n",
       "      <td>0.906648</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>24000</td>\n",
       "      <td>1.279277</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>26000</td>\n",
       "      <td>0.891624</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>26000</td>\n",
       "      <td>1.380691</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>28000</td>\n",
       "      <td>0.902877</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>28000</td>\n",
       "      <td>1.342315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>30000</td>\n",
       "      <td>0.898336</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>30000</td>\n",
       "      <td>1.293099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>32000</td>\n",
       "      <td>0.922345</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>32000</td>\n",
       "      <td>1.288079</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>34000</td>\n",
       "      <td>0.891033</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>34000</td>\n",
       "      <td>1.341836</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>36000</td>\n",
       "      <td>0.871922</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>36000</td>\n",
       "      <td>1.311534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>cnn_kernal_5_5_4dense_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>70.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       experience train epoch   itrs      loss accuracy\n",
       "0    cnn_kernal_5_5_4dense_4epoch     0     1   2000  2.216621        0\n",
       "1    cnn_kernal_5_5_4dense_4epoch     1     1   2000  2.060538        0\n",
       "2    cnn_kernal_5_5_4dense_4epoch     0     1   4000  1.948544        0\n",
       "3    cnn_kernal_5_5_4dense_4epoch     1     1   4000  1.859651        0\n",
       "4    cnn_kernal_5_5_4dense_4epoch     0     1   6000  1.792599        0\n",
       "5    cnn_kernal_5_5_4dense_4epoch     1     1   6000  1.799055        0\n",
       "6    cnn_kernal_5_5_4dense_4epoch     0     1   8000  1.727922        0\n",
       "7    cnn_kernal_5_5_4dense_4epoch     1     1   8000  1.700664        0\n",
       "8    cnn_kernal_5_5_4dense_4epoch     0     1  10000  1.658381        0\n",
       "9    cnn_kernal_5_5_4dense_4epoch     1     1  10000  1.672770        0\n",
       "10   cnn_kernal_5_5_4dense_4epoch     0     1  12000  1.600563        0\n",
       "11   cnn_kernal_5_5_4dense_4epoch     1     1  12000  1.635130        0\n",
       "12   cnn_kernal_5_5_4dense_4epoch     0     1  14000  1.565857        0\n",
       "13   cnn_kernal_5_5_4dense_4epoch     1     1  14000  1.627682        0\n",
       "14   cnn_kernal_5_5_4dense_4epoch     0     1  16000  1.510127        0\n",
       "15   cnn_kernal_5_5_4dense_4epoch     1     1  16000  1.667776        0\n",
       "16   cnn_kernal_5_5_4dense_4epoch     0     1  18000  1.490284        0\n",
       "17   cnn_kernal_5_5_4dense_4epoch     1     1  18000  1.609906        0\n",
       "18   cnn_kernal_5_5_4dense_4epoch     0     1  20000  1.447582        0\n",
       "19   cnn_kernal_5_5_4dense_4epoch     1     1  20000  1.593307        0\n",
       "20   cnn_kernal_5_5_4dense_4epoch     0     1  22000  1.439247        0\n",
       "21   cnn_kernal_5_5_4dense_4epoch     1     1  22000  1.520754        0\n",
       "22   cnn_kernal_5_5_4dense_4epoch     0     1  24000  1.381702        0\n",
       "23   cnn_kernal_5_5_4dense_4epoch     1     1  24000  1.523847        0\n",
       "24   cnn_kernal_5_5_4dense_4epoch     0     1  26000  1.340960        0\n",
       "25   cnn_kernal_5_5_4dense_4epoch     1     1  26000  1.554098        0\n",
       "26   cnn_kernal_5_5_4dense_4epoch     0     1  28000  1.349334        0\n",
       "27   cnn_kernal_5_5_4dense_4epoch     1     1  28000  1.481779        0\n",
       "28   cnn_kernal_5_5_4dense_4epoch     0     1  30000  1.304694        0\n",
       "29   cnn_kernal_5_5_4dense_4epoch     1     1  30000  1.492743        0\n",
       "..                            ...   ...   ...    ...       ...      ...\n",
       "115  cnn_kernal_5_5_4dense_4epoch     1     4   8000  1.296214        0\n",
       "116  cnn_kernal_5_5_4dense_4epoch     0     4  10000  0.936403        0\n",
       "117  cnn_kernal_5_5_4dense_4epoch     1     4  10000  1.303041        0\n",
       "118  cnn_kernal_5_5_4dense_4epoch     0     4  12000  0.921876        0\n",
       "119  cnn_kernal_5_5_4dense_4epoch     1     4  12000  1.317650        0\n",
       "120  cnn_kernal_5_5_4dense_4epoch     0     4  14000  0.916088        0\n",
       "121  cnn_kernal_5_5_4dense_4epoch     1     4  14000  1.419268        0\n",
       "122  cnn_kernal_5_5_4dense_4epoch     0     4  16000  0.902080        0\n",
       "123  cnn_kernal_5_5_4dense_4epoch     1     4  16000  1.271064        0\n",
       "124  cnn_kernal_5_5_4dense_4epoch     0     4  18000  0.911378        0\n",
       "125  cnn_kernal_5_5_4dense_4epoch     1     4  18000  1.275888        0\n",
       "126  cnn_kernal_5_5_4dense_4epoch     0     4  20000  0.907806        0\n",
       "127  cnn_kernal_5_5_4dense_4epoch     1     4  20000  1.287139        0\n",
       "128  cnn_kernal_5_5_4dense_4epoch     0     4  22000  0.898090        0\n",
       "129  cnn_kernal_5_5_4dense_4epoch     1     4  22000  1.329379        0\n",
       "130  cnn_kernal_5_5_4dense_4epoch     0     4  24000  0.906648        0\n",
       "131  cnn_kernal_5_5_4dense_4epoch     1     4  24000  1.279277        0\n",
       "132  cnn_kernal_5_5_4dense_4epoch     0     4  26000  0.891624        0\n",
       "133  cnn_kernal_5_5_4dense_4epoch     1     4  26000  1.380691        0\n",
       "134  cnn_kernal_5_5_4dense_4epoch     0     4  28000  0.902877        0\n",
       "135  cnn_kernal_5_5_4dense_4epoch     1     4  28000  1.342315        0\n",
       "136  cnn_kernal_5_5_4dense_4epoch     0     4  30000  0.898336        0\n",
       "137  cnn_kernal_5_5_4dense_4epoch     1     4  30000  1.293099        0\n",
       "138  cnn_kernal_5_5_4dense_4epoch     0     4  32000  0.922345        0\n",
       "139  cnn_kernal_5_5_4dense_4epoch     1     4  32000  1.288079        0\n",
       "140  cnn_kernal_5_5_4dense_4epoch     0     4  34000  0.891033        0\n",
       "141  cnn_kernal_5_5_4dense_4epoch     1     4  34000  1.341836        0\n",
       "142  cnn_kernal_5_5_4dense_4epoch     0     4  36000  0.871922        0\n",
       "143  cnn_kernal_5_5_4dense_4epoch     1     4  36000  1.311534        0\n",
       "144  cnn_kernal_5_5_4dense_4epoch     0     0      0  0.000000    70.89\n",
       "\n",
       "[145 rows x 6 columns]"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN4,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,16,3)#in_channels,Out_channels,kernel_size\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(16,32,3)\n",
    "        self.fc1 = nn.Linear(32 * 6 * 6, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128,84)\n",
    "        self.fc4 = nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 32 * 6 *6)#reshape\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN4()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(cnn.parameters(),lr=0.001,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss 2.292\n",
      "[1,  2000] val_loss: 2.233\n",
      "[1,  4000] loss 2.114\n",
      "[1,  4000] val_loss: 2.023\n",
      "[1,  6000] loss 1.971\n",
      "[1,  6000] val_loss: 1.962\n",
      "[1,  8000] loss 1.837\n",
      "[1,  8000] val_loss: 1.862\n",
      "[1, 10000] loss 1.752\n",
      "[1, 10000] val_loss: 1.767\n",
      "[1, 12000] loss 1.644\n",
      "[1, 12000] val_loss: 1.640\n",
      "[1, 14000] loss 1.588\n",
      "[1, 14000] val_loss: 1.673\n",
      "[1, 16000] loss 1.530\n",
      "[1, 16000] val_loss: 1.699\n",
      "[1, 18000] loss 1.510\n",
      "[1, 18000] val_loss: 1.609\n",
      "[1, 20000] loss 1.471\n",
      "[1, 20000] val_loss: 1.558\n",
      "[1, 22000] loss 1.427\n",
      "[1, 22000] val_loss: 1.591\n",
      "[1, 24000] loss 1.413\n",
      "[1, 24000] val_loss: 1.661\n",
      "[1, 26000] loss 1.350\n",
      "[1, 26000] val_loss: 1.583\n",
      "[1, 28000] loss 1.353\n",
      "[1, 28000] val_loss: 1.528\n",
      "[1, 30000] loss 1.314\n",
      "[1, 30000] val_loss: 1.541\n",
      "[1, 32000] loss 1.296\n",
      "[1, 32000] val_loss: 1.568\n",
      "[1, 34000] loss 1.256\n",
      "[1, 34000] val_loss: 1.525\n",
      "[1, 36000] loss 1.277\n",
      "[1, 36000] val_loss: 1.462\n",
      "[2,  2000] loss 1.208\n",
      "[2,  2000] val_loss: 1.461\n",
      "[2,  4000] loss 1.203\n",
      "[2,  4000] val_loss: 1.458\n",
      "[2,  6000] loss 1.208\n",
      "[2,  6000] val_loss: 1.395\n",
      "[2,  8000] loss 1.173\n",
      "[2,  8000] val_loss: 1.418\n",
      "[2, 10000] loss 1.163\n",
      "[2, 10000] val_loss: 1.375\n",
      "[2, 12000] loss 1.154\n",
      "[2, 12000] val_loss: 1.384\n",
      "[2, 14000] loss 1.136\n",
      "[2, 14000] val_loss: 1.382\n",
      "[2, 16000] loss 1.134\n",
      "[2, 16000] val_loss: 1.384\n",
      "[2, 18000] loss 1.109\n",
      "[2, 18000] val_loss: 1.353\n",
      "[2, 20000] loss 1.087\n",
      "[2, 20000] val_loss: 1.351\n",
      "[2, 22000] loss 1.085\n",
      "[2, 22000] val_loss: 1.321\n",
      "[2, 24000] loss 1.090\n",
      "[2, 24000] val_loss: 1.416\n",
      "[2, 26000] loss 1.074\n",
      "[2, 26000] val_loss: 1.358\n",
      "[2, 28000] loss 1.072\n",
      "[2, 28000] val_loss: 1.378\n",
      "[2, 30000] loss 1.065\n",
      "[2, 30000] val_loss: 1.324\n",
      "[2, 32000] loss 1.055\n",
      "[2, 32000] val_loss: 1.279\n",
      "[2, 34000] loss 1.026\n",
      "[2, 34000] val_loss: 1.268\n",
      "[2, 36000] loss 1.036\n",
      "[2, 36000] val_loss: 1.398\n",
      "[3,  2000] loss 0.957\n",
      "[3,  2000] val_loss: 1.409\n",
      "[3,  4000] loss 1.003\n",
      "[3,  4000] val_loss: 1.299\n",
      "[3,  6000] loss 0.934\n",
      "[3,  6000] val_loss: 1.380\n",
      "[3,  8000] loss 0.961\n",
      "[3,  8000] val_loss: 1.323\n",
      "[3, 10000] loss 0.956\n",
      "[3, 10000] val_loss: 1.266\n",
      "[3, 12000] loss 0.968\n",
      "[3, 12000] val_loss: 1.335\n",
      "[3, 14000] loss 0.968\n",
      "[3, 14000] val_loss: 1.322\n",
      "[3, 16000] loss 0.972\n",
      "[3, 16000] val_loss: 1.257\n",
      "[3, 18000] loss 0.965\n",
      "[3, 18000] val_loss: 1.251\n",
      "[3, 20000] loss 0.937\n",
      "[3, 20000] val_loss: 1.300\n",
      "[3, 22000] loss 0.961\n",
      "[3, 22000] val_loss: 1.306\n",
      "[3, 24000] loss 0.947\n",
      "[3, 24000] val_loss: 1.276\n",
      "[3, 26000] loss 0.924\n",
      "[3, 26000] val_loss: 1.286\n",
      "[3, 28000] loss 0.931\n",
      "[3, 28000] val_loss: 1.327\n",
      "[3, 30000] loss 0.922\n",
      "[3, 30000] val_loss: 1.271\n",
      "[3, 32000] loss 0.936\n",
      "[3, 32000] val_loss: 1.252\n",
      "[3, 34000] loss 0.912\n",
      "[3, 34000] val_loss: 1.193\n",
      "[3, 36000] loss 0.912\n",
      "[3, 36000] val_loss: 1.260\n",
      "[4,  2000] loss 0.874\n",
      "[4,  2000] val_loss: 1.238\n",
      "[4,  4000] loss 0.848\n",
      "[4,  4000] val_loss: 1.297\n",
      "[4,  6000] loss 0.844\n",
      "[4,  6000] val_loss: 1.268\n",
      "[4,  8000] loss 0.875\n",
      "[4,  8000] val_loss: 1.211\n",
      "[4, 10000] loss 0.841\n",
      "[4, 10000] val_loss: 1.260\n",
      "[4, 12000] loss 0.856\n",
      "[4, 12000] val_loss: 1.270\n",
      "[4, 14000] loss 0.871\n",
      "[4, 14000] val_loss: 1.294\n",
      "[4, 16000] loss 0.842\n",
      "[4, 16000] val_loss: 1.351\n",
      "[4, 18000] loss 0.835\n",
      "[4, 18000] val_loss: 1.318\n",
      "[4, 20000] loss 0.837\n",
      "[4, 20000] val_loss: 1.379\n",
      "[4, 22000] loss 0.848\n",
      "[4, 22000] val_loss: 1.291\n",
      "[4, 24000] loss 0.842\n",
      "[4, 24000] val_loss: 1.323\n",
      "[4, 26000] loss 0.847\n",
      "[4, 26000] val_loss: 1.364\n",
      "[4, 28000] loss 0.820\n",
      "[4, 28000] val_loss: 1.291\n",
      "[4, 30000] loss 0.838\n",
      "[4, 30000] val_loss: 1.293\n",
      "[4, 32000] loss 0.821\n",
      "[4, 32000] val_loss: 1.214\n",
      "[4, 34000] loss 0.850\n",
      "[4, 34000] val_loss: 1.243\n",
      "[4, 36000] loss 0.827\n",
      "[4, 36000] val_loss: 1.248\n",
      "Finish Training\n",
      "Accuracy of the network on the 10000 test images: 73 %\n"
     ]
    }
   ],
   "source": [
    "recording = training('cnn_kernal_3_3_4dense_16channel_4epoch',model=cnn,loss_function=criterion,optimizer=optimizer,trainloader=trainloader,validationloader=validationloader,validation=True,epochs=4)\n",
    "recording = testing('cnn_kernal_3_3_4dense_16channel_4epoch',model=cnn,testloader=testloader,recording=recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = record.append(recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN5,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,6,5)#in_channels,Out_channels,kernel_size\n",
    "        self.bnc1 = nn.BatchNorm2d(6)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(6,16,5)\n",
    "        self.bnc2 = nn.BatchNorm2d(16)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 256)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.fc3 = nn.Linear(128,84)\n",
    "        self.bn3 = nn.BatchNorm1d(84)\n",
    "        self.fc4 = nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.bnc1(F.relu(self.conv1(x))))\n",
    "        x = self.pool(self.bnc2(F.relu(self.conv2(x))))\n",
    "        x = x.view(-1, 16 * 5 *5)#reshape\n",
    "        x = self.bn1(F.relu(self.fc1(x)))\n",
    "        x = self.bn2(F.relu(self.fc2(x)))\n",
    "        x = self.bn3(F.relu(self.fc3(x)))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN5()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(cnn.parameters(),lr=0.001,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss 2.179\n",
      "[1,  2000] val_loss: 2.064\n",
      "[1,  4000] loss 2.122\n",
      "[1,  4000] val_loss: 2.022\n",
      "[1,  6000] loss 2.089\n",
      "[1,  6000] val_loss: 1.941\n",
      "[1,  8000] loss 2.058\n",
      "[1,  8000] val_loss: 1.928\n",
      "[1, 10000] loss 2.020\n",
      "[1, 10000] val_loss: 1.987\n",
      "[1, 12000] loss 2.056\n",
      "[1, 12000] val_loss: 1.933\n",
      "[1, 14000] loss 2.031\n",
      "[1, 14000] val_loss: 1.929\n",
      "[1, 16000] loss 2.023\n",
      "[1, 16000] val_loss: 1.906\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-518-76c1ef6e45e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrecording\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cnn_kernal_5_5_4dense_batchnorm_all_relu_2epoch'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidationloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidationloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrecording\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtesting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cnn_kernal_5_5_4dense_batchnorm_all_relu_2epoch'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrecording\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecording\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-247-982648f0f6eb>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(experiment, model, loss_function, optimizer, trainloader, validationloader, validation, epochs)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/LuyiSHENX/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/LuyiSHENX/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "recording = training('cnn_kernal_5_5_4dense_batchnorm_all_relu_2epoch',model=cnn,loss_function=criterion,optimizer=optimizer,trainloader=trainloader,validationloader=validationloader,validation=True,epochs=2)\n",
    "recording = testing('cnn_kernal_5_5_4dense_batchnorm_all_relu_2epoch',model=cnn,testloader=testloader,recording=recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = record.append(recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN6(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN6,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,16,3)#in_channels,Out_channels,kernel_size\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(16,32,3)\n",
    "        self.fc1 = nn.Linear(32 * 6 * 6, 512)\n",
    "        self.dp = nn.Dropout(0.2)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128,84)\n",
    "        self.fc4 = nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 32 * 6 *6)#reshape\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dp(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dp(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.dp(x)\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN6()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(cnn.parameters(),lr=0.001,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss 2.300\n",
      "[1,  2000] val_loss: 2.290\n",
      "[1,  4000] loss 2.153\n",
      "[1,  4000] val_loss: 2.019\n",
      "[1,  6000] loss 1.944\n",
      "[1,  6000] val_loss: 1.938\n",
      "[1,  8000] loss 1.816\n",
      "[1,  8000] val_loss: 1.792\n",
      "[1, 10000] loss 1.749\n",
      "[1, 10000] val_loss: 1.718\n",
      "[1, 12000] loss 1.663\n",
      "[1, 12000] val_loss: 1.709\n",
      "[1, 14000] loss 1.634\n",
      "[1, 14000] val_loss: 1.632\n",
      "[1, 16000] loss 1.566\n",
      "[1, 16000] val_loss: 1.685\n",
      "[1, 18000] loss 1.543\n",
      "[1, 18000] val_loss: 1.661\n",
      "[1, 20000] loss 1.493\n",
      "[1, 20000] val_loss: 1.639\n",
      "[1, 22000] loss 1.447\n",
      "[1, 22000] val_loss: 1.576\n",
      "[1, 24000] loss 1.446\n",
      "[1, 24000] val_loss: 1.548\n",
      "[1, 26000] loss 1.393\n",
      "[1, 26000] val_loss: 1.614\n",
      "[1, 28000] loss 1.381\n",
      "[1, 28000] val_loss: 1.636\n",
      "[1, 30000] loss 1.338\n",
      "[1, 30000] val_loss: 1.675\n",
      "[1, 32000] loss 1.336\n",
      "[1, 32000] val_loss: 1.516\n",
      "[1, 34000] loss 1.322\n",
      "[1, 34000] val_loss: 1.505\n",
      "[1, 36000] loss 1.292\n",
      "[1, 36000] val_loss: 1.518\n",
      "[2,  2000] loss 1.239\n",
      "[2,  2000] val_loss: 1.584\n",
      "[2,  4000] loss 1.231\n",
      "[2,  4000] val_loss: 1.579\n",
      "[2,  6000] loss 1.224\n",
      "[2,  6000] val_loss: 1.527\n",
      "[2,  8000] loss 1.188\n",
      "[2,  8000] val_loss: 1.537\n",
      "[2, 10000] loss 1.207\n",
      "[2, 10000] val_loss: 1.569\n",
      "[2, 12000] loss 1.186\n",
      "[2, 12000] val_loss: 1.518\n",
      "[2, 14000] loss 1.161\n",
      "[2, 14000] val_loss: 1.486\n",
      "[2, 16000] loss 1.158\n",
      "[2, 16000] val_loss: 1.579\n",
      "[2, 18000] loss 1.150\n",
      "[2, 18000] val_loss: 1.464\n",
      "[2, 20000] loss 1.123\n",
      "[2, 20000] val_loss: 1.411\n",
      "[2, 22000] loss 1.124\n",
      "[2, 22000] val_loss: 1.410\n",
      "[2, 24000] loss 1.104\n",
      "[2, 24000] val_loss: 1.393\n",
      "[2, 26000] loss 1.102\n",
      "[2, 26000] val_loss: 1.400\n",
      "[2, 28000] loss 1.106\n",
      "[2, 28000] val_loss: 1.408\n",
      "[2, 30000] loss 1.087\n",
      "[2, 30000] val_loss: 1.426\n",
      "[2, 32000] loss 1.106\n",
      "[2, 32000] val_loss: 1.489\n",
      "[2, 34000] loss 1.049\n",
      "[2, 34000] val_loss: 1.385\n",
      "[2, 36000] loss 1.071\n",
      "[2, 36000] val_loss: 1.381\n",
      "Finish Training\n",
      "Accuracy of the network on the 10000 test images: 67 %\n"
     ]
    }
   ],
   "source": [
    "recording = training('cnn_kernal_3_3_4dense_16channel_2epoch',model=cnn,loss_function=criterion,optimizer=optimizer,trainloader=trainloader,validationloader=validationloader,validation=True,epochs=2)\n",
    "recording = testing('cnn_kernal_3_3_4dense_16channel_2epoch',model=cnn,testloader=testloader,recording=recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = record.append(recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN6(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN6,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,16,3)#in_channels,Out_channels,kernel_size\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(16,32,3)\n",
    "        self.fc1 = nn.Linear(32 * 6 * 6, 512)\n",
    "        self.dp = nn.Dropout(0.1)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128,84)\n",
    "        self.fc4 = nn.Linear(84, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 32 * 6 *6)#reshape\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dp(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dp(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.dp(x)\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN6()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(cnn.parameters(),lr=0.001,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss 2.269\n",
      "[1,  2000] val_loss: 2.109\n",
      "[1,  4000] loss 2.053\n",
      "[1,  4000] val_loss: 1.951\n",
      "[1,  6000] loss 1.907\n",
      "[1,  6000] val_loss: 1.885\n",
      "[1,  8000] loss 1.788\n",
      "[1,  8000] val_loss: 1.764\n",
      "[1, 10000] loss 1.729\n",
      "[1, 10000] val_loss: 1.782\n",
      "[1, 12000] loss 1.660\n",
      "[1, 12000] val_loss: 1.654\n",
      "[1, 14000] loss 1.624\n",
      "[1, 14000] val_loss: 1.666\n",
      "[1, 16000] loss 1.601\n",
      "[1, 16000] val_loss: 1.620\n",
      "[1, 18000] loss 1.550\n",
      "[1, 18000] val_loss: 1.626\n",
      "[1, 20000] loss 1.508\n",
      "[1, 20000] val_loss: 1.587\n",
      "[1, 22000] loss 1.508\n",
      "[1, 22000] val_loss: 1.606\n",
      "[1, 24000] loss 1.451\n",
      "[1, 24000] val_loss: 1.595\n",
      "[1, 26000] loss 1.438\n",
      "[1, 26000] val_loss: 1.625\n",
      "[1, 28000] loss 1.406\n",
      "[1, 28000] val_loss: 1.562\n",
      "[1, 30000] loss 1.391\n",
      "[1, 30000] val_loss: 1.563\n",
      "[1, 32000] loss 1.358\n",
      "[1, 32000] val_loss: 1.593\n",
      "[1, 34000] loss 1.364\n",
      "[1, 34000] val_loss: 1.649\n",
      "[1, 36000] loss 1.337\n",
      "[1, 36000] val_loss: 1.493\n",
      "[2,  2000] loss 1.290\n",
      "[2,  2000] val_loss: 1.410\n",
      "[2,  4000] loss 1.285\n",
      "[2,  4000] val_loss: 1.452\n",
      "[2,  6000] loss 1.282\n",
      "[2,  6000] val_loss: 1.447\n",
      "[2,  8000] loss 1.275\n",
      "[2,  8000] val_loss: 1.438\n",
      "[2, 10000] loss 1.257\n",
      "[2, 10000] val_loss: 1.472\n",
      "[2, 12000] loss 1.237\n",
      "[2, 12000] val_loss: 1.383\n",
      "[2, 14000] loss 1.210\n",
      "[2, 14000] val_loss: 1.469\n",
      "[2, 16000] loss 1.230\n",
      "[2, 16000] val_loss: 1.438\n",
      "[2, 18000] loss 1.201\n",
      "[2, 18000] val_loss: 1.451\n",
      "[2, 20000] loss 1.200\n",
      "[2, 20000] val_loss: 1.440\n",
      "[2, 22000] loss 1.210\n",
      "[2, 22000] val_loss: 1.435\n",
      "[2, 24000] loss 1.185\n",
      "[2, 24000] val_loss: 1.441\n",
      "[2, 26000] loss 1.154\n",
      "[2, 26000] val_loss: 1.371\n",
      "[2, 28000] loss 1.162\n",
      "[2, 28000] val_loss: 1.365\n",
      "[2, 30000] loss 1.168\n",
      "[2, 30000] val_loss: 1.381\n",
      "[2, 32000] loss 1.145\n",
      "[2, 32000] val_loss: 1.375\n",
      "[2, 34000] loss 1.118\n",
      "[2, 34000] val_loss: 1.368\n",
      "[2, 36000] loss 1.095\n",
      "[2, 36000] val_loss: 1.394\n",
      "[3,  2000] loss 1.078\n",
      "[3,  2000] val_loss: 1.348\n",
      "[3,  4000] loss 1.088\n",
      "[3,  4000] val_loss: 1.344\n",
      "[3,  6000] loss 1.073\n",
      "[3,  6000] val_loss: 1.416\n",
      "[3,  8000] loss 1.056\n",
      "[3,  8000] val_loss: 1.348\n",
      "[3, 10000] loss 1.062\n",
      "[3, 10000] val_loss: 1.396\n",
      "[3, 12000] loss 1.062\n",
      "[3, 12000] val_loss: 1.354\n",
      "[3, 14000] loss 1.066\n",
      "[3, 14000] val_loss: 1.403\n",
      "[3, 16000] loss 1.040\n",
      "[3, 16000] val_loss: 1.347\n",
      "[3, 18000] loss 1.059\n",
      "[3, 18000] val_loss: 1.335\n",
      "[3, 20000] loss 1.033\n",
      "[3, 20000] val_loss: 1.348\n",
      "[3, 22000] loss 1.032\n",
      "[3, 22000] val_loss: 1.364\n",
      "[3, 24000] loss 1.041\n",
      "[3, 24000] val_loss: 1.348\n",
      "[3, 26000] loss 1.022\n",
      "[3, 26000] val_loss: 1.259\n",
      "[3, 28000] loss 1.048\n",
      "[3, 28000] val_loss: 1.271\n",
      "[3, 30000] loss 0.990\n",
      "[3, 30000] val_loss: 1.370\n",
      "[3, 32000] loss 1.020\n",
      "[3, 32000] val_loss: 1.392\n",
      "[3, 34000] loss 0.990\n",
      "[3, 34000] val_loss: 1.382\n",
      "[3, 36000] loss 1.004\n",
      "[3, 36000] val_loss: 1.328\n",
      "[4,  2000] loss 0.960\n",
      "[4,  2000] val_loss: 1.329\n",
      "[4,  4000] loss 0.932\n",
      "[4,  4000] val_loss: 1.371\n",
      "[4,  6000] loss 0.967\n",
      "[4,  6000] val_loss: 1.290\n",
      "[4,  8000] loss 0.951\n",
      "[4,  8000] val_loss: 1.361\n",
      "[4, 10000] loss 0.957\n",
      "[4, 10000] val_loss: 1.360\n",
      "[4, 12000] loss 0.937\n",
      "[4, 12000] val_loss: 1.398\n",
      "[4, 14000] loss 0.932\n",
      "[4, 14000] val_loss: 1.328\n",
      "[4, 16000] loss 0.951\n",
      "[4, 16000] val_loss: 1.292\n",
      "[4, 18000] loss 0.973\n",
      "[4, 18000] val_loss: 1.305\n",
      "[4, 20000] loss 0.940\n",
      "[4, 20000] val_loss: 1.335\n",
      "[4, 22000] loss 0.947\n",
      "[4, 22000] val_loss: 1.345\n",
      "[4, 24000] loss 0.941\n",
      "[4, 24000] val_loss: 1.332\n",
      "[4, 26000] loss 0.933\n",
      "[4, 26000] val_loss: 1.345\n",
      "[4, 28000] loss 0.942\n",
      "[4, 28000] val_loss: 1.394\n",
      "[4, 30000] loss 0.943\n",
      "[4, 30000] val_loss: 1.349\n",
      "[4, 32000] loss 0.930\n",
      "[4, 32000] val_loss: 1.317\n",
      "[4, 34000] loss 0.920\n",
      "[4, 34000] val_loss: 1.290\n",
      "[4, 36000] loss 0.922\n",
      "[4, 36000] val_loss: 1.261\n",
      "Finish Training\n",
      "Accuracy of the network on the 10000 test images: 70 %\n"
     ]
    }
   ],
   "source": [
    "recording = training('cnn_kernal_3_3_4dense_16channel_dropout01_4epoch',model=cnn,loss_function=criterion,optimizer=optimizer,trainloader=trainloader,validationloader=validationloader,validation=True,epochs=4)\n",
    "recording = testing('cnn_kernal_3_3_4dense_16channel_dropout01_4epoch',model=cnn,testloader=testloader,recording=recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = record.append(recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['base_cnn', 'base_cnn_4epochs', 'base_cnn_SGD_nesterov',\n",
       "       'base_cnn_SGD_nesterov_2epoch', 'base_cnn_adadelta_2epoch',\n",
       "       'base_cnn_adadelta_2epoch_lr001', 'base_cnn_adadelta_2epoch_lr01',\n",
       "       'base_cnn_augmented_data', 'base_cnn_augmented_data_2epoch',\n",
       "       'base_cnn_focalloss2_lr001', 'base_cnn_focalloss5_lr001',\n",
       "       'base_cnn_multimargin_lr001', 'base_cnn_test',\n",
       "       'base_cnn_xavier_normal', 'base_cnn_xavier_uniform',\n",
       "       'cnn_kernal_3_3', 'cnn_kernal_3_3_4dense_16channel_4epoch',\n",
       "       'cnn_kernal_3_3_4dense_dropout_2epoch', 'cnn_kernal_3_3_4epoch',\n",
       "       'cnn_kernal_3_3_channel_16_2epoch', 'cnn_kernal_5_5_4dense_2epoch',\n",
       "       'cnn_kernal_5_5_4dense_4epoch',\n",
       "       'cnn_kernal_5_5_4dense_batchnorm_2epoch',\n",
       "       'cnn_kernal_5_5_4dense_batchnorm_conv_2epoch',\n",
       "       'cnn_kernal_5_5_4dense_batchnorm_conv_relu_2epoch',\n",
       "       'cnn_kernal_5_5_4dense_batchnorm_dense_2epoch'], dtype=object)"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(record['experience'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experience</th>\n",
       "      <th>train</th>\n",
       "      <th>epoch</th>\n",
       "      <th>itrs</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>2.291716</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>2.233272</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4000</td>\n",
       "      <td>2.113734</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4000</td>\n",
       "      <td>2.022873</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6000</td>\n",
       "      <td>1.971031</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6000</td>\n",
       "      <td>1.961726</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8000</td>\n",
       "      <td>1.837075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8000</td>\n",
       "      <td>1.862097</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.751998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.767125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12000</td>\n",
       "      <td>1.643656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12000</td>\n",
       "      <td>1.640208</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14000</td>\n",
       "      <td>1.588391</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14000</td>\n",
       "      <td>1.673095</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16000</td>\n",
       "      <td>1.530479</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16000</td>\n",
       "      <td>1.698796</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18000</td>\n",
       "      <td>1.509897</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18000</td>\n",
       "      <td>1.608753</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20000</td>\n",
       "      <td>1.471142</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20000</td>\n",
       "      <td>1.557863</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22000</td>\n",
       "      <td>1.427328</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22000</td>\n",
       "      <td>1.590672</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24000</td>\n",
       "      <td>1.413100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24000</td>\n",
       "      <td>1.660548</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26000</td>\n",
       "      <td>1.349847</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26000</td>\n",
       "      <td>1.582980</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28000</td>\n",
       "      <td>1.353226</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28000</td>\n",
       "      <td>1.528459</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30000</td>\n",
       "      <td>1.313766</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30000</td>\n",
       "      <td>1.540634</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8000</td>\n",
       "      <td>1.210985</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.841359</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.260273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12000</td>\n",
       "      <td>0.856307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>12000</td>\n",
       "      <td>1.270087</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>14000</td>\n",
       "      <td>0.870611</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>14000</td>\n",
       "      <td>1.294492</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>16000</td>\n",
       "      <td>0.841683</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>16000</td>\n",
       "      <td>1.351260</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>18000</td>\n",
       "      <td>0.834560</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>18000</td>\n",
       "      <td>1.318399</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.837423</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>20000</td>\n",
       "      <td>1.378679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>22000</td>\n",
       "      <td>0.847835</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>22000</td>\n",
       "      <td>1.291334</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>24000</td>\n",
       "      <td>0.841835</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>24000</td>\n",
       "      <td>1.322619</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>26000</td>\n",
       "      <td>0.846977</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>26000</td>\n",
       "      <td>1.363780</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>28000</td>\n",
       "      <td>0.819895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>28000</td>\n",
       "      <td>1.291068</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>30000</td>\n",
       "      <td>0.838225</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>30000</td>\n",
       "      <td>1.293265</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>32000</td>\n",
       "      <td>0.820902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>32000</td>\n",
       "      <td>1.214486</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>34000</td>\n",
       "      <td>0.850345</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>34000</td>\n",
       "      <td>1.242980</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>36000</td>\n",
       "      <td>0.827178</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>36000</td>\n",
       "      <td>1.248003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>73.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 experience train epoch   itrs      loss  \\\n",
       "0    cnn_kernal_3_3_4dense_16channel_4epoch     0     1   2000  2.291716   \n",
       "1    cnn_kernal_3_3_4dense_16channel_4epoch     1     1   2000  2.233272   \n",
       "2    cnn_kernal_3_3_4dense_16channel_4epoch     0     1   4000  2.113734   \n",
       "3    cnn_kernal_3_3_4dense_16channel_4epoch     1     1   4000  2.022873   \n",
       "4    cnn_kernal_3_3_4dense_16channel_4epoch     0     1   6000  1.971031   \n",
       "5    cnn_kernal_3_3_4dense_16channel_4epoch     1     1   6000  1.961726   \n",
       "6    cnn_kernal_3_3_4dense_16channel_4epoch     0     1   8000  1.837075   \n",
       "7    cnn_kernal_3_3_4dense_16channel_4epoch     1     1   8000  1.862097   \n",
       "8    cnn_kernal_3_3_4dense_16channel_4epoch     0     1  10000  1.751998   \n",
       "9    cnn_kernal_3_3_4dense_16channel_4epoch     1     1  10000  1.767125   \n",
       "10   cnn_kernal_3_3_4dense_16channel_4epoch     0     1  12000  1.643656   \n",
       "11   cnn_kernal_3_3_4dense_16channel_4epoch     1     1  12000  1.640208   \n",
       "12   cnn_kernal_3_3_4dense_16channel_4epoch     0     1  14000  1.588391   \n",
       "13   cnn_kernal_3_3_4dense_16channel_4epoch     1     1  14000  1.673095   \n",
       "14   cnn_kernal_3_3_4dense_16channel_4epoch     0     1  16000  1.530479   \n",
       "15   cnn_kernal_3_3_4dense_16channel_4epoch     1     1  16000  1.698796   \n",
       "16   cnn_kernal_3_3_4dense_16channel_4epoch     0     1  18000  1.509897   \n",
       "17   cnn_kernal_3_3_4dense_16channel_4epoch     1     1  18000  1.608753   \n",
       "18   cnn_kernal_3_3_4dense_16channel_4epoch     0     1  20000  1.471142   \n",
       "19   cnn_kernal_3_3_4dense_16channel_4epoch     1     1  20000  1.557863   \n",
       "20   cnn_kernal_3_3_4dense_16channel_4epoch     0     1  22000  1.427328   \n",
       "21   cnn_kernal_3_3_4dense_16channel_4epoch     1     1  22000  1.590672   \n",
       "22   cnn_kernal_3_3_4dense_16channel_4epoch     0     1  24000  1.413100   \n",
       "23   cnn_kernal_3_3_4dense_16channel_4epoch     1     1  24000  1.660548   \n",
       "24   cnn_kernal_3_3_4dense_16channel_4epoch     0     1  26000  1.349847   \n",
       "25   cnn_kernal_3_3_4dense_16channel_4epoch     1     1  26000  1.582980   \n",
       "26   cnn_kernal_3_3_4dense_16channel_4epoch     0     1  28000  1.353226   \n",
       "27   cnn_kernal_3_3_4dense_16channel_4epoch     1     1  28000  1.528459   \n",
       "28   cnn_kernal_3_3_4dense_16channel_4epoch     0     1  30000  1.313766   \n",
       "29   cnn_kernal_3_3_4dense_16channel_4epoch     1     1  30000  1.540634   \n",
       "..                                      ...   ...   ...    ...       ...   \n",
       "115  cnn_kernal_3_3_4dense_16channel_4epoch     1     4   8000  1.210985   \n",
       "116  cnn_kernal_3_3_4dense_16channel_4epoch     0     4  10000  0.841359   \n",
       "117  cnn_kernal_3_3_4dense_16channel_4epoch     1     4  10000  1.260273   \n",
       "118  cnn_kernal_3_3_4dense_16channel_4epoch     0     4  12000  0.856307   \n",
       "119  cnn_kernal_3_3_4dense_16channel_4epoch     1     4  12000  1.270087   \n",
       "120  cnn_kernal_3_3_4dense_16channel_4epoch     0     4  14000  0.870611   \n",
       "121  cnn_kernal_3_3_4dense_16channel_4epoch     1     4  14000  1.294492   \n",
       "122  cnn_kernal_3_3_4dense_16channel_4epoch     0     4  16000  0.841683   \n",
       "123  cnn_kernal_3_3_4dense_16channel_4epoch     1     4  16000  1.351260   \n",
       "124  cnn_kernal_3_3_4dense_16channel_4epoch     0     4  18000  0.834560   \n",
       "125  cnn_kernal_3_3_4dense_16channel_4epoch     1     4  18000  1.318399   \n",
       "126  cnn_kernal_3_3_4dense_16channel_4epoch     0     4  20000  0.837423   \n",
       "127  cnn_kernal_3_3_4dense_16channel_4epoch     1     4  20000  1.378679   \n",
       "128  cnn_kernal_3_3_4dense_16channel_4epoch     0     4  22000  0.847835   \n",
       "129  cnn_kernal_3_3_4dense_16channel_4epoch     1     4  22000  1.291334   \n",
       "130  cnn_kernal_3_3_4dense_16channel_4epoch     0     4  24000  0.841835   \n",
       "131  cnn_kernal_3_3_4dense_16channel_4epoch     1     4  24000  1.322619   \n",
       "132  cnn_kernal_3_3_4dense_16channel_4epoch     0     4  26000  0.846977   \n",
       "133  cnn_kernal_3_3_4dense_16channel_4epoch     1     4  26000  1.363780   \n",
       "134  cnn_kernal_3_3_4dense_16channel_4epoch     0     4  28000  0.819895   \n",
       "135  cnn_kernal_3_3_4dense_16channel_4epoch     1     4  28000  1.291068   \n",
       "136  cnn_kernal_3_3_4dense_16channel_4epoch     0     4  30000  0.838225   \n",
       "137  cnn_kernal_3_3_4dense_16channel_4epoch     1     4  30000  1.293265   \n",
       "138  cnn_kernal_3_3_4dense_16channel_4epoch     0     4  32000  0.820902   \n",
       "139  cnn_kernal_3_3_4dense_16channel_4epoch     1     4  32000  1.214486   \n",
       "140  cnn_kernal_3_3_4dense_16channel_4epoch     0     4  34000  0.850345   \n",
       "141  cnn_kernal_3_3_4dense_16channel_4epoch     1     4  34000  1.242980   \n",
       "142  cnn_kernal_3_3_4dense_16channel_4epoch     0     4  36000  0.827178   \n",
       "143  cnn_kernal_3_3_4dense_16channel_4epoch     1     4  36000  1.248003   \n",
       "144  cnn_kernal_3_3_4dense_16channel_4epoch     0     0      0  0.000000   \n",
       "\n",
       "    accuracy  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "5          0  \n",
       "6          0  \n",
       "7          0  \n",
       "8          0  \n",
       "9          0  \n",
       "10         0  \n",
       "11         0  \n",
       "12         0  \n",
       "13         0  \n",
       "14         0  \n",
       "15         0  \n",
       "16         0  \n",
       "17         0  \n",
       "18         0  \n",
       "19         0  \n",
       "20         0  \n",
       "21         0  \n",
       "22         0  \n",
       "23         0  \n",
       "24         0  \n",
       "25         0  \n",
       "26         0  \n",
       "27         0  \n",
       "28         0  \n",
       "29         0  \n",
       "..       ...  \n",
       "115        0  \n",
       "116        0  \n",
       "117        0  \n",
       "118        0  \n",
       "119        0  \n",
       "120        0  \n",
       "121        0  \n",
       "122        0  \n",
       "123        0  \n",
       "124        0  \n",
       "125        0  \n",
       "126        0  \n",
       "127        0  \n",
       "128        0  \n",
       "129        0  \n",
       "130        0  \n",
       "131        0  \n",
       "132        0  \n",
       "133        0  \n",
       "134        0  \n",
       "135        0  \n",
       "136        0  \n",
       "137        0  \n",
       "138        0  \n",
       "139        0  \n",
       "140        0  \n",
       "141        0  \n",
       "142        0  \n",
       "143        0  \n",
       "144    73.33  \n",
       "\n",
       "[145 rows x 6 columns]"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record[record['experience']=='cnn_kernal_3_3_4dense_16channel_4epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = record.append(recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "record.to_csv('record.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['base_cnn', 'base_cnn_4epochs', 'base_cnn_SGD_nesterov',\n",
       "       'base_cnn_SGD_nesterov_2epoch', 'base_cnn_adadelta_2epoch',\n",
       "       'base_cnn_adadelta_2epoch_lr001', 'base_cnn_adadelta_2epoch_lr01',\n",
       "       'base_cnn_augmented_data', 'base_cnn_augmented_data_2epoch',\n",
       "       'base_cnn_focalloss2_lr001', 'base_cnn_focalloss5_lr001',\n",
       "       'base_cnn_multimargin_lr001', 'base_cnn_test',\n",
       "       'base_cnn_xavier_normal', 'base_cnn_xavier_uniform',\n",
       "       'cnn_kernal_3_3', 'cnn_kernal_3_3_4dense_16channel_2epoch',\n",
       "       'cnn_kernal_3_3_4dense_16channel_4epoch',\n",
       "       'cnn_kernal_3_3_4dense_16channel_dropout01_4epoch',\n",
       "       'cnn_kernal_3_3_4dense_16channel_dropout_4epoch',\n",
       "       'cnn_kernal_3_3_4dense_dropout_2epoch', 'cnn_kernal_3_3_4epoch',\n",
       "       'cnn_kernal_3_3_channel_16_2epoch', 'cnn_kernal_5_5_4dense_2epoch',\n",
       "       'cnn_kernal_5_5_4dense_4epoch',\n",
       "       'cnn_kernal_5_5_4dense_batchnorm_2epoch',\n",
       "       'cnn_kernal_5_5_4dense_batchnorm_conv_2epoch',\n",
       "       'cnn_kernal_5_5_4dense_batchnorm_conv_relu_2epoch',\n",
       "       'cnn_kernal_5_5_4dense_batchnorm_dense_2epoch'], dtype=object)"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(record['experience'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep = record[record['experience']=='base_cnn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = ep[ep['train']==0]['loss'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = ep[ep['train']==1]['loss'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1306114e0>]"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x131482a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(title, record):\n",
    "    ep = record[record['experience']==title]\n",
    "    train_loss = ep[ep['train']==0]\n",
    "    accuracy = train_loss.iloc[-1]['accuracy']\n",
    "    train_loss = train_loss['loss'].values[:-1]\n",
    "    val_loss = ep[ep['train']==1]['loss'].values\n",
    "    return train_loss,val_loss,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss,val_loss,accuracy = get_result('base_cnn_4epochs',record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x130e63550>]"
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1308c38d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['base_cnn', 'base_cnn_4epochs', 'base_cnn_SGD_nesterov',\n",
       "       'base_cnn_SGD_nesterov_2epoch', 'base_cnn_adadelta_2epoch',\n",
       "       'base_cnn_adadelta_2epoch_lr001', 'base_cnn_adadelta_2epoch_lr01',\n",
       "       'base_cnn_augmented_data', 'base_cnn_augmented_data_2epoch',\n",
       "       'base_cnn_focalloss2_lr001', 'base_cnn_focalloss5_lr001',\n",
       "       'base_cnn_multimargin_lr001', 'base_cnn_test',\n",
       "       'base_cnn_xavier_normal', 'base_cnn_xavier_uniform',\n",
       "       'cnn_kernal_3_3', 'cnn_kernal_3_3_4dense_16channel_2epoch',\n",
       "       'cnn_kernal_3_3_4dense_16channel_4epoch',\n",
       "       'cnn_kernal_3_3_4dense_16channel_dropout01_4epoch',\n",
       "       'cnn_kernal_3_3_4dense_16channel_dropout_4epoch',\n",
       "       'cnn_kernal_3_3_4dense_dropout_2epoch', 'cnn_kernal_3_3_4epoch',\n",
       "       'cnn_kernal_3_3_channel_16_2epoch', 'cnn_kernal_5_5_4dense_2epoch',\n",
       "       'cnn_kernal_5_5_4dense_4epoch',\n",
       "       'cnn_kernal_5_5_4dense_batchnorm_2epoch',\n",
       "       'cnn_kernal_5_5_4dense_batchnorm_conv_2epoch',\n",
       "       'cnn_kernal_5_5_4dense_batchnorm_conv_relu_2epoch',\n",
       "       'cnn_kernal_5_5_4dense_batchnorm_dense_2epoch'], dtype=object)"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(record['experience'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experience</th>\n",
       "      <th>train</th>\n",
       "      <th>epoch</th>\n",
       "      <th>itrs</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>base_cnn</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>2.188427</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>base_cnn</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>2.024263</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>base_cnn</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4000</td>\n",
       "      <td>1.849628</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>base_cnn</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4000</td>\n",
       "      <td>1.817170</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>base_cnn</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6000</td>\n",
       "      <td>1.657342</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>base_cnn</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6000</td>\n",
       "      <td>1.886216</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>base_cnn</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8000</td>\n",
       "      <td>1.562179</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>base_cnn</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8000</td>\n",
       "      <td>1.912048</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>base_cnn</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.511154</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>base_cnn</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.821935</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>base_cnn</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12000</td>\n",
       "      <td>1.458052</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>base_cnn</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12000</td>\n",
       "      <td>1.896441</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>base_cnn</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "      <td>1.383534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>base_cnn</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "      <td>1.750954</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>base_cnn</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4000</td>\n",
       "      <td>1.362030</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>base_cnn</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4000</td>\n",
       "      <td>1.744072</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>base_cnn</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6000</td>\n",
       "      <td>1.349054</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>base_cnn</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6000</td>\n",
       "      <td>1.649942</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>base_cnn</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8000</td>\n",
       "      <td>1.297650</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>base_cnn</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8000</td>\n",
       "      <td>1.771225</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>base_cnn</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.288243</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>base_cnn</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.732668</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>base_cnn</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12000</td>\n",
       "      <td>1.242153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>base_cnn</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12000</td>\n",
       "      <td>1.737988</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   experience train epoch   itrs      loss accuracy\n",
       "0    base_cnn     0     1   2000  2.188427        0\n",
       "1    base_cnn     1     1   2000  2.024263        0\n",
       "2    base_cnn     0     1   4000  1.849628        0\n",
       "3    base_cnn     1     1   4000  1.817170        0\n",
       "4    base_cnn     0     1   6000  1.657342        0\n",
       "5    base_cnn     1     1   6000  1.886216        0\n",
       "6    base_cnn     0     1   8000  1.562179        0\n",
       "7    base_cnn     1     1   8000  1.912048        0\n",
       "8    base_cnn     0     1  10000  1.511154        0\n",
       "9    base_cnn     1     1  10000  1.821935        0\n",
       "10   base_cnn     0     1  12000  1.458052        0\n",
       "11   base_cnn     1     1  12000  1.896441        0\n",
       "12   base_cnn     0     2   2000  1.383534        0\n",
       "13   base_cnn     1     2   2000  1.750954        0\n",
       "14   base_cnn     0     2   4000  1.362030        0\n",
       "15   base_cnn     1     2   4000  1.744072        0\n",
       "16   base_cnn     0     2   6000  1.349054        0\n",
       "17   base_cnn     1     2   6000  1.649942        0\n",
       "18   base_cnn     0     2   8000  1.297650        0\n",
       "19   base_cnn     1     2   8000  1.771225        0\n",
       "20   base_cnn     0     2  10000  1.288243        0\n",
       "21   base_cnn     1     2  10000  1.732668        0\n",
       "22   base_cnn     0     2  12000  1.242153        0\n",
       "23   base_cnn     1     2  12000  1.737988        0"
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record[record['experience']=='base_cnn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['base_cnn', 'base_cnn_4epochs', 'base_cnn_SGD_nesterov',\n",
       "       'base_cnn_SGD_nesterov_2epoch', 'base_cnn_adadelta_2epoch',\n",
       "       'base_cnn_adadelta_2epoch_lr001', 'base_cnn_adadelta_2epoch_lr01',\n",
       "       'base_cnn_augmented_data', 'base_cnn_augmented_data_2epoch',\n",
       "       'base_cnn_focalloss2_lr001', 'base_cnn_focalloss5_lr001',\n",
       "       'base_cnn_multimargin_lr001', 'base_cnn_test',\n",
       "       'base_cnn_xavier_normal', 'base_cnn_xavier_uniform',\n",
       "       'cnn_kernal_3_3', 'cnn_kernal_3_3_4dense_16channel_2epoch',\n",
       "       'cnn_kernal_3_3_4dense_16channel_4epoch',\n",
       "       'cnn_kernal_3_3_4dense_16channel_dropout01_4epoch',\n",
       "       'cnn_kernal_3_3_4dense_16channel_dropout_4epoch',\n",
       "       'cnn_kernal_3_3_4dense_dropout_2epoch', 'cnn_kernal_3_3_4epoch',\n",
       "       'cnn_kernal_3_3_channel_16_2epoch', 'cnn_kernal_5_5_4dense_2epoch',\n",
       "       'cnn_kernal_5_5_4dense_4epoch',\n",
       "       'cnn_kernal_5_5_4dense_batchnorm_2epoch',\n",
       "       'cnn_kernal_5_5_4dense_batchnorm_conv_2epoch',\n",
       "       'cnn_kernal_5_5_4dense_batchnorm_conv_relu_2epoch',\n",
       "       'cnn_kernal_5_5_4dense_batchnorm_dense_2epoch'], dtype=object)"
      ]
     },
     "execution_count": 600,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(record['experience'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss,val_loss,accuracy = get_result('base_cnn_augmented_data',record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.19"
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "record.to_csv('record.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = pd.read_csv('record.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>experience</th>\n",
       "      <th>train</th>\n",
       "      <th>epoch</th>\n",
       "      <th>itrs</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>base_cnn</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>2.188427</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>base_cnn</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>2.024263</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>base_cnn</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4000</td>\n",
       "      <td>1.849628</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>base_cnn</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4000</td>\n",
       "      <td>1.817170</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>base_cnn</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6000</td>\n",
       "      <td>1.657342</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>base_cnn</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6000</td>\n",
       "      <td>1.886216</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>base_cnn</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8000</td>\n",
       "      <td>1.562179</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>base_cnn</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8000</td>\n",
       "      <td>1.912048</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>base_cnn</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.511154</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>base_cnn</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.821935</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>base_cnn</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12000</td>\n",
       "      <td>1.458052</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>base_cnn</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12000</td>\n",
       "      <td>1.896441</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>base_cnn</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "      <td>1.383534</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>base_cnn</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "      <td>1.750954</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>base_cnn</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4000</td>\n",
       "      <td>1.362030</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>base_cnn</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4000</td>\n",
       "      <td>1.744072</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>base_cnn</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6000</td>\n",
       "      <td>1.349054</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>base_cnn</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6000</td>\n",
       "      <td>1.649942</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>base_cnn</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8000</td>\n",
       "      <td>1.297650</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>base_cnn</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8000</td>\n",
       "      <td>1.771225</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>base_cnn</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.288243</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>base_cnn</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.732668</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>base_cnn</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12000</td>\n",
       "      <td>1.242153</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>base_cnn</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12000</td>\n",
       "      <td>1.737988</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>base_cnn_test</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>base_cnn_4epochs</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>2.161975</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>base_cnn_4epochs</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>1.945604</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>base_cnn_4epochs</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4000</td>\n",
       "      <td>1.788963</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3</td>\n",
       "      <td>base_cnn_4epochs</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4000</td>\n",
       "      <td>1.843406</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4</td>\n",
       "      <td>base_cnn_4epochs</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6000</td>\n",
       "      <td>1.659541</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2880</th>\n",
       "      <td>115</td>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_dropout01_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8000</td>\n",
       "      <td>1.361478</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2881</th>\n",
       "      <td>116</td>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_dropout01_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.957289</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2882</th>\n",
       "      <td>117</td>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_dropout01_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.360487</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2883</th>\n",
       "      <td>118</td>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_dropout01_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12000</td>\n",
       "      <td>0.936609</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2884</th>\n",
       "      <td>119</td>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_dropout01_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>12000</td>\n",
       "      <td>1.397816</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2885</th>\n",
       "      <td>120</td>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_dropout01_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>14000</td>\n",
       "      <td>0.931723</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2886</th>\n",
       "      <td>121</td>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_dropout01_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>14000</td>\n",
       "      <td>1.328069</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2887</th>\n",
       "      <td>122</td>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_dropout01_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>16000</td>\n",
       "      <td>0.950912</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2888</th>\n",
       "      <td>123</td>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_dropout01_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>16000</td>\n",
       "      <td>1.292170</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2889</th>\n",
       "      <td>124</td>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_dropout01_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>18000</td>\n",
       "      <td>0.973376</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2890</th>\n",
       "      <td>125</td>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_dropout01_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>18000</td>\n",
       "      <td>1.305044</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2891</th>\n",
       "      <td>126</td>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_dropout01_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.939545</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>127</td>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_dropout01_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>20000</td>\n",
       "      <td>1.334659</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>128</td>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_dropout01_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>22000</td>\n",
       "      <td>0.946843</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2894</th>\n",
       "      <td>129</td>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_dropout01_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>22000</td>\n",
       "      <td>1.345354</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2895</th>\n",
       "      <td>130</td>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_dropout01_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>24000</td>\n",
       "      <td>0.941030</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2896</th>\n",
       "      <td>131</td>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_dropout01_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>24000</td>\n",
       "      <td>1.331851</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2897</th>\n",
       "      <td>132</td>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_dropout01_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>26000</td>\n",
       "      <td>0.933047</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2898</th>\n",
       "      <td>133</td>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_dropout01_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>26000</td>\n",
       "      <td>1.345367</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2899</th>\n",
       "      <td>134</td>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_dropout01_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>28000</td>\n",
       "      <td>0.941536</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2900</th>\n",
       "      <td>135</td>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_dropout01_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>28000</td>\n",
       "      <td>1.393807</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2901</th>\n",
       "      <td>136</td>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_dropout01_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>30000</td>\n",
       "      <td>0.943245</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2902</th>\n",
       "      <td>137</td>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_dropout01_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>30000</td>\n",
       "      <td>1.349472</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2903</th>\n",
       "      <td>138</td>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_dropout01_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>32000</td>\n",
       "      <td>0.930421</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2904</th>\n",
       "      <td>139</td>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_dropout01_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>32000</td>\n",
       "      <td>1.317442</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2905</th>\n",
       "      <td>140</td>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_dropout01_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>34000</td>\n",
       "      <td>0.920096</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2906</th>\n",
       "      <td>141</td>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_dropout01_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>34000</td>\n",
       "      <td>1.290108</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2907</th>\n",
       "      <td>142</td>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_dropout01_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>36000</td>\n",
       "      <td>0.922217</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2908</th>\n",
       "      <td>143</td>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_dropout01_4epoch</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>36000</td>\n",
       "      <td>1.261258</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2909</th>\n",
       "      <td>144</td>\n",
       "      <td>cnn_kernal_3_3_4dense_16channel_dropout01_4epoch</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>70.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2910 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                        experience  train  \\\n",
       "0              0                                          base_cnn      0   \n",
       "1              1                                          base_cnn      1   \n",
       "2              2                                          base_cnn      0   \n",
       "3              3                                          base_cnn      1   \n",
       "4              4                                          base_cnn      0   \n",
       "5              5                                          base_cnn      1   \n",
       "6              6                                          base_cnn      0   \n",
       "7              7                                          base_cnn      1   \n",
       "8              8                                          base_cnn      0   \n",
       "9              9                                          base_cnn      1   \n",
       "10            10                                          base_cnn      0   \n",
       "11            11                                          base_cnn      1   \n",
       "12            12                                          base_cnn      0   \n",
       "13            13                                          base_cnn      1   \n",
       "14            14                                          base_cnn      0   \n",
       "15            15                                          base_cnn      1   \n",
       "16            16                                          base_cnn      0   \n",
       "17            17                                          base_cnn      1   \n",
       "18            18                                          base_cnn      0   \n",
       "19            19                                          base_cnn      1   \n",
       "20            20                                          base_cnn      0   \n",
       "21            21                                          base_cnn      1   \n",
       "22            22                                          base_cnn      0   \n",
       "23            23                                          base_cnn      1   \n",
       "24            24                                     base_cnn_test      0   \n",
       "25             0                                  base_cnn_4epochs      0   \n",
       "26             1                                  base_cnn_4epochs      1   \n",
       "27             2                                  base_cnn_4epochs      0   \n",
       "28             3                                  base_cnn_4epochs      1   \n",
       "29             4                                  base_cnn_4epochs      0   \n",
       "...          ...                                               ...    ...   \n",
       "2880         115  cnn_kernal_3_3_4dense_16channel_dropout01_4epoch      1   \n",
       "2881         116  cnn_kernal_3_3_4dense_16channel_dropout01_4epoch      0   \n",
       "2882         117  cnn_kernal_3_3_4dense_16channel_dropout01_4epoch      1   \n",
       "2883         118  cnn_kernal_3_3_4dense_16channel_dropout01_4epoch      0   \n",
       "2884         119  cnn_kernal_3_3_4dense_16channel_dropout01_4epoch      1   \n",
       "2885         120  cnn_kernal_3_3_4dense_16channel_dropout01_4epoch      0   \n",
       "2886         121  cnn_kernal_3_3_4dense_16channel_dropout01_4epoch      1   \n",
       "2887         122  cnn_kernal_3_3_4dense_16channel_dropout01_4epoch      0   \n",
       "2888         123  cnn_kernal_3_3_4dense_16channel_dropout01_4epoch      1   \n",
       "2889         124  cnn_kernal_3_3_4dense_16channel_dropout01_4epoch      0   \n",
       "2890         125  cnn_kernal_3_3_4dense_16channel_dropout01_4epoch      1   \n",
       "2891         126  cnn_kernal_3_3_4dense_16channel_dropout01_4epoch      0   \n",
       "2892         127  cnn_kernal_3_3_4dense_16channel_dropout01_4epoch      1   \n",
       "2893         128  cnn_kernal_3_3_4dense_16channel_dropout01_4epoch      0   \n",
       "2894         129  cnn_kernal_3_3_4dense_16channel_dropout01_4epoch      1   \n",
       "2895         130  cnn_kernal_3_3_4dense_16channel_dropout01_4epoch      0   \n",
       "2896         131  cnn_kernal_3_3_4dense_16channel_dropout01_4epoch      1   \n",
       "2897         132  cnn_kernal_3_3_4dense_16channel_dropout01_4epoch      0   \n",
       "2898         133  cnn_kernal_3_3_4dense_16channel_dropout01_4epoch      1   \n",
       "2899         134  cnn_kernal_3_3_4dense_16channel_dropout01_4epoch      0   \n",
       "2900         135  cnn_kernal_3_3_4dense_16channel_dropout01_4epoch      1   \n",
       "2901         136  cnn_kernal_3_3_4dense_16channel_dropout01_4epoch      0   \n",
       "2902         137  cnn_kernal_3_3_4dense_16channel_dropout01_4epoch      1   \n",
       "2903         138  cnn_kernal_3_3_4dense_16channel_dropout01_4epoch      0   \n",
       "2904         139  cnn_kernal_3_3_4dense_16channel_dropout01_4epoch      1   \n",
       "2905         140  cnn_kernal_3_3_4dense_16channel_dropout01_4epoch      0   \n",
       "2906         141  cnn_kernal_3_3_4dense_16channel_dropout01_4epoch      1   \n",
       "2907         142  cnn_kernal_3_3_4dense_16channel_dropout01_4epoch      0   \n",
       "2908         143  cnn_kernal_3_3_4dense_16channel_dropout01_4epoch      1   \n",
       "2909         144  cnn_kernal_3_3_4dense_16channel_dropout01_4epoch      0   \n",
       "\n",
       "      epoch   itrs      loss  accuracy  \n",
       "0         1   2000  2.188427      0.00  \n",
       "1         1   2000  2.024263      0.00  \n",
       "2         1   4000  1.849628      0.00  \n",
       "3         1   4000  1.817170      0.00  \n",
       "4         1   6000  1.657342      0.00  \n",
       "5         1   6000  1.886216      0.00  \n",
       "6         1   8000  1.562179      0.00  \n",
       "7         1   8000  1.912048      0.00  \n",
       "8         1  10000  1.511154      0.00  \n",
       "9         1  10000  1.821935      0.00  \n",
       "10        1  12000  1.458052      0.00  \n",
       "11        1  12000  1.896441      0.00  \n",
       "12        2   2000  1.383534      0.00  \n",
       "13        2   2000  1.750954      0.00  \n",
       "14        2   4000  1.362030      0.00  \n",
       "15        2   4000  1.744072      0.00  \n",
       "16        2   6000  1.349054      0.00  \n",
       "17        2   6000  1.649942      0.00  \n",
       "18        2   8000  1.297650      0.00  \n",
       "19        2   8000  1.771225      0.00  \n",
       "20        2  10000  1.288243      0.00  \n",
       "21        2  10000  1.732668      0.00  \n",
       "22        2  12000  1.242153      0.00  \n",
       "23        2  12000  1.737988      0.00  \n",
       "24        0      0  0.000000     56.36  \n",
       "25        1   2000  2.161975      0.00  \n",
       "26        1   2000  1.945604      0.00  \n",
       "27        1   4000  1.788963      0.00  \n",
       "28        1   4000  1.843406      0.00  \n",
       "29        1   6000  1.659541      0.00  \n",
       "...     ...    ...       ...       ...  \n",
       "2880      4   8000  1.361478      0.00  \n",
       "2881      4  10000  0.957289      0.00  \n",
       "2882      4  10000  1.360487      0.00  \n",
       "2883      4  12000  0.936609      0.00  \n",
       "2884      4  12000  1.397816      0.00  \n",
       "2885      4  14000  0.931723      0.00  \n",
       "2886      4  14000  1.328069      0.00  \n",
       "2887      4  16000  0.950912      0.00  \n",
       "2888      4  16000  1.292170      0.00  \n",
       "2889      4  18000  0.973376      0.00  \n",
       "2890      4  18000  1.305044      0.00  \n",
       "2891      4  20000  0.939545      0.00  \n",
       "2892      4  20000  1.334659      0.00  \n",
       "2893      4  22000  0.946843      0.00  \n",
       "2894      4  22000  1.345354      0.00  \n",
       "2895      4  24000  0.941030      0.00  \n",
       "2896      4  24000  1.331851      0.00  \n",
       "2897      4  26000  0.933047      0.00  \n",
       "2898      4  26000  1.345367      0.00  \n",
       "2899      4  28000  0.941536      0.00  \n",
       "2900      4  28000  1.393807      0.00  \n",
       "2901      4  30000  0.943245      0.00  \n",
       "2902      4  30000  1.349472      0.00  \n",
       "2903      4  32000  0.930421      0.00  \n",
       "2904      4  32000  1.317442      0.00  \n",
       "2905      4  34000  0.920096      0.00  \n",
       "2906      4  34000  1.290108      0.00  \n",
       "2907      4  36000  0.922217      0.00  \n",
       "2908      4  36000  1.261258      0.00  \n",
       "2909      0      0  0.000000     70.68  \n",
       "\n",
       "[2910 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-c96ea106a431>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcifar10\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\condathree\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\condathree\\lib\\site-packages\\keras\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mio_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Globally-importable utils.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\condathree\\lib\\site-packages\\keras\\utils\\conv_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\condathree\\lib\\site-packages\\keras\\backend\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;32melif\u001b[0m \u001b[0m_BACKEND\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tensorflow'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Using TensorFlow backend.\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;31m# Try and load external backend.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\condathree\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mops\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmoving_averages\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# pylint: disable=g-bad-import-order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m  \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbitwise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m# Framework\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework_lib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m  \u001b[1;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\framework_lib.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# Classes used when building a Graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDeviceSpec\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGraph\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOperation\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mversions\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcontrol_flow_util\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf_logging\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\platform\\app.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_export\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf_export\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\platform\\flags.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;31m# absl.flags APIs use `default` as the name of the default value argument.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;31m# Allow the following functions continue to accept `default_value`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m \u001b[0mDEFINE_string\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_wrap_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDEFINE_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[0mDEFINE_boolean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_wrap_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDEFINE_boolean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[0mDEFINE_bool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDEFINE_boolean\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\platform\\flags.py\u001b[0m in \u001b[0;36m_wrap_define_function\u001b[1;34m(original_function)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0moriginal_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_decorator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\util\\tf_decorator.py\u001b[0m in \u001b[0;36mmake_decorator\u001b[1;34m(target, decorator_func, decorator_name, decorator_doc, decorator_argspec)\u001b[0m\n\u001b[0;32m     84\u001b[0m   \"\"\"\n\u001b[0;32m     85\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mdecorator_name\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_traceback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_stack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m     \u001b[1;31m# frame name is tuple[2] in python2, and object.name in python3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[0mdecorator_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Caller's name\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\condathree\\lib\\traceback.py\u001b[0m in \u001b[0;36mextract_stack\u001b[1;34m(f, limit)\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_back\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m     \u001b[0mstack\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStackSummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwalk_stack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m     \u001b[0mstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mstack\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\condathree\\lib\\traceback.py\u001b[0m in \u001b[0;36mextract\u001b[1;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlookup_lines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 358\u001b[1;33m                 \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\condathree\\lib\\traceback.py\u001b[0m in \u001b[0;36mline\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    280\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_line\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 282\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_line\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinecache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlineno\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    283\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_line\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\condathree\\lib\\linecache.py\u001b[0m in \u001b[0;36mgetline\u001b[1;34m(filename, lineno, module_globals)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgetline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlineno\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodule_globals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodule_globals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mlineno\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlineno\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\condathree\\lib\\linecache.py\u001b[0m in \u001b[0;36mgetlines\u001b[1;34m(filename, module_globals)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdatecache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodule_globals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mMemoryError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mclearcache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\condathree\\lib\\linecache.py\u001b[0m in \u001b[0;36mupdatecache\u001b[1;34m(filename, module_globals)\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[0mfullname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m         \u001b[0mstat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfullname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[0mbasename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(1000)\n",
    "\n",
    "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.0001, decay=1e-6),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train / 255.0, to_categorical(Y_train),\n",
    "          batch_size=128,\n",
    "          shuffle=True,\n",
    "          epochs=250,\n",
    "          validation_data=(X_test / 255.0, to_categorical(Y_test)),\n",
    "          callbacks=[EarlyStopping(min_delta=0.001, patience=3)])\n",
    "\n",
    "# Evaluate the model\n",
    "scores = model.evaluate(X_test / 255.0, to_categorical(Y_test))\n",
    "\n",
    "print('Loss: %.3f' % scores[0])\n",
    "print('Accuracy: %.3f' % scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:condathree]",
   "language": "python",
   "name": "conda-env-condathree-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
