{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/250\n",
      "50000/50000 [==============================] - 61s 1ms/step - loss: 2.0074 - acc: 0.2504 - val_loss: 1.7253 - val_acc: 0.3786\n",
      "Epoch 2/250\n",
      "50000/50000 [==============================] - 50s 997us/step - loss: 1.6732 - acc: 0.3802 - val_loss: 1.5442 - val_acc: 0.4375\n",
      "Epoch 3/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 1.5274 - acc: 0.4384 - val_loss: 1.4163 - val_acc: 0.4868\n",
      "Epoch 4/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 1.4312 - acc: 0.4760 - val_loss: 1.3284 - val_acc: 0.5256\n",
      "Epoch 5/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 1.3538 - acc: 0.5111 - val_loss: 1.2654 - val_acc: 0.5420\n",
      "Epoch 6/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 1.2885 - acc: 0.5384 - val_loss: 1.1919 - val_acc: 0.5839\n",
      "Epoch 7/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 1.2394 - acc: 0.5568 - val_loss: 1.1426 - val_acc: 0.5959\n",
      "Epoch 8/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 1.1920 - acc: 0.5762 - val_loss: 1.1068 - val_acc: 0.6091\n",
      "Epoch 9/250\n",
      "50000/50000 [==============================] - 50s 1000us/step - loss: 1.1463 - acc: 0.5928 - val_loss: 1.0775 - val_acc: 0.6209\n",
      "Epoch 10/250\n",
      "50000/50000 [==============================] - 50s 1000us/step - loss: 1.1168 - acc: 0.6046 - val_loss: 1.0451 - val_acc: 0.6335\n",
      "Epoch 11/250\n",
      "50000/50000 [==============================] - 50s 998us/step - loss: 1.0808 - acc: 0.6183 - val_loss: 1.0078 - val_acc: 0.6488\n",
      "Epoch 12/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 1.0513 - acc: 0.6262 - val_loss: 0.9881 - val_acc: 0.6548\n",
      "Epoch 13/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 1.0269 - acc: 0.6374 - val_loss: 0.9707 - val_acc: 0.6613\n",
      "Epoch 14/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.9994 - acc: 0.6478 - val_loss: 0.9493 - val_acc: 0.6715\n",
      "Epoch 15/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.9799 - acc: 0.6564 - val_loss: 0.9512 - val_acc: 0.6679\n",
      "Epoch 16/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.9552 - acc: 0.6623 - val_loss: 0.9040 - val_acc: 0.6848\n",
      "Epoch 17/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.9363 - acc: 0.6714 - val_loss: 0.8965 - val_acc: 0.6899\n",
      "Epoch 18/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.9149 - acc: 0.6795 - val_loss: 0.8778 - val_acc: 0.6977\n",
      "Epoch 19/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.8976 - acc: 0.6856 - val_loss: 0.8638 - val_acc: 0.7028\n",
      "Epoch 20/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.8829 - acc: 0.6909 - val_loss: 0.8438 - val_acc: 0.7082\n",
      "Epoch 21/250\n",
      "50000/50000 [==============================] - 50s 1000us/step - loss: 0.8628 - acc: 0.6962 - val_loss: 0.8400 - val_acc: 0.7070\n",
      "Epoch 22/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.8451 - acc: 0.7045 - val_loss: 0.8229 - val_acc: 0.7159\n",
      "Epoch 23/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.8270 - acc: 0.7098 - val_loss: 0.8207 - val_acc: 0.7120\n",
      "Epoch 24/250\n",
      "50000/50000 [==============================] - 50s 998us/step - loss: 0.8142 - acc: 0.7152 - val_loss: 0.7954 - val_acc: 0.7281\n",
      "Epoch 25/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.7992 - acc: 0.7198 - val_loss: 0.8000 - val_acc: 0.7210\n",
      "Epoch 26/250\n",
      "50000/50000 [==============================] - 50s 998us/step - loss: 0.7884 - acc: 0.7231 - val_loss: 0.7910 - val_acc: 0.7255\n",
      "Epoch 27/250\n",
      "50000/50000 [==============================] - 50s 998us/step - loss: 0.7753 - acc: 0.7279 - val_loss: 0.7690 - val_acc: 0.7313\n",
      "Epoch 28/250\n",
      "50000/50000 [==============================] - 50s 999us/step - loss: 0.7630 - acc: 0.7337 - val_loss: 0.7525 - val_acc: 0.7400\n",
      "Epoch 29/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.7430 - acc: 0.7407 - val_loss: 0.7626 - val_acc: 0.7311\n",
      "Epoch 30/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.7330 - acc: 0.7441 - val_loss: 0.7348 - val_acc: 0.7466\n",
      "Epoch 31/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.7258 - acc: 0.7451 - val_loss: 0.7449 - val_acc: 0.7414\n",
      "Epoch 32/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.7095 - acc: 0.7509 - val_loss: 0.7358 - val_acc: 0.7416\n",
      "Epoch 33/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.7048 - acc: 0.7531 - val_loss: 0.7223 - val_acc: 0.7495\n",
      "Epoch 34/250\n",
      "50000/50000 [==============================] - 50s 998us/step - loss: 0.6877 - acc: 0.7595 - val_loss: 0.7175 - val_acc: 0.7497\n",
      "Epoch 35/250\n",
      "50000/50000 [==============================] - 50s 999us/step - loss: 0.6813 - acc: 0.7601 - val_loss: 0.7102 - val_acc: 0.7535\n",
      "Epoch 36/250\n",
      "50000/50000 [==============================] - 50s 997us/step - loss: 0.6704 - acc: 0.7653 - val_loss: 0.7134 - val_acc: 0.7558\n",
      "Epoch 37/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.6584 - acc: 0.7690 - val_loss: 0.6903 - val_acc: 0.7600\n",
      "Epoch 38/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.6472 - acc: 0.7722 - val_loss: 0.6860 - val_acc: 0.7632\n",
      "Epoch 39/250\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 0.6399 - acc: 0.7770 - val_loss: 0.6877 - val_acc: 0.7638\n",
      "Epoch 40/250\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 0.6298 - acc: 0.7773 - val_loss: 0.6854 - val_acc: 0.7641\n",
      "Epoch 41/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.6196 - acc: 0.7852 - val_loss: 0.6747 - val_acc: 0.7705\n",
      "Epoch 42/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.6133 - acc: 0.7855 - val_loss: 0.6704 - val_acc: 0.7669\n",
      "Epoch 43/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.6028 - acc: 0.7873 - val_loss: 0.6674 - val_acc: 0.7714\n",
      "Epoch 44/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.5943 - acc: 0.7920 - val_loss: 0.6555 - val_acc: 0.7716\n",
      "Epoch 45/250\n",
      "50000/50000 [==============================] - 50s 998us/step - loss: 0.5869 - acc: 0.7945 - val_loss: 0.6562 - val_acc: 0.7781\n",
      "Epoch 46/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.5757 - acc: 0.7989 - val_loss: 0.6486 - val_acc: 0.7778\n",
      "Epoch 47/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.5727 - acc: 0.7983 - val_loss: 0.6431 - val_acc: 0.7810\n",
      "Epoch 48/250\n",
      "50000/50000 [==============================] - 50s 999us/step - loss: 0.5630 - acc: 0.8012 - val_loss: 0.6450 - val_acc: 0.7787\n",
      "Epoch 49/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.5566 - acc: 0.8049 - val_loss: 0.6445 - val_acc: 0.7762\n",
      "Epoch 50/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 0.5511 - acc: 0.8069 - val_loss: 0.6504 - val_acc: 0.7746\n",
      "10000/10000 [==============================] - 4s 426us/step\n",
      "Loss: 0.650\n",
      "Accuracy: 0.775\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(1000)\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.0001, decay=1e-6),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train / 255.0, to_categorical(Y_train),\n",
    "          batch_size=128,\n",
    "          shuffle=True,\n",
    "          epochs=250,\n",
    "          validation_data=(X_test / 255.0, to_categorical(Y_test)),\n",
    "          callbacks=[EarlyStopping(min_delta=0.001, patience=3)])\n",
    "\n",
    "# Evaluate the model\n",
    "scores = model.evaluate(X_test / 255.0, to_categorical(Y_test))\n",
    "\n",
    "print('Loss: %.3f' % scores[0])\n",
    "print('Accuracy: %.3f' % scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.convolutional.Conv2D object at 0x000002857F37D128>\n",
      "<keras.layers.convolutional.Conv2D object at 0x00000285700587F0>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x000002850E5F34E0>\n",
      "<keras.layers.core.Dropout object at 0x000002850E5F3860>\n",
      "<keras.layers.convolutional.Conv2D object at 0x0000028505321E10>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x000002850E623400>\n",
      "<keras.layers.convolutional.Conv2D object at 0x000002850E5F3908>\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x000002850E667898>\n",
      "<keras.layers.core.Dropout object at 0x000002856E1770B8>\n",
      "<keras.layers.core.Flatten object at 0x000002850E67CCF8>\n",
      "<keras.layers.core.Dense object at 0x000002850E667908>\n",
      "<keras.layers.core.Dropout object at 0x000002850E690E48>\n",
      "<keras.layers.core.Dense object at 0x000002850E6D06D8>\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = Sequential()\n",
    "\n",
    "for layer in model.layers[:-3]:\n",
    "    layer.trainable = False\n",
    "    new_model.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.convolutional.Conv2D at 0x2857f37d128>,\n",
       " <keras.layers.convolutional.Conv2D at 0x285700587f0>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x2850e5f34e0>,\n",
       " <keras.layers.core.Dropout at 0x2850e5f3860>,\n",
       " <keras.layers.convolutional.Conv2D at 0x28505321e10>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x2850e623400>,\n",
       " <keras.layers.convolutional.Conv2D at 0x2850e5f3908>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x2850e667898>,\n",
       " <keras.layers.core.Dropout at 0x2856e1770b8>,\n",
       " <keras.layers.core.Flatten at 0x2850e67ccf8>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.add(Dense(1024, activation='relu'))\n",
    "\n",
    "new_model.add(Dense(200, activation='relu'))\n",
    "\n",
    "new_model.add(Dense(100, activation='softmax'))\n",
    "\n",
    "new_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.01, decay=1e-6),\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar100\n",
    "\n",
    "(X_train_100, Y_train_100), (X_test_100, Y_test_100) = cifar100.load_data()\n",
    "\n",
    "X_train_100 = X_train_100 / 255.0\n",
    "X_test_100 = X_test_100 / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "391/391 [==============================] - 24s 61ms/step - loss: 3.3224 - acc: 0.2029 - val_loss: 2.9099 - val_acc: 0.2787\n",
      "Epoch 2/250\n",
      "391/391 [==============================] - 22s 56ms/step - loss: 2.9653 - acc: 0.2720 - val_loss: 2.8270 - val_acc: 0.2984\n",
      "Epoch 3/250\n",
      "391/391 [==============================] - 22s 56ms/step - loss: 2.8498 - acc: 0.2957 - val_loss: 2.7863 - val_acc: 0.3135\n",
      "Epoch 4/250\n",
      "391/391 [==============================] - 22s 56ms/step - loss: 2.7829 - acc: 0.3103 - val_loss: 2.7889 - val_acc: 0.3197\n",
      "Epoch 5/250\n",
      "391/391 [==============================] - 22s 56ms/step - loss: 2.7312 - acc: 0.3205 - val_loss: 2.7808 - val_acc: 0.3174\n",
      "Epoch 6/250\n",
      "391/391 [==============================] - 22s 56ms/step - loss: 2.6854 - acc: 0.3332 - val_loss: 2.7805 - val_acc: 0.3238\n",
      "Epoch 7/250\n",
      "391/391 [==============================] - 22s 56ms/step - loss: 2.6432 - acc: 0.3418 - val_loss: 2.7753 - val_acc: 0.3280\n",
      "Epoch 8/250\n",
      "391/391 [==============================] - 22s 56ms/step - loss: 2.6206 - acc: 0.3500 - val_loss: 2.7620 - val_acc: 0.3277\n",
      "Epoch 9/250\n",
      "391/391 [==============================] - 22s 56ms/step - loss: 2.5912 - acc: 0.3564 - val_loss: 2.7909 - val_acc: 0.3338\n",
      "Epoch 10/250\n",
      "391/391 [==============================] - 22s 56ms/step - loss: 2.5815 - acc: 0.3601 - val_loss: 2.7654 - val_acc: 0.3349\n",
      "Epoch 11/250\n",
      "391/391 [==============================] - 22s 57ms/step - loss: 2.5542 - acc: 0.3640 - val_loss: 2.7713 - val_acc: 0.3382\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2850efd3be0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_gen_100 = ImageDataGenerator()#rotation_range=90; vertical_flip = True\n",
    "train_gen_100.fit(X_train_100)\n",
    "\n",
    "# Train the model\n",
    "new_model.fit_generator(train_gen_100.flow(X_train_100, to_categorical(Y_train_100), batch_size=128, shuffle = True),\n",
    "          epochs=250,\n",
    "          validation_data=(X_test_100, to_categorical(Y_test_100)),\n",
    "          callbacks=[EarlyStopping(min_delta=0.001, patience=3)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NON-Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/250\n",
      "50000/50000 [==============================] - 53s 1ms/step - loss: 4.4423 - acc: 0.0272 - val_loss: 4.2010 - val_acc: 0.0638\n",
      "Epoch 2/250\n",
      "50000/50000 [==============================] - 51s 1ms/step - loss: 4.1047 - acc: 0.0705 - val_loss: 3.9122 - val_acc: 0.1176\n",
      "Epoch 3/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 3.8967 - acc: 0.1025 - val_loss: 3.6956 - val_acc: 0.1489\n",
      "Epoch 4/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 3.7311 - acc: 0.1323 - val_loss: 3.5388 - val_acc: 0.1796\n",
      "Epoch 5/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 3.6146 - acc: 0.1492 - val_loss: 3.4394 - val_acc: 0.1886\n",
      "Epoch 6/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 3.5141 - acc: 0.1671 - val_loss: 3.3514 - val_acc: 0.2065\n",
      "Epoch 7/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 3.4328 - acc: 0.1811 - val_loss: 3.2699 - val_acc: 0.2251\n",
      "Epoch 8/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 3.3584 - acc: 0.1938 - val_loss: 3.1897 - val_acc: 0.2370\n",
      "Epoch 9/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 3.2956 - acc: 0.2041 - val_loss: 3.1343 - val_acc: 0.2486\n",
      "Epoch 10/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 3.2315 - acc: 0.2183 - val_loss: 3.1003 - val_acc: 0.2522\n",
      "Epoch 11/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 3.1783 - acc: 0.2267 - val_loss: 3.0105 - val_acc: 0.2719\n",
      "Epoch 12/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 3.1213 - acc: 0.2357 - val_loss: 2.9676 - val_acc: 0.2770\n",
      "Epoch 13/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 3.0718 - acc: 0.2470 - val_loss: 2.9325 - val_acc: 0.2901\n",
      "Epoch 14/250\n",
      "50000/50000 [==============================] - 50s 1ms/step - loss: 3.0323 - acc: 0.2542 - val_loss: 2.8970 - val_acc: 0.2914\n",
      "Epoch 15/250\n",
      "29568/50000 [================>.............] - ETA: 19s - loss: 2.9853 - acc: 0.2657"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(1000)\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "(X_train, Y_train), (X_test, Y_test) = cifar100.load_data()\n",
    "\n",
    "# Create the model\n",
    "model1 = Sequential()\n",
    "\n",
    "model1.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model1.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model1.add(Dropout(0.25))\n",
    "\n",
    "model1.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model1.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model1.add(Dropout(0.25))\n",
    "\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(1024, activation='relu'))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(100, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model1.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.0001, decay=1e-6),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model1.fit(X_train / 255.0, to_categorical(Y_train),\n",
    "          batch_size=128,\n",
    "          shuffle=True,\n",
    "          epochs=250,\n",
    "          validation_data=(X_test / 255.0, to_categorical(Y_test)),\n",
    "          callbacks=[EarlyStopping(min_delta=0.001, patience=3)])\n",
    "\n",
    "# Evaluate the model\n",
    "scores = model1.evaluate(X_test / 255.0, to_categorical(Y_test))\n",
    "\n",
    "print('Loss: %.3f' % scores[0])\n",
    "print('Accuracy: %.3f' % scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:condathree]",
   "language": "python",
   "name": "conda-env-condathree-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
